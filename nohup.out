Traceback (most recent call last):
  File "/home/hkustadmin/evaluation/opencompass/run.py", line 328, in <module>
    main()
  File "/home/hkustadmin/evaluation/opencompass/run.py", line 197, in main
    cfg = get_config_from_arg(args)
  File "/home/hkustadmin/evaluation/opencompass/opencompass/utils/run.py", line 59, in get_config_from_arg
    return Config.fromfile(args.config, format_python_code=False)
  File "/home/hkustadmin/miniconda3/envs/opencompass/lib/python3.10/site-packages/mmengine/config/config.py", line 456, in fromfile
    lazy_import is None and not Config._is_lazy_import(filename):
  File "/home/hkustadmin/miniconda3/envs/opencompass/lib/python3.10/site-packages/mmengine/config/config.py", line 1657, in _is_lazy_import
    parsed_codes = ast.parse(codes_str)
  File "/home/hkustadmin/miniconda3/envs/opencompass/lib/python3.10/ast.py", line 50, in parse
    return compile(source, filename, mode, flags,
  File "<unknown>", line 37
    from .summarizer import dataset_abbrs summary_groups
                                          ^^^^^^^^^^^^^^
SyntaxError: invalid syntax
Traceback (most recent call last):
  File "/home/hkustadmin/evaluation/opencompass/run.py", line 328, in <module>
    main()
  File "/home/hkustadmin/evaluation/opencompass/run.py", line 197, in main
    cfg = get_config_from_arg(args)
  File "/home/hkustadmin/evaluation/opencompass/opencompass/utils/run.py", line 59, in get_config_from_arg
    return Config.fromfile(args.config, format_python_code=False)
  File "/home/hkustadmin/miniconda3/envs/opencompass/lib/python3.10/site-packages/mmengine/config/config.py", line 456, in fromfile
    lazy_import is None and not Config._is_lazy_import(filename):
  File "/home/hkustadmin/miniconda3/envs/opencompass/lib/python3.10/site-packages/mmengine/config/config.py", line 1657, in _is_lazy_import
    parsed_codes = ast.parse(codes_str)
  File "/home/hkustadmin/miniconda3/envs/opencompass/lib/python3.10/ast.py", line 50, in parse
    return compile(source, filename, mode, flags,
  File "<unknown>", line 37
    from .summarizer import dataset_abbrs summary_groups
                                          ^^^^^^^^^^^^^^
SyntaxError: invalid syntax
Traceback (most recent call last):
  File "/home/hkustadmin/evaluation/opencompass/run.py", line 328, in <module>
    main()
  File "/home/hkustadmin/evaluation/opencompass/run.py", line 197, in main
    cfg = get_config_from_arg(args)
  File "/home/hkustadmin/evaluation/opencompass/opencompass/utils/run.py", line 59, in get_config_from_arg
    return Config.fromfile(args.config, format_python_code=False)
  File "/home/hkustadmin/miniconda3/envs/opencompass/lib/python3.10/site-packages/mmengine/config/config.py", line 490, in fromfile
    raise e
  File "/home/hkustadmin/miniconda3/envs/opencompass/lib/python3.10/site-packages/mmengine/config/config.py", line 488, in fromfile
    cfg_dict, imported_names = Config._parse_lazy_import(filename)
  File "/home/hkustadmin/miniconda3/envs/opencompass/lib/python3.10/site-packages/mmengine/config/config.py", line 1068, in _parse_lazy_import
    raise ConfigParsingError(
mmengine.config.utils.ConfigParsingError: summarizer.py not found! It means that incorrect module is defined in `with read_base(): = from .summarizer import ...`, please make sure the base config module is valid and is consistent with the prior import logic
Traceback (most recent call last):
  File "/home/hkustadmin/evaluation/opencompass/run.py", line 328, in <module>
    main()
  File "/home/hkustadmin/evaluation/opencompass/run.py", line 197, in main
    cfg = get_config_from_arg(args)
  File "/home/hkustadmin/evaluation/opencompass/opencompass/utils/run.py", line 59, in get_config_from_arg
    return Config.fromfile(args.config, format_python_code=False)
  File "/home/hkustadmin/miniconda3/envs/opencompass/lib/python3.10/site-packages/mmengine/config/config.py", line 490, in fromfile
    raise e
  File "/home/hkustadmin/miniconda3/envs/opencompass/lib/python3.10/site-packages/mmengine/config/config.py", line 488, in fromfile
    cfg_dict, imported_names = Config._parse_lazy_import(filename)
  File "/home/hkustadmin/miniconda3/envs/opencompass/lib/python3.10/site-packages/mmengine/config/config.py", line 1103, in _parse_lazy_import
    exec(
  File "eval_llama_7b_test.py", line 43, in <module>
    summarizer = dict(dataset_abbrs, summary_groups, )
TypeError: dict expected at most 1 argument, got 2
Traceback (most recent call last):
  File "/home/hkustadmin/evaluation/opencompass/run.py", line 328, in <module>
    main()
  File "/home/hkustadmin/evaluation/opencompass/run.py", line 197, in main
    cfg = get_config_from_arg(args)
  File "/home/hkustadmin/evaluation/opencompass/opencompass/utils/run.py", line 59, in get_config_from_arg
    return Config.fromfile(args.config, format_python_code=False)
  File "/home/hkustadmin/miniconda3/envs/opencompass/lib/python3.10/site-packages/mmengine/config/config.py", line 490, in fromfile
    raise e
  File "/home/hkustadmin/miniconda3/envs/opencompass/lib/python3.10/site-packages/mmengine/config/config.py", line 488, in fromfile
    cfg_dict, imported_names = Config._parse_lazy_import(filename)
  File "/home/hkustadmin/miniconda3/envs/opencompass/lib/python3.10/site-packages/mmengine/config/config.py", line 1103, in _parse_lazy_import
    exec(
  File "eval_llama_7b_test.py", line 43, in <module>
    summarizer = dict(dataset_abbrs, summary_groups, )
TypeError: dict expected at most 1 argument, got 2
11/11 18:38:42 - OpenCompass - WARNING - SlurmRunner is not used, so the partition argument is ignored.
11/11 18:38:42 - OpenCompass - WARNING - Key eval.runner.task.judge_cfg not found in config, ignored.
11/11 18:38:42 - OpenCompass - INFO - Partitioned into 62 tasks.

  0%|          | 0/62 [00:00<?, ?it/s]
                                      

  0%|          | 0/62 [00:00<?, ?it/s]launch OpenICLInfer[llama-7b-hf/math_0] on GPU 0,1,2,3,4,5,6,7
11/11 18:39:02 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/math_0] fail, see
./outputs/default/20231111_183841/logs/infer/llama-7b-hf/math_0.out

  2%|▏         | 1/62 [00:19<19:49, 19.50s/it]
                                              

  2%|▏         | 1/62 [00:19<19:49, 19.50s/it]launch OpenICLInfer[llama-7b-hf/squad2.0_0] on GPU 0,1,2,3,4,5,6,7
11/11 18:39:21 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/squad2.0_0] fail, see
./outputs/default/20231111_183841/logs/infer/llama-7b-hf/squad2.0_0.out

  3%|▎         | 2/62 [00:39<19:31, 19.52s/it]
                                              

  3%|▎         | 2/62 [00:39<19:31, 19.52s/it]launch OpenICLInfer[llama-7b-hf/squad2.0_1] on GPU 0,1,2,3,4,5,6,7
11/11 18:39:41 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/squad2.0_1] fail, see
./outputs/default/20231111_183841/logs/infer/llama-7b-hf/squad2.0_1.out

  5%|▍         | 3/62 [00:58<19:06, 19.43s/it]
                                              

  5%|▍         | 3/62 [00:58<19:06, 19.43s/it]launch OpenICLInfer[llama-7b-hf/squad2.0_2] on GPU 0,1,2,3,4,5,6,7
11/11 18:40:00 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/squad2.0_2] fail, see
./outputs/default/20231111_183841/logs/infer/llama-7b-hf/squad2.0_2.out

  6%|▋         | 4/62 [01:17<18:46, 19.42s/it]
                                              

  6%|▋         | 4/62 [01:17<18:46, 19.42s/it]launch OpenICLInfer[llama-7b-hf/squad2.0_3] on GPU 0,1,2,3,4,5,6,7
11/11 18:40:20 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/squad2.0_3] fail, see
./outputs/default/20231111_183841/logs/infer/llama-7b-hf/squad2.0_3.out

  8%|▊         | 5/62 [01:37<18:26, 19.42s/it]
                                              

  8%|▊         | 5/62 [01:37<18:26, 19.42s/it]launch OpenICLInfer[llama-7b-hf/squad2.0_4] on GPU 0,1,2,3,4,5,6,7
11/11 18:40:39 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/squad2.0_4] fail, see
./outputs/default/20231111_183841/logs/infer/llama-7b-hf/squad2.0_4.out

 10%|▉         | 6/62 [01:56<18:10, 19.47s/it]
                                              

 10%|▉         | 6/62 [01:56<18:10, 19.47s/it]launch OpenICLInfer[llama-7b-hf/squad2.0_5] on GPU 0,1,2,3,4,5,6,7
11/11 18:40:59 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/squad2.0_5] fail, see
./outputs/default/20231111_183841/logs/infer/llama-7b-hf/squad2.0_5.out

 11%|█▏        | 7/62 [02:16<17:51, 19.48s/it]
                                              

 11%|█▏        | 7/62 [02:16<17:51, 19.48s/it]launch OpenICLInfer[llama-7b-hf/triviaqa_0] on GPU 0,1,2,3,4,5,6,7
11/11 18:41:18 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/triviaqa_0] fail, see
./outputs/default/20231111_183841/logs/infer/llama-7b-hf/triviaqa_0.out

 13%|█▎        | 8/62 [02:35<17:30, 19.45s/it]
                                              

 13%|█▎        | 8/62 [02:35<17:30, 19.45s/it]launch OpenICLInfer[llama-7b-hf/triviaqa_1] on GPU 0,1,2,3,4,5,6,7
11/11 18:41:37 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/triviaqa_1] fail, see
./outputs/default/20231111_183841/logs/infer/llama-7b-hf/triviaqa_1.out

 15%|█▍        | 9/62 [02:54<17:07, 19.38s/it]
                                              

 15%|█▍        | 9/62 [02:54<17:07, 19.38s/it]launch OpenICLInfer[llama-7b-hf/triviaqa_2] on GPU 0,1,2,3,4,5,6,7
11/11 18:41:56 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/triviaqa_2] fail, see
./outputs/default/20231111_183841/logs/infer/llama-7b-hf/triviaqa_2.out

 16%|█▌        | 10/62 [03:13<16:41, 19.27s/it]
                                               

 16%|█▌        | 10/62 [03:13<16:41, 19.27s/it]launch OpenICLInfer[llama-7b-hf/triviaqa_3] on GPU 0,1,2,3,4,5,6,7
11/11 18:42:16 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/triviaqa_3] fail, see
./outputs/default/20231111_183841/logs/infer/llama-7b-hf/triviaqa_3.out

 18%|█▊        | 11/62 [03:33<16:23, 19.28s/it]
                                               

 18%|█▊        | 11/62 [03:33<16:23, 19.28s/it]launch OpenICLInfer[llama-7b-hf/triviaqa_4] on GPU 0,1,2,3,4,5,6,7
11/11 18:42:35 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/triviaqa_4] fail, see
./outputs/default/20231111_183841/logs/infer/llama-7b-hf/triviaqa_4.out

 19%|█▉        | 12/62 [03:52<16:01, 19.23s/it]
                                               

 19%|█▉        | 12/62 [03:52<16:01, 19.23s/it]launch OpenICLInfer[llama-7b-hf/triviaqa_1shot_0] on GPU 0,1,2,3,4,5,6,7
11/11 18:42:54 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/triviaqa_1shot_0] fail, see
./outputs/default/20231111_183841/logs/infer/llama-7b-hf/triviaqa_1shot_0.out

 21%|██        | 13/62 [04:11<15:45, 19.29s/it]
                                               

 21%|██        | 13/62 [04:11<15:45, 19.29s/it]launch OpenICLInfer[llama-7b-hf/triviaqa_1shot_1] on GPU 0,1,2,3,4,5,6,7
11/11 18:43:13 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/triviaqa_1shot_1] fail, see
./outputs/default/20231111_183841/logs/infer/llama-7b-hf/triviaqa_1shot_1.out

 23%|██▎       | 14/62 [04:30<15:24, 19.26s/it]
                                               

 23%|██▎       | 14/62 [04:30<15:24, 19.26s/it]launch OpenICLInfer[llama-7b-hf/triviaqa_1shot_2] on GPU 0,1,2,3,4,5,6,7
11/11 18:43:32 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/triviaqa_1shot_2] fail, see
./outputs/default/20231111_183841/logs/infer/llama-7b-hf/triviaqa_1shot_2.out

 24%|██▍       | 15/62 [04:49<14:58, 19.11s/it]
                                               

 24%|██▍       | 15/62 [04:49<14:58, 19.11s/it]launch OpenICLInfer[llama-7b-hf/triviaqa_1shot_3] on GPU 0,1,2,3,4,5,6,7
11/11 18:43:59 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/triviaqa_1shot_3] fail, see
./outputs/default/20231111_183841/logs/infer/llama-7b-hf/triviaqa_1shot_3.out

 26%|██▌       | 16/62 [05:16<16:31, 21.56s/it]
                                               

 26%|██▌       | 16/62 [05:16<16:31, 21.56s/it]launch OpenICLInfer[llama-7b-hf/triviaqa_1shot_4] on GPU 0,1,2,3,4,5,6,7
11/11 19:19:36 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/triviaqa_1shot_4] fail, see
./outputs/default/20231111_183841/logs/infer/llama-7b-hf/triviaqa_1shot_4.out

 27%|██▋       | 17/62 [40:53<8:13:06, 657.48s/it]
                                                  

 27%|██▋       | 17/62 [40:53<8:13:06, 657.48s/it]launch OpenICLInfer[llama-7b-hf/triviaqa_5shot_0] on GPU 0,1,2,3,4,5,6,7
11/11 19:21:29 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/triviaqa_5shot_0] fail, see
./outputs/default/20231111_183841/logs/infer/llama-7b-hf/triviaqa_5shot_0.out

 29%|██▉       | 18/62 [42:46<6:02:13, 493.94s/it]
                                                  

 29%|██▉       | 18/62 [42:46<6:02:13, 493.94s/it]launch OpenICLInfer[llama-7b-hf/triviaqa_5shot_1] on GPU 0,1,2,3,4,5,6,7
11/11 19:23:12 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/triviaqa_5shot_1] fail, see
./outputs/default/20231111_183841/logs/infer/llama-7b-hf/triviaqa_5shot_1.out

 31%|███       | 19/62 [44:30<4:29:56, 376.67s/it]
                                                  

 31%|███       | 19/62 [44:30<4:29:56, 376.67s/it]usage: run.py [-h] [--slurm | --dlc] [--mm-eval]
              [--models MODELS [MODELS ...]]
              [--datasets DATASETS [DATASETS ...]] [--summarizer SUMMARIZER]
              [--debug] [--dry-run] [-m {all,infer,eval,viz}] [-r [REUSE]]
              [-w WORK_DIR] [--config-dir CONFIG_DIR] [-l]
              [--max-partition-size MAX_PARTITION_SIZE]
              [--gen-task-coef GEN_TASK_COEF]
              [--max-num-workers MAX_NUM_WORKERS]
              [--max-workers-per-gpu MAX_WORKERS_PER_GPU] [--retry RETRY]
              [-p PARTITION] [-q QUOTATYPE] [--qos QOS]
              [--aliyun-cfg ALIYUN_CFG] [--hf-path HF_PATH]
              [--peft-path PEFT_PATH] [--tokenizer-path TOKENIZER_PATH]
              [--model-kwargs MODEL_KWARGS [MODEL_KWARGS ...]]
              [--tokenizer-kwargs TOKENIZER_KWARGS [TOKENIZER_KWARGS ...]]
              [--max-out-len MAX_OUT_LEN] [--max-seq-len MAX_SEQ_LEN]
              [--no-batch-padding] [--batch-size BATCH_SIZE]
              [--num-gpus NUM_GPUS] [--pad-token-id PAD_TOKEN_ID]
              [config]
run.py: error: unrecognized arguments: --num_fewshot 5
11/12 01:53:14 - OpenCompass - WARNING - SlurmRunner is not used, so the partition argument is ignored.
11/12 01:53:14 - OpenCompass - WARNING - Key eval.runner.task.judge_cfg not found in config, ignored.
11/12 01:53:14 - OpenCompass - INFO - Partitioned into 2 tasks.

  0%|          | 0/2 [00:00<?, ?it/s]
                                     

  0%|          | 0/2 [00:00<?, ?it/s]launch OpenICLInfer[llama-7b-hf/cmmlu-professional_law,llama-7b-hf/cmmlu-jurisprudence,llama-7b-hf/cmmlu-professional_medicine,llama-7b-hf/cmmlu-chinese_history,llama-7b-hf/cmmlu-college_medicine,llama-7b-hf/cmmlu-elementary_chinese,llama-7b-hf/cmmlu-elementary_information_and_technology,llama-7b-hf/cmmlu-clinical_knowledge,llama-7b-hf/cmmlu-professional_psychology,llama-7b-hf/cmmlu-elementary_mathematics,llama-7b-hf/cmmlu-sociology,llama-7b-hf/cmmlu-legal_and_moral_basis,llama-7b-hf/cmmlu-management,llama-7b-hf/cmmlu-business_ethics,llama-7b-hf/cmmlu-chinese_literature,llama-7b-hf/cmmlu-computer_science,llama-7b-hf/cmmlu-elementary_commonsense,llama-7b-hf/cmmlu-marxist_theory,llama-7b-hf/cmmlu-international_law,llama-7b-hf/cmmlu-traditional_chinese_medicine,llama-7b-hf/cmmlu-marketing,llama-7b-hf/cmmlu-chinese_teacher_qualification,llama-7b-hf/cmmlu-genetics,llama-7b-hf/cmmlu-professional_accounting,llama-7b-hf/cmmlu-public_relations,llama-7b-hf/cmmlu-electrical_engineering,llama-7b-hf/cmmlu-journalism,llama-7b-hf/cmmlu-computer_security,llama-7b-hf/cmmlu-agronomy,llama-7b-hf/cmmlu-high_school_biology,llama-7b-hf/cmmlu-virology,llama-7b-hf/cmmlu-astronomy,llama-7b-hf/cmmlu-sports_science,llama-7b-hf/cmmlu-ancient_chinese,llama-7b-hf/cmmlu-high_school_mathematics,llama-7b-hf/cmmlu-education,llama-7b-hf/cmmlu-world_history,llama-7b-hf/cmmlu-arts,llama-7b-hf/cmmlu-chinese_civil_service_exam] on GPU 0,1,2,3,4,5,6,7
11/12 01:53:37 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/cmmlu-professional_law,llama-7b-hf/cmmlu-jurisprudence,llama-7b-hf/cmmlu-professional_medicine,llama-7b-hf/cmmlu-chinese_history,llama-7b-hf/cmmlu-college_medicine,llama-7b-hf/cmmlu-elementary_chinese,llama-7b-hf/cmmlu-elementary_information_and_technology,llama-7b-hf/cmmlu-clinical_knowledge,llama-7b-hf/cmmlu-professional_psychology,llama-7b-hf/cmmlu-elementary_mathematics,llama-7b-hf/cmmlu-sociology,llama-7b-hf/cmmlu-legal_and_moral_basis,llama-7b-hf/cmmlu-management,llama-7b-hf/cmmlu-business_ethics,llama-7b-hf/cmmlu-chinese_literature,llama-7b-hf/cmmlu-computer_science,llama-7b-hf/cmmlu-elementary_commonsense,llama-7b-hf/cmmlu-marxist_theory,llama-7b-hf/cmmlu-international_law,llama-7b-hf/cmmlu-traditional_chinese_medicine,llama-7b-hf/cmmlu-marketing,llama-7b-hf/cmmlu-chinese_teacher_qualification,llama-7b-hf/cmmlu-genetics,llama-7b-hf/cmmlu-professional_accounting,llama-7b-hf/cmmlu-public_relations,llama-7b-hf/cmmlu-electrical_engineering,llama-7b-hf/cmmlu-journalism,llama-7b-hf/cmmlu-computer_security,llama-7b-hf/cmmlu-agronomy,llama-7b-hf/cmmlu-high_school_biology,llama-7b-hf/cmmlu-virology,llama-7b-hf/cmmlu-astronomy,llama-7b-hf/cmmlu-sports_science,llama-7b-hf/cmmlu-ancient_chinese,llama-7b-hf/cmmlu-high_school_mathematics,llama-7b-hf/cmmlu-education,llama-7b-hf/cmmlu-world_history,llama-7b-hf/cmmlu-arts,llama-7b-hf/cmmlu-chinese_civil_service_exam] fail, see
./outputs/default/20231112_015313/logs/infer/llama-7b-hf/cmmlu-professional_law.out

 50%|█████     | 1/2 [00:23<00:23, 23.14s/it]
                                             

 50%|█████     | 1/2 [00:23<00:23, 23.14s/it]launch OpenICLInfer[llama-7b-hf/cmmlu-world_religions,llama-7b-hf/cmmlu-economics,llama-7b-hf/cmmlu-global_facts,llama-7b-hf/cmmlu-anatomy,llama-7b-hf/cmmlu-conceptual_physics,llama-7b-hf/cmmlu-nutrition,llama-7b-hf/cmmlu-food_science,llama-7b-hf/cmmlu-high_school_politics,llama-7b-hf/cmmlu-construction_project_management,llama-7b-hf/cmmlu-chinese_food_culture,llama-7b-hf/cmmlu-ethnology,llama-7b-hf/cmmlu-security_study,llama-7b-hf/cmmlu-high_school_chemistry,llama-7b-hf/cmmlu-chinese_driving_rule,llama-7b-hf/cmmlu-human_sexuality,llama-7b-hf/cmmlu-logical,llama-7b-hf/cmmlu-machine_learning,llama-7b-hf/cmmlu-high_school_geography,llama-7b-hf/cmmlu-modern_chinese,llama-7b-hf/cmmlu-high_school_physics,llama-7b-hf/cmmlu-college_law,llama-7b-hf/cmmlu-chinese_foreign_policy,llama-7b-hf/cmmlu-college_education,llama-7b-hf/cmmlu-college_actuarial_science,llama-7b-hf/cmmlu-college_engineering_hydrology,llama-7b-hf/cmmlu-college_medical_statistics,llama-7b-hf/cmmlu-college_mathematics,llama-7b-hf/cmmlu-philosophy] on GPU 0,1,2,3,4,5,6,7
11/12 01:54:01 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/cmmlu-world_religions,llama-7b-hf/cmmlu-economics,llama-7b-hf/cmmlu-global_facts,llama-7b-hf/cmmlu-anatomy,llama-7b-hf/cmmlu-conceptual_physics,llama-7b-hf/cmmlu-nutrition,llama-7b-hf/cmmlu-food_science,llama-7b-hf/cmmlu-high_school_politics,llama-7b-hf/cmmlu-construction_project_management,llama-7b-hf/cmmlu-chinese_food_culture,llama-7b-hf/cmmlu-ethnology,llama-7b-hf/cmmlu-security_study,llama-7b-hf/cmmlu-high_school_chemistry,llama-7b-hf/cmmlu-chinese_driving_rule,llama-7b-hf/cmmlu-human_sexuality,llama-7b-hf/cmmlu-logical,llama-7b-hf/cmmlu-machine_learning,llama-7b-hf/cmmlu-high_school_geography,llama-7b-hf/cmmlu-modern_chinese,llama-7b-hf/cmmlu-high_school_physics,llama-7b-hf/cmmlu-college_law,llama-7b-hf/cmmlu-chinese_foreign_policy,llama-7b-hf/cmmlu-college_education,llama-7b-hf/cmmlu-college_actuarial_science,llama-7b-hf/cmmlu-college_engineering_hydrology,llama-7b-hf/cmmlu-college_medical_statistics,llama-7b-hf/cmmlu-college_mathematics,llama-7b-hf/cmmlu-philosophy] fail, see
./outputs/default/20231112_015313/logs/infer/llama-7b-hf/cmmlu-world_religions.out

100%|██████████| 2/2 [00:46<00:00, 23.20s/it]
100%|██████████| 2/2 [00:46<00:00, 23.19s/it]
11/12 01:54:01 - OpenCompass - ERROR - /home/hkustadmin/evaluation/opencompass/opencompass/runners/base.py - summarize - 63 - OpenICLInfer[llama-7b-hf/cmmlu-professional_law,llama-7b-hf/cmmlu-jurisprudence,llama-7b-hf/cmmlu-professional_medicine,llama-7b-hf/cmmlu-chinese_history,llama-7b-hf/cmmlu-college_medicine,llama-7b-hf/cmmlu-elementary_chinese,llama-7b-hf/cmmlu-elementary_information_and_technology,llama-7b-hf/cmmlu-clinical_knowledge,llama-7b-hf/cmmlu-professional_psychology,llama-7b-hf/cmmlu-elementary_mathematics,llama-7b-hf/cmmlu-sociology,llama-7b-hf/cmmlu-legal_and_moral_basis,llama-7b-hf/cmmlu-management,llama-7b-hf/cmmlu-business_ethics,llama-7b-hf/cmmlu-chinese_literature,llama-7b-hf/cmmlu-computer_science,llama-7b-hf/cmmlu-elementary_commonsense,llama-7b-hf/cmmlu-marxist_theory,llama-7b-hf/cmmlu-international_law,llama-7b-hf/cmmlu-traditional_chinese_medicine,llama-7b-hf/cmmlu-marketing,llama-7b-hf/cmmlu-chinese_teacher_qualification,llama-7b-hf/cmmlu-genetics,llama-7b-hf/cmmlu-professional_accounting,llama-7b-hf/cmmlu-public_relations,llama-7b-hf/cmmlu-electrical_engineering,llama-7b-hf/cmmlu-journalism,llama-7b-hf/cmmlu-computer_security,llama-7b-hf/cmmlu-agronomy,llama-7b-hf/cmmlu-high_school_biology,llama-7b-hf/cmmlu-virology,llama-7b-hf/cmmlu-astronomy,llama-7b-hf/cmmlu-sports_science,llama-7b-hf/cmmlu-ancient_chinese,llama-7b-hf/cmmlu-high_school_mathematics,llama-7b-hf/cmmlu-education,llama-7b-hf/cmmlu-world_history,llama-7b-hf/cmmlu-arts,llama-7b-hf/cmmlu-chinese_civil_service_exam] failed with code 1
11/12 01:54:01 - OpenCompass - ERROR - /home/hkustadmin/evaluation/opencompass/opencompass/runners/base.py - summarize - 63 - OpenICLInfer[llama-7b-hf/cmmlu-world_religions,llama-7b-hf/cmmlu-economics,llama-7b-hf/cmmlu-global_facts,llama-7b-hf/cmmlu-anatomy,llama-7b-hf/cmmlu-conceptual_physics,llama-7b-hf/cmmlu-nutrition,llama-7b-hf/cmmlu-food_science,llama-7b-hf/cmmlu-high_school_politics,llama-7b-hf/cmmlu-construction_project_management,llama-7b-hf/cmmlu-chinese_food_culture,llama-7b-hf/cmmlu-ethnology,llama-7b-hf/cmmlu-security_study,llama-7b-hf/cmmlu-high_school_chemistry,llama-7b-hf/cmmlu-chinese_driving_rule,llama-7b-hf/cmmlu-human_sexuality,llama-7b-hf/cmmlu-logical,llama-7b-hf/cmmlu-machine_learning,llama-7b-hf/cmmlu-high_school_geography,llama-7b-hf/cmmlu-modern_chinese,llama-7b-hf/cmmlu-high_school_physics,llama-7b-hf/cmmlu-college_law,llama-7b-hf/cmmlu-chinese_foreign_policy,llama-7b-hf/cmmlu-college_education,llama-7b-hf/cmmlu-college_actuarial_science,llama-7b-hf/cmmlu-college_engineering_hydrology,llama-7b-hf/cmmlu-college_medical_statistics,llama-7b-hf/cmmlu-college_mathematics,llama-7b-hf/cmmlu-philosophy] failed with code 1
11/12 01:54:01 - OpenCompass - INFO - Partitioned into 67 tasks.

  0%|          | 0/67 [00:00<?, ?it/s]
                                      

  0%|          | 0/67 [00:00<?, ?it/s]
                                      

  0%|          | 0/67 [00:00<?, ?it/s]
                                      

  0%|          | 0/67 [00:00<?, ?it/s]
                                      

  0%|          | 0/67 [00:00<?, ?it/s]
                                      

  0%|          | 0/67 [00:00<?, ?it/s]
                                      

  0%|          | 0/67 [00:00<?, ?it/s]
                                      

  0%|          | 0/67 [00:00<?, ?it/s]
                                      

  0%|          | 0/67 [00:00<?, ?it/s]
                                      

  0%|          | 0/67 [00:00<?, ?it/s]
                                      

  0%|          | 0/67 [00:01<?, ?it/s]
                                      

  0%|          | 0/67 [00:01<?, ?it/s]
                                      

  0%|          | 0/67 [00:01<?, ?it/s]
                                      

  0%|          | 0/67 [00:02<?, ?it/s]
                                      

  0%|          | 0/67 [00:02<?, ?it/s]
                                      

  0%|          | 0/67 [00:02<?, ?it/s]
                                      

  0%|          | 0/67 [00:03<?, ?it/s]
                                      

  0%|          | 0/67 [00:04<?, ?it/s]
                                      

  0%|          | 0/67 [00:04<?, ?it/s]
                                      

  0%|          | 0/67 [00:05<?, ?it/s]
                                      

  0%|          | 0/67 [00:05<?, ?it/s]
                                      

  0%|          | 0/67 [00:06<?, ?it/s]
                                      

  0%|          | 0/67 [00:06<?, ?it/s]
                                      

  0%|          | 0/67 [00:07<?, ?it/s]
                                      

  0%|          | 0/67 [00:08<?, ?it/s]
                                      

  0%|          | 0/67 [00:09<?, ?it/s]
                                      

  0%|          | 0/67 [00:11<?, ?it/s]
                                      

  0%|          | 0/67 [00:11<?, ?it/s]
                                      

  0%|          | 0/67 [00:14<?, ?it/s]
                                      

  0%|          | 0/67 [00:15<?, ?it/s]
                                      

  0%|          | 0/67 [00:15<?, ?it/s]
                                      

  0%|          | 0/67 [00:16<?, ?it/s]
                                      

  0%|          | 0/67 [00:17<?, ?it/s]
  1%|▏         | 1/67 [00:45<49:43, 45.21s/it]
  3%|▎         | 2/67 [00:45<30:50, 28.46s/it]
                                              

  3%|▎         | 2/67 [00:46<30:50, 28.46s/it]
                                              

  3%|▎         | 2/67 [00:47<30:50, 28.46s/it]
  4%|▍         | 3/67 [00:47<20:47, 19.49s/it]
                                              

  4%|▍         | 3/67 [00:47<20:47, 19.49s/it]
  6%|▌         | 4/67 [00:49<14:17, 13.61s/it]
                                              

  6%|▌         | 4/67 [00:49<14:17, 13.61s/it]
  7%|▋         | 5/67 [00:50<09:47,  9.47s/it]
                                              

  7%|▋         | 5/67 [00:50<09:47,  9.47s/it]
  9%|▉         | 6/67 [00:51<07:06,  7.00s/it]
 12%|█▏        | 8/67 [00:52<03:05,  3.14s/it]
                                              

 13%|█▎        | 9/67 [00:52<02:23,  2.47s/it]
 13%|█▎        | 9/67 [00:52<02:23,  2.47s/it]
                                              

 16%|█▋        | 11/67 [00:54<00:54,  1.04it/s]
 16%|█▋        | 11/67 [00:54<00:54,  1.04it/s]
 18%|█▊        | 12/67 [00:55<01:08,  1.24s/it]
 18%|█▊        | 12/67 [00:55<01:08,  1.24s/it]
                                               

 18%|█▊        | 12/67 [00:56<01:08,  1.24s/it]
                                               

 18%|█▊        | 12/67 [00:56<01:08,  1.24s/it]
 18%|█▊        | 12/67 [00:56<01:08,  1.24s/it]
                                               

 18%|█▊        | 12/67 [00:57<01:08,  1.24s/it]
                                               

 19%|█▉        | 13/67 [00:57<01:24,  1.57s/it]
                                               

 19%|█▉        | 13/67 [00:58<01:24,  1.57s/it]
 19%|█▉        | 13/67 [00:58<01:24,  1.57s/it]
                                               

 19%|█▉        | 13/67 [00:59<01:24,  1.57s/it]
 21%|██        | 14/67 [00:59<01:26,  1.63s/it]
                                               

 21%|██        | 14/67 [00:59<01:26,  1.63s/it]
 22%|██▏       | 15/67 [01:01<01:30,  1.74s/it]
 24%|██▍       | 16/67 [01:02<01:16,  1.50s/it]
                                               

 27%|██▋       | 18/67 [01:02<00:41,  1.18it/s]
 28%|██▊       | 19/67 [01:03<00:45,  1.05it/s]
 30%|██▉       | 20/67 [01:03<00:52,  1.12s/it]
                                               

 31%|███▏      | 21/67 [01:04<01:01,  1.33s/it]
 31%|███▏      | 21/67 [01:04<01:01,  1.33s/it]
                                               

 31%|███▏      | 21/67 [01:05<01:01,  1.33s/it]
 31%|███▏      | 21/67 [01:05<01:01,  1.33s/it]
                                               

 31%|███▏      | 21/67 [01:07<01:01,  1.33s/it]
 31%|███▏      | 21/67 [01:07<01:01,  1.33s/it]
                                               

 33%|███▎      | 22/67 [01:08<01:33,  2.07s/it]
                                               

 33%|███▎      | 22/67 [01:09<01:33,  2.07s/it]
 33%|███▎      | 22/67 [01:09<01:33,  2.07s/it]
                                               

 36%|███▌      | 24/67 [01:10<01:58,  2.75s/it]
 37%|███▋      | 25/67 [01:10<01:29,  2.12s/it]
                                               

 37%|███▋      | 25/67 [01:11<01:29,  2.12s/it]
 37%|███▋      | 25/67 [01:11<01:29,  2.12s/it]
 37%|███▋      | 25/67 [01:11<01:29,  2.12s/it]
                                               

 37%|███▋      | 25/67 [01:12<01:29,  2.12s/it]
                                               

 37%|███▋      | 25/67 [01:14<01:29,  2.12s/it]
                                               

 37%|███▋      | 25/67 [01:15<01:29,  2.12s/it]
 39%|███▉      | 26/67 [01:15<01:57,  2.86s/it]
                                               

 39%|███▉      | 26/67 [01:16<01:57,  2.86s/it]
 40%|████      | 27/67 [01:20<02:13,  3.35s/it]
                                               

 40%|████      | 27/67 [01:20<02:13,  3.35s/it]
 42%|████▏     | 28/67 [01:20<01:39,  2.56s/it]
                                               

 43%|████▎     | 29/67 [01:21<01:12,  1.91s/it]
 45%|████▍     | 30/67 [01:21<00:46,  1.25s/it]
 45%|████▍     | 30/67 [01:22<00:46,  1.25s/it]
                                               

 45%|████▍     | 30/67 [01:23<00:46,  1.25s/it]
                                               

 45%|████▍     | 30/67 [01:24<00:46,  1.25s/it]
 46%|████▋     | 31/67 [01:27<01:21,  2.27s/it]
                                               

 48%|████▊     | 32/67 [01:27<01:02,  1.79s/it]
 48%|████▊     | 32/67 [01:28<01:02,  1.79s/it]
                                               

 48%|████▊     | 32/67 [01:28<01:02,  1.79s/it]
 49%|████▉     | 33/67 [01:50<04:15,  7.51s/it]
                                               

 49%|████▉     | 33/67 [01:51<04:15,  7.51s/it]
 51%|█████     | 34/67 [01:56<03:53,  7.06s/it]
                                               

 52%|█████▏    | 35/67 [01:57<02:51,  5.37s/it]
 52%|█████▏    | 35/67 [01:58<02:51,  5.37s/it]
                                               

 54%|█████▎    | 36/67 [01:59<02:09,  4.18s/it]
 54%|█████▎    | 36/67 [01:59<02:09,  4.18s/it]
 55%|█████▌    | 37/67 [02:03<02:05,  4.18s/it]
 57%|█████▋    | 38/67 [02:03<01:28,  3.06s/it]
 58%|█████▊    | 39/67 [02:04<01:08,  2.44s/it]
 60%|█████▉    | 40/67 [02:08<01:15,  2.78s/it]
 61%|██████    | 41/67 [02:09<01:00,  2.34s/it]
 63%|██████▎   | 42/67 [02:10<00:49,  1.98s/it]
 64%|██████▍   | 43/67 [02:11<00:39,  1.63s/it]
 66%|██████▌   | 44/67 [02:16<01:00,  2.62s/it]
 67%|██████▋   | 45/67 [02:16<00:42,  1.93s/it]
 69%|██████▊   | 46/67 [02:16<00:29,  1.40s/it]
 70%|███████   | 47/67 [02:17<00:25,  1.28s/it]
 72%|███████▏  | 48/67 [02:18<00:20,  1.09s/it]
 73%|███████▎  | 49/67 [02:20<00:23,  1.32s/it]
 75%|███████▍  | 50/67 [02:21<00:19,  1.17s/it]
 76%|███████▌  | 51/67 [02:21<00:13,  1.15it/s]
 78%|███████▊  | 52/67 [02:21<00:10,  1.42it/s]
 79%|███████▉  | 53/67 [02:24<00:18,  1.35s/it]
 81%|████████  | 54/67 [02:24<00:13,  1.06s/it]
 84%|████████▎ | 56/67 [02:25<00:07,  1.55it/s]
 85%|████████▌ | 57/67 [02:25<00:05,  1.95it/s]
 87%|████████▋ | 58/67 [02:25<00:03,  2.41it/s]
 88%|████████▊ | 59/67 [02:25<00:02,  2.90it/s]
 90%|████████▉ | 60/67 [02:25<00:02,  2.86it/s]
 91%|█████████ | 61/67 [02:26<00:02,  2.66it/s]
 94%|█████████▍| 63/67 [02:26<00:01,  3.31it/s]
 97%|█████████▋| 65/67 [02:28<00:00,  2.11it/s]
 99%|█████████▊| 66/67 [02:28<00:00,  2.05it/s]
100%|██████████| 67/67 [02:28<00:00,  2.22s/it]
launch OpenICLEval[llama-7b-hf/cmmlu-agronomy] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-anatomy] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-ancient_chinese] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-arts] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-astronomy] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-business_ethics] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-chinese_civil_service_exam] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-chinese_driving_rule] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-chinese_food_culture] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-chinese_foreign_policy] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-chinese_history] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-chinese_literature] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-chinese_teacher_qualification] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-clinical_knowledge] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-college_actuarial_science] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-college_education] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-college_engineering_hydrology] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-college_law] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-college_mathematics] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-college_medical_statistics] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-college_medicine] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-computer_science] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-computer_security] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-conceptual_physics] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-construction_project_management] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-economics] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-education] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-electrical_engineering] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-elementary_chinese] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-elementary_commonsense] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-elementary_information_and_technology] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-elementary_mathematics] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-ethnology] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-food_science] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-genetics] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-global_facts] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-high_school_biology] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-high_school_chemistry] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-high_school_geography] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-high_school_mathematics] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-high_school_physics] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-high_school_politics] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-human_sexuality] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-international_law] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-journalism] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-jurisprudence] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-legal_and_moral_basis] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-logical] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-machine_learning] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-management] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-marketing] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-marxist_theory] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-modern_chinese] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-nutrition] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-philosophy] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-professional_accounting] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-professional_law] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-professional_medicine] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-professional_psychology] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-public_relations] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-security_study] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-sociology] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-sports_science] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-traditional_chinese_medicine] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-virology] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-world_history] on CPU 
launch OpenICLEval[llama-7b-hf/cmmlu-world_religions] on CPU 
dataset                       version    metric    mode    llama-7b-hf
----------------------------  ---------  --------  ------  -------------
------- MMLU details -------  -          -         -       -
mmlu-humanities               -          -         -       -
mmlu-stem                     -          -         -       -
mmlu-social-science           -          -         -       -
mmlu-other                    -          -         -       -
mmlu                          -          -         -       -
---- Standard Benchmarks ---  -          -         -       -
BoolQ                         -          -         -       -
piqa                          -          -         -       -
siqa                          -          -         -       -
hellaswag                     -          -         -       -
winogrande                    -          -         -       -
ARC-e                         -          -         -       -
ARC-c                         -          -         -       -
openbookqa_fact               -          -         -       -
commonsense_qa                -          -         -       -
mmlu                          -          -         -       -
------ Code Generation -----  -          -         -       -
openai_humaneval              -          -         -       -
mbpp                          -          -         -       -
------ World Knowledge -----  -          -         -       -
triviaqa                      -          -         -       -
--- Reading Comprehension --  -          -         -       -
squad2.0                      -          -         -       -
---------- Exams -----------  -          -         -       -
math                          -          -         -       -
gsm8k                         -          -         -       -
TheoremQA                     -          -         -       -
--------- Chinese ----------  -          -         -       -
ceval                         -          -         -       -
ceval-stem                    -          -         -       -
ceval-social-science          -          -         -       -
ceval-humanities              -          -         -       -
ceval-other                   -          -         -       -
ceval-hard                    -          -         -       -
ceval-test-stem               -          -         -       -
ceval-test-social-science     -          -         -       -
ceval-test-humanities         -          -         -       -
ceval-test-other              -          -         -       -
ceval-test-hard               -          -         -       -
ceval-test                    -          -         -       -
cmmlu                         -          -         -       -
cmmlu-humanities              -          -         -       -
cmmlu-stem                    -          -         -       -
cmmlu-social-science          -          -         -       -
cmmlu-other                   -          -         -       -
cmmlu-china-specific          -          -         -       -
11/12 01:56:29 - OpenCompass - INFO - write summary to /home/hkustadmin/evaluation/opencompass/outputs/default/20231112_015313/summary/summary_20231112_015313.txt
11/12 01:56:29 - OpenCompass - INFO - write csv to /home/hkustadmin/evaluation/opencompass/outputs/default/20231112_015313/summary/summary_20231112_015313.csv
11/12 01:57:39 - OpenCompass - WARNING - SlurmRunner is not used, so the partition argument is ignored.
11/12 01:57:39 - OpenCompass - WARNING - Key eval.runner.task.judge_cfg not found in config, ignored.
11/12 01:57:39 - OpenCompass - INFO - Partitioned into 4 tasks.

  0%|          | 0/4 [00:00<?, ?it/s]
                                     

  0%|          | 0/4 [00:00<?, ?it/s]launch OpenICLInfer[llama-7b-hf/lukaemon_mmlu_professional_law_0] on GPU 0,1,2,3,4,5,6,7
11/12 01:58:00 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/lukaemon_mmlu_professional_law_0] fail, see
./outputs/default/20231112_015739/logs/infer/llama-7b-hf/lukaemon_mmlu_professional_law_0.out

 25%|██▌       | 1/4 [00:20<01:02, 20.82s/it]
                                             

 25%|██▌       | 1/4 [00:21<01:02, 20.82s/it]launch OpenICLInfer[llama-7b-hf/lukaemon_mmlu_professional_law_1] on GPU 0,1,2,3,4,5,6,7
11/12 01:58:21 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/lukaemon_mmlu_professional_law_1] fail, see
./outputs/default/20231112_015739/logs/infer/llama-7b-hf/lukaemon_mmlu_professional_law_1.out

 50%|█████     | 2/4 [00:41<00:41, 20.82s/it]
                                             

 50%|█████     | 2/4 [00:42<00:41, 20.82s/it]launch OpenICLInfer[llama-7b-hf/lukaemon_mmlu_moral_scenarios,llama-7b-hf/lukaemon_mmlu_miscellaneous,llama-7b-hf/lukaemon_mmlu_professional_psychology,llama-7b-hf/lukaemon_mmlu_high_school_psychology,llama-7b-hf/lukaemon_mmlu_high_school_macroeconomics,llama-7b-hf/lukaemon_mmlu_elementary_mathematics,llama-7b-hf/lukaemon_mmlu_moral_disputes,llama-7b-hf/lukaemon_mmlu_prehistory,llama-7b-hf/lukaemon_mmlu_philosophy,llama-7b-hf/lukaemon_mmlu_high_school_biology,llama-7b-hf/lukaemon_mmlu_nutrition,llama-7b-hf/lukaemon_mmlu_professional_accounting,llama-7b-hf/lukaemon_mmlu_professional_medicine,llama-7b-hf/lukaemon_mmlu_high_school_mathematics,llama-7b-hf/lukaemon_mmlu_clinical_knowledge,llama-7b-hf/lukaemon_mmlu_security_studies,llama-7b-hf/lukaemon_mmlu_high_school_microeconomics,llama-7b-hf/lukaemon_mmlu_high_school_world_history,llama-7b-hf/lukaemon_mmlu_conceptual_physics,llama-7b-hf/lukaemon_mmlu_marketing,llama-7b-hf/lukaemon_mmlu_human_aging,llama-7b-hf/lukaemon_mmlu_high_school_statistics,llama-7b-hf/lukaemon_mmlu_high_school_us_history,llama-7b-hf/lukaemon_mmlu_high_school_chemistry,llama-7b-hf/lukaemon_mmlu_sociology,llama-7b-hf/lukaemon_mmlu_high_school_geography,llama-7b-hf/lukaemon_mmlu_high_school_government_and_politics,llama-7b-hf/lukaemon_mmlu_college_medicine,llama-7b-hf/lukaemon_mmlu_world_religions,llama-7b-hf/lukaemon_mmlu_virology,llama-7b-hf/lukaemon_mmlu_high_school_european_history,llama-7b-hf/lukaemon_mmlu_logical_fallacies,llama-7b-hf/lukaemon_mmlu_astronomy] on GPU 0,1,2,3,4,5,6,7
11/12 01:58:43 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/lukaemon_mmlu_moral_scenarios,llama-7b-hf/lukaemon_mmlu_miscellaneous,llama-7b-hf/lukaemon_mmlu_professional_psychology,llama-7b-hf/lukaemon_mmlu_high_school_psychology,llama-7b-hf/lukaemon_mmlu_high_school_macroeconomics,llama-7b-hf/lukaemon_mmlu_elementary_mathematics,llama-7b-hf/lukaemon_mmlu_moral_disputes,llama-7b-hf/lukaemon_mmlu_prehistory,llama-7b-hf/lukaemon_mmlu_philosophy,llama-7b-hf/lukaemon_mmlu_high_school_biology,llama-7b-hf/lukaemon_mmlu_nutrition,llama-7b-hf/lukaemon_mmlu_professional_accounting,llama-7b-hf/lukaemon_mmlu_professional_medicine,llama-7b-hf/lukaemon_mmlu_high_school_mathematics,llama-7b-hf/lukaemon_mmlu_clinical_knowledge,llama-7b-hf/lukaemon_mmlu_security_studies,llama-7b-hf/lukaemon_mmlu_high_school_microeconomics,llama-7b-hf/lukaemon_mmlu_high_school_world_history,llama-7b-hf/lukaemon_mmlu_conceptual_physics,llama-7b-hf/lukaemon_mmlu_marketing,llama-7b-hf/lukaemon_mmlu_human_aging,llama-7b-hf/lukaemon_mmlu_high_school_statistics,llama-7b-hf/lukaemon_mmlu_high_school_us_history,llama-7b-hf/lukaemon_mmlu_high_school_chemistry,llama-7b-hf/lukaemon_mmlu_sociology,llama-7b-hf/lukaemon_mmlu_high_school_geography,llama-7b-hf/lukaemon_mmlu_high_school_government_and_politics,llama-7b-hf/lukaemon_mmlu_college_medicine,llama-7b-hf/lukaemon_mmlu_world_religions,llama-7b-hf/lukaemon_mmlu_virology,llama-7b-hf/lukaemon_mmlu_high_school_european_history,llama-7b-hf/lukaemon_mmlu_logical_fallacies,llama-7b-hf/lukaemon_mmlu_astronomy] fail, see
./outputs/default/20231112_015739/logs/infer/llama-7b-hf/lukaemon_mmlu_moral_scenarios.out

 75%|███████▌  | 3/4 [01:03<00:21, 21.52s/it]
                                             

 75%|███████▌  | 3/4 [01:04<00:21, 21.52s/it]launch OpenICLInfer[llama-7b-hf/lukaemon_mmlu_high_school_physics,llama-7b-hf/lukaemon_mmlu_electrical_engineering,llama-7b-hf/lukaemon_mmlu_college_biology,llama-7b-hf/lukaemon_mmlu_anatomy,llama-7b-hf/lukaemon_mmlu_human_sexuality,llama-7b-hf/lukaemon_mmlu_formal_logic,llama-7b-hf/lukaemon_mmlu_international_law,llama-7b-hf/lukaemon_mmlu_econometrics,llama-7b-hf/lukaemon_mmlu_machine_learning,llama-7b-hf/lukaemon_mmlu_public_relations,llama-7b-hf/lukaemon_mmlu_jurisprudence,llama-7b-hf/lukaemon_mmlu_management,llama-7b-hf/lukaemon_mmlu_college_physics,llama-7b-hf/lukaemon_mmlu_college_chemistry,llama-7b-hf/lukaemon_mmlu_college_computer_science,llama-7b-hf/lukaemon_mmlu_college_mathematics,llama-7b-hf/lukaemon_mmlu_abstract_algebra,llama-7b-hf/lukaemon_mmlu_global_facts,llama-7b-hf/lukaemon_mmlu_computer_security,llama-7b-hf/lukaemon_mmlu_medical_genetics,llama-7b-hf/lukaemon_mmlu_high_school_computer_science,llama-7b-hf/lukaemon_mmlu_business_ethics,llama-7b-hf/lukaemon_mmlu_us_foreign_policy] on GPU 0,1,2,3,4,5,6,7
11/12 01:59:06 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/lukaemon_mmlu_high_school_physics,llama-7b-hf/lukaemon_mmlu_electrical_engineering,llama-7b-hf/lukaemon_mmlu_college_biology,llama-7b-hf/lukaemon_mmlu_anatomy,llama-7b-hf/lukaemon_mmlu_human_sexuality,llama-7b-hf/lukaemon_mmlu_formal_logic,llama-7b-hf/lukaemon_mmlu_international_law,llama-7b-hf/lukaemon_mmlu_econometrics,llama-7b-hf/lukaemon_mmlu_machine_learning,llama-7b-hf/lukaemon_mmlu_public_relations,llama-7b-hf/lukaemon_mmlu_jurisprudence,llama-7b-hf/lukaemon_mmlu_management,llama-7b-hf/lukaemon_mmlu_college_physics,llama-7b-hf/lukaemon_mmlu_college_chemistry,llama-7b-hf/lukaemon_mmlu_college_computer_science,llama-7b-hf/lukaemon_mmlu_college_mathematics,llama-7b-hf/lukaemon_mmlu_abstract_algebra,llama-7b-hf/lukaemon_mmlu_global_facts,llama-7b-hf/lukaemon_mmlu_computer_security,llama-7b-hf/lukaemon_mmlu_medical_genetics,llama-7b-hf/lukaemon_mmlu_high_school_computer_science,llama-7b-hf/lukaemon_mmlu_business_ethics,llama-7b-hf/lukaemon_mmlu_us_foreign_policy] fail, see
./outputs/default/20231112_015739/logs/infer/llama-7b-hf/lukaemon_mmlu_high_school_physics.out

100%|██████████| 4/4 [01:26<00:00, 21.80s/it]
100%|██████████| 4/4 [01:26<00:00, 21.56s/it]
11/12 01:59:06 - OpenCompass - ERROR - /home/hkustadmin/evaluation/opencompass/opencompass/runners/base.py - summarize - 63 - OpenICLInfer[llama-7b-hf/lukaemon_mmlu_professional_law_0] failed with code 1
11/12 01:59:06 - OpenCompass - ERROR - /home/hkustadmin/evaluation/opencompass/opencompass/runners/base.py - summarize - 63 - OpenICLInfer[llama-7b-hf/lukaemon_mmlu_professional_law_1] failed with code 1
11/12 01:59:06 - OpenCompass - ERROR - /home/hkustadmin/evaluation/opencompass/opencompass/runners/base.py - summarize - 63 - OpenICLInfer[llama-7b-hf/lukaemon_mmlu_moral_scenarios,llama-7b-hf/lukaemon_mmlu_miscellaneous,llama-7b-hf/lukaemon_mmlu_professional_psychology,llama-7b-hf/lukaemon_mmlu_high_school_psychology,llama-7b-hf/lukaemon_mmlu_high_school_macroeconomics,llama-7b-hf/lukaemon_mmlu_elementary_mathematics,llama-7b-hf/lukaemon_mmlu_moral_disputes,llama-7b-hf/lukaemon_mmlu_prehistory,llama-7b-hf/lukaemon_mmlu_philosophy,llama-7b-hf/lukaemon_mmlu_high_school_biology,llama-7b-hf/lukaemon_mmlu_nutrition,llama-7b-hf/lukaemon_mmlu_professional_accounting,llama-7b-hf/lukaemon_mmlu_professional_medicine,llama-7b-hf/lukaemon_mmlu_high_school_mathematics,llama-7b-hf/lukaemon_mmlu_clinical_knowledge,llama-7b-hf/lukaemon_mmlu_security_studies,llama-7b-hf/lukaemon_mmlu_high_school_microeconomics,llama-7b-hf/lukaemon_mmlu_high_school_world_history,llama-7b-hf/lukaemon_mmlu_conceptual_physics,llama-7b-hf/lukaemon_mmlu_marketing,llama-7b-hf/lukaemon_mmlu_human_aging,llama-7b-hf/lukaemon_mmlu_high_school_statistics,llama-7b-hf/lukaemon_mmlu_high_school_us_history,llama-7b-hf/lukaemon_mmlu_high_school_chemistry,llama-7b-hf/lukaemon_mmlu_sociology,llama-7b-hf/lukaemon_mmlu_high_school_geography,llama-7b-hf/lukaemon_mmlu_high_school_government_and_politics,llama-7b-hf/lukaemon_mmlu_college_medicine,llama-7b-hf/lukaemon_mmlu_world_religions,llama-7b-hf/lukaemon_mmlu_virology,llama-7b-hf/lukaemon_mmlu_high_school_european_history,llama-7b-hf/lukaemon_mmlu_logical_fallacies,llama-7b-hf/lukaemon_mmlu_astronomy] failed with code 1
11/12 01:59:06 - OpenCompass - ERROR - /home/hkustadmin/evaluation/opencompass/opencompass/runners/base.py - summarize - 63 - OpenICLInfer[llama-7b-hf/lukaemon_mmlu_high_school_physics,llama-7b-hf/lukaemon_mmlu_electrical_engineering,llama-7b-hf/lukaemon_mmlu_college_biology,llama-7b-hf/lukaemon_mmlu_anatomy,llama-7b-hf/lukaemon_mmlu_human_sexuality,llama-7b-hf/lukaemon_mmlu_formal_logic,llama-7b-hf/lukaemon_mmlu_international_law,llama-7b-hf/lukaemon_mmlu_econometrics,llama-7b-hf/lukaemon_mmlu_machine_learning,llama-7b-hf/lukaemon_mmlu_public_relations,llama-7b-hf/lukaemon_mmlu_jurisprudence,llama-7b-hf/lukaemon_mmlu_management,llama-7b-hf/lukaemon_mmlu_college_physics,llama-7b-hf/lukaemon_mmlu_college_chemistry,llama-7b-hf/lukaemon_mmlu_college_computer_science,llama-7b-hf/lukaemon_mmlu_college_mathematics,llama-7b-hf/lukaemon_mmlu_abstract_algebra,llama-7b-hf/lukaemon_mmlu_global_facts,llama-7b-hf/lukaemon_mmlu_computer_security,llama-7b-hf/lukaemon_mmlu_medical_genetics,llama-7b-hf/lukaemon_mmlu_high_school_computer_science,llama-7b-hf/lukaemon_mmlu_business_ethics,llama-7b-hf/lukaemon_mmlu_us_foreign_policy] failed with code 1
11/12 01:59:06 - OpenCompass - INFO - Partitioned into 57 tasks.

  0%|          | 0/57 [00:00<?, ?it/s]
                                      

  0%|          | 0/57 [00:00<?, ?it/s]
                                      

  0%|          | 0/57 [00:00<?, ?it/s]
                                      

  0%|          | 0/57 [00:00<?, ?it/s]
                                      

  0%|          | 0/57 [00:00<?, ?it/s]
                                      

  0%|          | 0/57 [00:00<?, ?it/s]
                                      

  0%|          | 0/57 [00:00<?, ?it/s]
                                      

  0%|          | 0/57 [00:00<?, ?it/s]
                                      

  0%|          | 0/57 [00:00<?, ?it/s]
                                      

  0%|          | 0/57 [00:01<?, ?it/s]
                                      

  0%|          | 0/57 [00:01<?, ?it/s]
                                      

  0%|          | 0/57 [00:02<?, ?it/s]
                                      

  0%|          | 0/57 [00:03<?, ?it/s]
                                      

  0%|          | 0/57 [00:03<?, ?it/s]
                                      

  0%|          | 0/57 [00:03<?, ?it/s]
                                      

  0%|          | 0/57 [00:04<?, ?it/s]
                                      

  0%|          | 0/57 [00:05<?, ?it/s]
                                      

  0%|          | 0/57 [00:07<?, ?it/s]
                                      

  0%|          | 0/57 [00:09<?, ?it/s]
                                      

  0%|          | 0/57 [00:09<?, ?it/s]
                                      

  0%|          | 0/57 [00:11<?, ?it/s]
                                      

  0%|          | 0/57 [00:12<?, ?it/s]
                                      

  0%|          | 0/57 [00:13<?, ?it/s]
                                      

  0%|          | 0/57 [00:13<?, ?it/s]
                                      

  0%|          | 0/57 [00:15<?, ?it/s]
                                      

  0%|          | 0/57 [00:16<?, ?it/s]
                                      

  0%|          | 0/57 [00:17<?, ?it/s]
                                      

  2%|▏         | 1/57 [00:18<17:07, 18.34s/it]
                                              

  2%|▏         | 1/57 [00:19<17:07, 18.34s/it]
                                              

  5%|▌         | 3/57 [00:20<07:56,  8.82s/it]
                                              

  5%|▌         | 3/57 [00:20<07:56,  8.82s/it]
                                              

  5%|▌         | 3/57 [00:21<07:56,  8.82s/it]
                                              

  5%|▌         | 3/57 [00:21<07:56,  8.82s/it]
  7%|▋         | 4/57 [00:22<06:08,  6.96s/it]
  7%|▋         | 4/57 [00:22<06:08,  6.96s/it]
  9%|▉         | 5/57 [00:22<05:36,  6.48s/it]
  9%|▉         | 5/57 [00:22<05:36,  6.48s/it]
                                              

  9%|▉         | 5/57 [00:22<05:36,  6.48s/it]
  9%|▉         | 5/57 [00:23<05:36,  6.48s/it]
                                              

  9%|▉         | 5/57 [00:23<05:36,  6.48s/it]
                                              

 12%|█▏        | 7/57 [00:23<03:11,  3.84s/it]
                                              

 12%|█▏        | 7/57 [00:25<03:11,  3.84s/it]
                                              

 18%|█▊        | 10/57 [00:25<00:59,  1.26s/it]
 18%|█▊        | 10/57 [00:26<00:59,  1.26s/it]
 18%|█▊        | 10/57 [00:26<00:59,  1.26s/it]
 19%|█▉        | 11/57 [00:27<01:13,  1.60s/it]
 21%|██        | 12/57 [00:28<01:21,  1.80s/it]
 23%|██▎       | 13/57 [00:28<01:29,  2.02s/it]
                                               

 25%|██▍       | 14/57 [00:28<01:37,  2.26s/it]
                                               

 25%|██▍       | 14/57 [00:29<01:37,  2.26s/it]
 25%|██▍       | 14/57 [00:29<01:37,  2.26s/it]
                                               

 25%|██▍       | 14/57 [00:30<01:37,  2.26s/it]
 25%|██▍       | 14/57 [00:31<01:37,  2.26s/it]
                                               

 26%|██▋       | 15/57 [00:32<01:50,  2.63s/it]
 26%|██▋       | 15/57 [00:32<01:50,  2.63s/it]
                                               

 26%|██▋       | 15/57 [00:33<01:50,  2.63s/it]
 26%|██▋       | 15/57 [00:33<01:50,  2.63s/it]
                                               

 26%|██▋       | 15/57 [00:34<01:50,  2.63s/it]
                                               

 26%|██▋       | 15/57 [00:35<01:50,  2.63s/it]
 26%|██▋       | 15/57 [00:36<01:50,  2.63s/it]
                                               

 26%|██▋       | 15/57 [00:37<01:50,  2.63s/it]
                                               

 26%|██▋       | 15/57 [00:38<01:50,  2.63s/it]
                                               

 28%|██▊       | 16/57 [00:39<02:27,  3.59s/it]
 28%|██▊       | 16/57 [00:39<02:27,  3.59s/it]
                                               

 28%|██▊       | 16/57 [00:39<02:27,  3.59s/it]
 30%|██▉       | 17/57 [00:44<02:43,  4.08s/it]
                                               

 30%|██▉       | 17/57 [00:45<02:43,  4.08s/it]
 32%|███▏      | 18/57 [00:48<02:40,  4.12s/it]
                                               

 32%|███▏      | 18/57 [00:49<02:40,  4.12s/it]
 33%|███▎      | 19/57 [00:50<02:02,  3.24s/it]
                                               

 33%|███▎      | 19/57 [00:51<02:02,  3.24s/it]
 35%|███▌      | 20/57 [00:54<02:12,  3.59s/it]
 39%|███▊      | 22/57 [00:54<01:20,  2.31s/it]
 40%|████      | 23/57 [00:54<01:06,  1.95s/it]
                                               

 40%|████      | 23/57 [00:56<01:06,  1.95s/it]
                                               

 46%|████▌     | 26/57 [00:56<00:40,  1.29s/it]
 46%|████▌     | 26/57 [00:57<00:40,  1.29s/it]
                                               

 46%|████▌     | 26/57 [00:58<00:40,  1.29s/it]
 46%|████▌     | 26/57 [00:58<00:40,  1.29s/it]
 46%|████▌     | 26/57 [00:58<00:40,  1.29s/it]
 46%|████▌     | 26/57 [00:59<00:40,  1.29s/it]
                                               

 46%|████▌     | 26/57 [00:59<00:40,  1.29s/it]
                                               

 46%|████▌     | 26/57 [00:59<00:40,  1.29s/it]
                                               

 46%|████▌     | 26/57 [01:00<00:40,  1.29s/it]
 47%|████▋     | 27/57 [01:02<01:02,  2.09s/it]
 49%|████▉     | 28/57 [01:04<00:57,  1.97s/it]
 51%|█████     | 29/57 [01:04<00:42,  1.53s/it]
 53%|█████▎    | 30/57 [01:05<00:39,  1.47s/it]
 54%|█████▍    | 31/57 [01:05<00:32,  1.26s/it]
 56%|█████▌    | 32/57 [01:07<00:35,  1.42s/it]
 58%|█████▊    | 33/57 [01:08<00:32,  1.34s/it]
 60%|█████▉    | 34/57 [01:09<00:27,  1.18s/it]
 61%|██████▏   | 35/57 [01:10<00:22,  1.01s/it]
 63%|██████▎   | 36/57 [01:10<00:16,  1.24it/s]
 65%|██████▍   | 37/57 [01:11<00:14,  1.35it/s]
 67%|██████▋   | 38/57 [01:11<00:14,  1.32it/s]
 68%|██████▊   | 39/57 [01:12<00:10,  1.65it/s]
 70%|███████   | 40/57 [01:14<00:18,  1.06s/it]
 72%|███████▏  | 41/57 [01:16<00:22,  1.38s/it]
 74%|███████▎  | 42/57 [01:16<00:15,  1.05s/it]
 75%|███████▌  | 43/57 [01:18<00:15,  1.14s/it]
 77%|███████▋  | 44/57 [01:18<00:10,  1.18it/s]
 79%|███████▉  | 45/57 [01:18<00:08,  1.45it/s]
 81%|████████  | 46/57 [01:19<00:07,  1.57it/s]
 82%|████████▏ | 47/57 [01:20<00:06,  1.44it/s]
 84%|████████▍ | 48/57 [01:22<00:10,  1.18s/it]
 86%|████████▌ | 49/57 [01:22<00:07,  1.08it/s]
 89%|████████▉ | 51/57 [01:24<00:04,  1.21it/s]
 91%|█████████ | 52/57 [01:25<00:04,  1.05it/s]
 93%|█████████▎| 53/57 [01:25<00:03,  1.23it/s]
 96%|█████████▋| 55/57 [01:26<00:00,  2.01it/s]
100%|██████████| 57/57 [01:26<00:00,  3.02it/s]
100%|██████████| 57/57 [01:26<00:00,  1.51s/it]
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_college_biology] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_college_chemistry] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_college_computer_science] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_college_mathematics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_college_physics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_electrical_engineering] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_astronomy] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_anatomy] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_abstract_algebra] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_machine_learning] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_clinical_knowledge] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_global_facts] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_management] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_nutrition] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_marketing] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_professional_accounting] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_geography] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_international_law] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_moral_scenarios] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_computer_security] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_microeconomics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_professional_law] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_medical_genetics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_professional_psychology] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_jurisprudence] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_world_religions] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_philosophy] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_virology] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_chemistry] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_public_relations] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_macroeconomics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_human_sexuality] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_elementary_mathematics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_physics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_computer_science] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_european_history] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_business_ethics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_moral_disputes] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_statistics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_miscellaneous] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_formal_logic] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_government_and_politics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_prehistory] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_security_studies] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_biology] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_logical_fallacies] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_world_history] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_professional_medicine] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_mathematics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_college_medicine] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_us_history] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_sociology] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_econometrics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_psychology] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_human_aging] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_us_foreign_policy] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_conceptual_physics] on CPU 
dataset                       version    metric    mode    llama-7b-hf
----------------------------  ---------  --------  ------  -------------
------- MMLU details -------  -          -         -       -
mmlu-humanities               -          -         -       -
mmlu-stem                     -          -         -       -
mmlu-social-science           -          -         -       -
mmlu-other                    -          -         -       -
mmlu                          -          -         -       -
---- Standard Benchmarks ---  -          -         -       -
BoolQ                         -          -         -       -
piqa                          -          -         -       -
siqa                          -          -         -       -
hellaswag                     -          -         -       -
winogrande                    -          -         -       -
ARC-e                         -          -         -       -
ARC-c                         -          -         -       -
openbookqa_fact               -          -         -       -
commonsense_qa                -          -         -       -
mmlu                          -          -         -       -
------ Code Generation -----  -          -         -       -
openai_humaneval              -          -         -       -
mbpp                          -          -         -       -
------ World Knowledge -----  -          -         -       -
triviaqa                      -          -         -       -
--- Reading Comprehension --  -          -         -       -
squad2.0                      -          -         -       -
---------- Exams -----------  -          -         -       -
math                          -          -         -       -
gsm8k                         -          -         -       -
TheoremQA                     -          -         -       -
--------- Chinese ----------  -          -         -       -
ceval                         -          -         -       -
ceval-stem                    -          -         -       -
ceval-social-science          -          -         -       -
ceval-humanities              -          -         -       -
ceval-other                   -          -         -       -
ceval-hard                    -          -         -       -
ceval-test-stem               -          -         -       -
ceval-test-social-science     -          -         -       -
ceval-test-humanities         -          -         -       -
ceval-test-other              -          -         -       -
ceval-test-hard               -          -         -       -
ceval-test                    -          -         -       -
cmmlu                         -          -         -       -
cmmlu-humanities              -          -         -       -
cmmlu-stem                    -          -         -       -
cmmlu-social-science          -          -         -       -
cmmlu-other                   -          -         -       -
cmmlu-china-specific          -          -         -       -
11/12 02:00:32 - OpenCompass - INFO - write summary to /home/hkustadmin/evaluation/opencompass/outputs/default/20231112_015739/summary/summary_20231112_015739.txt
11/12 02:00:32 - OpenCompass - INFO - write csv to /home/hkustadmin/evaluation/opencompass/outputs/default/20231112_015739/summary/summary_20231112_015739.csv
11/12 02:01:33 - OpenCompass - WARNING - SlurmRunner is not used, so the partition argument is ignored.
11/12 02:01:33 - OpenCompass - WARNING - Key eval.runner.task.judge_cfg not found in config, ignored.
11/12 02:01:33 - OpenCompass - INFO - Partitioned into 4 tasks.

  0%|          | 0/4 [00:00<?, ?it/s]
                                     

  0%|          | 0/4 [00:00<?, ?it/s]launch OpenICLInfer[llama-7b-hf/lukaemon_mmlu_professional_law_0] on GPU 0,1,2,3,4,5,6,7
11/12 02:01:55 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/lukaemon_mmlu_professional_law_0] fail, see
./outputs/default/20231112_020133/logs/infer/llama-7b-hf/lukaemon_mmlu_professional_law_0.out

 25%|██▌       | 1/4 [00:21<01:05, 21.82s/it]
                                             

 25%|██▌       | 1/4 [00:22<01:05, 21.82s/it]launch OpenICLInfer[llama-7b-hf/lukaemon_mmlu_professional_law_1] on GPU 0,1,2,3,4,5,6,7
11/12 02:02:17 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/lukaemon_mmlu_professional_law_1] fail, see
./outputs/default/20231112_020133/logs/infer/llama-7b-hf/lukaemon_mmlu_professional_law_1.out

 50%|█████     | 2/4 [00:43<00:43, 21.91s/it]
                                             

 50%|█████     | 2/4 [00:44<00:43, 21.91s/it]launch OpenICLInfer[llama-7b-hf/lukaemon_mmlu_moral_scenarios,llama-7b-hf/lukaemon_mmlu_miscellaneous,llama-7b-hf/lukaemon_mmlu_professional_psychology,llama-7b-hf/lukaemon_mmlu_high_school_psychology,llama-7b-hf/lukaemon_mmlu_high_school_macroeconomics,llama-7b-hf/lukaemon_mmlu_elementary_mathematics,llama-7b-hf/lukaemon_mmlu_moral_disputes,llama-7b-hf/lukaemon_mmlu_prehistory,llama-7b-hf/lukaemon_mmlu_philosophy,llama-7b-hf/lukaemon_mmlu_high_school_biology,llama-7b-hf/lukaemon_mmlu_nutrition,llama-7b-hf/lukaemon_mmlu_professional_accounting,llama-7b-hf/lukaemon_mmlu_professional_medicine,llama-7b-hf/lukaemon_mmlu_high_school_mathematics,llama-7b-hf/lukaemon_mmlu_clinical_knowledge,llama-7b-hf/lukaemon_mmlu_security_studies,llama-7b-hf/lukaemon_mmlu_high_school_microeconomics,llama-7b-hf/lukaemon_mmlu_high_school_world_history,llama-7b-hf/lukaemon_mmlu_conceptual_physics,llama-7b-hf/lukaemon_mmlu_marketing,llama-7b-hf/lukaemon_mmlu_human_aging,llama-7b-hf/lukaemon_mmlu_high_school_statistics,llama-7b-hf/lukaemon_mmlu_high_school_us_history,llama-7b-hf/lukaemon_mmlu_high_school_chemistry,llama-7b-hf/lukaemon_mmlu_sociology,llama-7b-hf/lukaemon_mmlu_high_school_geography,llama-7b-hf/lukaemon_mmlu_high_school_government_and_politics,llama-7b-hf/lukaemon_mmlu_college_medicine,llama-7b-hf/lukaemon_mmlu_world_religions,llama-7b-hf/lukaemon_mmlu_virology,llama-7b-hf/lukaemon_mmlu_high_school_european_history,llama-7b-hf/lukaemon_mmlu_logical_fallacies,llama-7b-hf/lukaemon_mmlu_astronomy] on GPU 0,1,2,3,4,5,6,7
11/12 02:02:40 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/lukaemon_mmlu_moral_scenarios,llama-7b-hf/lukaemon_mmlu_miscellaneous,llama-7b-hf/lukaemon_mmlu_professional_psychology,llama-7b-hf/lukaemon_mmlu_high_school_psychology,llama-7b-hf/lukaemon_mmlu_high_school_macroeconomics,llama-7b-hf/lukaemon_mmlu_elementary_mathematics,llama-7b-hf/lukaemon_mmlu_moral_disputes,llama-7b-hf/lukaemon_mmlu_prehistory,llama-7b-hf/lukaemon_mmlu_philosophy,llama-7b-hf/lukaemon_mmlu_high_school_biology,llama-7b-hf/lukaemon_mmlu_nutrition,llama-7b-hf/lukaemon_mmlu_professional_accounting,llama-7b-hf/lukaemon_mmlu_professional_medicine,llama-7b-hf/lukaemon_mmlu_high_school_mathematics,llama-7b-hf/lukaemon_mmlu_clinical_knowledge,llama-7b-hf/lukaemon_mmlu_security_studies,llama-7b-hf/lukaemon_mmlu_high_school_microeconomics,llama-7b-hf/lukaemon_mmlu_high_school_world_history,llama-7b-hf/lukaemon_mmlu_conceptual_physics,llama-7b-hf/lukaemon_mmlu_marketing,llama-7b-hf/lukaemon_mmlu_human_aging,llama-7b-hf/lukaemon_mmlu_high_school_statistics,llama-7b-hf/lukaemon_mmlu_high_school_us_history,llama-7b-hf/lukaemon_mmlu_high_school_chemistry,llama-7b-hf/lukaemon_mmlu_sociology,llama-7b-hf/lukaemon_mmlu_high_school_geography,llama-7b-hf/lukaemon_mmlu_high_school_government_and_politics,llama-7b-hf/lukaemon_mmlu_college_medicine,llama-7b-hf/lukaemon_mmlu_world_religions,llama-7b-hf/lukaemon_mmlu_virology,llama-7b-hf/lukaemon_mmlu_high_school_european_history,llama-7b-hf/lukaemon_mmlu_logical_fallacies,llama-7b-hf/lukaemon_mmlu_astronomy] fail, see
./outputs/default/20231112_020133/logs/infer/llama-7b-hf/lukaemon_mmlu_moral_scenarios.out

 75%|███████▌  | 3/4 [01:07<00:22, 22.55s/it]
                                             

 75%|███████▌  | 3/4 [01:08<00:22, 22.55s/it]launch OpenICLInfer[llama-7b-hf/lukaemon_mmlu_high_school_physics,llama-7b-hf/lukaemon_mmlu_electrical_engineering,llama-7b-hf/lukaemon_mmlu_college_biology,llama-7b-hf/lukaemon_mmlu_anatomy,llama-7b-hf/lukaemon_mmlu_human_sexuality,llama-7b-hf/lukaemon_mmlu_formal_logic,llama-7b-hf/lukaemon_mmlu_international_law,llama-7b-hf/lukaemon_mmlu_econometrics,llama-7b-hf/lukaemon_mmlu_machine_learning,llama-7b-hf/lukaemon_mmlu_public_relations,llama-7b-hf/lukaemon_mmlu_jurisprudence,llama-7b-hf/lukaemon_mmlu_management,llama-7b-hf/lukaemon_mmlu_college_physics,llama-7b-hf/lukaemon_mmlu_college_chemistry,llama-7b-hf/lukaemon_mmlu_college_computer_science,llama-7b-hf/lukaemon_mmlu_college_mathematics,llama-7b-hf/lukaemon_mmlu_abstract_algebra,llama-7b-hf/lukaemon_mmlu_global_facts,llama-7b-hf/lukaemon_mmlu_computer_security,llama-7b-hf/lukaemon_mmlu_medical_genetics,llama-7b-hf/lukaemon_mmlu_high_school_computer_science,llama-7b-hf/lukaemon_mmlu_business_ethics,llama-7b-hf/lukaemon_mmlu_us_foreign_policy] on GPU 0,1,2,3,4,5,6,7
11/12 02:03:04 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/lukaemon_mmlu_high_school_physics,llama-7b-hf/lukaemon_mmlu_electrical_engineering,llama-7b-hf/lukaemon_mmlu_college_biology,llama-7b-hf/lukaemon_mmlu_anatomy,llama-7b-hf/lukaemon_mmlu_human_sexuality,llama-7b-hf/lukaemon_mmlu_formal_logic,llama-7b-hf/lukaemon_mmlu_international_law,llama-7b-hf/lukaemon_mmlu_econometrics,llama-7b-hf/lukaemon_mmlu_machine_learning,llama-7b-hf/lukaemon_mmlu_public_relations,llama-7b-hf/lukaemon_mmlu_jurisprudence,llama-7b-hf/lukaemon_mmlu_management,llama-7b-hf/lukaemon_mmlu_college_physics,llama-7b-hf/lukaemon_mmlu_college_chemistry,llama-7b-hf/lukaemon_mmlu_college_computer_science,llama-7b-hf/lukaemon_mmlu_college_mathematics,llama-7b-hf/lukaemon_mmlu_abstract_algebra,llama-7b-hf/lukaemon_mmlu_global_facts,llama-7b-hf/lukaemon_mmlu_computer_security,llama-7b-hf/lukaemon_mmlu_medical_genetics,llama-7b-hf/lukaemon_mmlu_high_school_computer_science,llama-7b-hf/lukaemon_mmlu_business_ethics,llama-7b-hf/lukaemon_mmlu_us_foreign_policy] fail, see
./outputs/default/20231112_020133/logs/infer/llama-7b-hf/lukaemon_mmlu_high_school_physics.out

100%|██████████| 4/4 [01:30<00:00, 22.89s/it]
100%|██████████| 4/4 [01:30<00:00, 22.63s/it]
11/12 02:03:04 - OpenCompass - ERROR - /home/hkustadmin/evaluation/opencompass/opencompass/runners/base.py - summarize - 63 - OpenICLInfer[llama-7b-hf/lukaemon_mmlu_professional_law_0] failed with code 1
11/12 02:03:04 - OpenCompass - ERROR - /home/hkustadmin/evaluation/opencompass/opencompass/runners/base.py - summarize - 63 - OpenICLInfer[llama-7b-hf/lukaemon_mmlu_professional_law_1] failed with code 1
11/12 02:03:04 - OpenCompass - ERROR - /home/hkustadmin/evaluation/opencompass/opencompass/runners/base.py - summarize - 63 - OpenICLInfer[llama-7b-hf/lukaemon_mmlu_moral_scenarios,llama-7b-hf/lukaemon_mmlu_miscellaneous,llama-7b-hf/lukaemon_mmlu_professional_psychology,llama-7b-hf/lukaemon_mmlu_high_school_psychology,llama-7b-hf/lukaemon_mmlu_high_school_macroeconomics,llama-7b-hf/lukaemon_mmlu_elementary_mathematics,llama-7b-hf/lukaemon_mmlu_moral_disputes,llama-7b-hf/lukaemon_mmlu_prehistory,llama-7b-hf/lukaemon_mmlu_philosophy,llama-7b-hf/lukaemon_mmlu_high_school_biology,llama-7b-hf/lukaemon_mmlu_nutrition,llama-7b-hf/lukaemon_mmlu_professional_accounting,llama-7b-hf/lukaemon_mmlu_professional_medicine,llama-7b-hf/lukaemon_mmlu_high_school_mathematics,llama-7b-hf/lukaemon_mmlu_clinical_knowledge,llama-7b-hf/lukaemon_mmlu_security_studies,llama-7b-hf/lukaemon_mmlu_high_school_microeconomics,llama-7b-hf/lukaemon_mmlu_high_school_world_history,llama-7b-hf/lukaemon_mmlu_conceptual_physics,llama-7b-hf/lukaemon_mmlu_marketing,llama-7b-hf/lukaemon_mmlu_human_aging,llama-7b-hf/lukaemon_mmlu_high_school_statistics,llama-7b-hf/lukaemon_mmlu_high_school_us_history,llama-7b-hf/lukaemon_mmlu_high_school_chemistry,llama-7b-hf/lukaemon_mmlu_sociology,llama-7b-hf/lukaemon_mmlu_high_school_geography,llama-7b-hf/lukaemon_mmlu_high_school_government_and_politics,llama-7b-hf/lukaemon_mmlu_college_medicine,llama-7b-hf/lukaemon_mmlu_world_religions,llama-7b-hf/lukaemon_mmlu_virology,llama-7b-hf/lukaemon_mmlu_high_school_european_history,llama-7b-hf/lukaemon_mmlu_logical_fallacies,llama-7b-hf/lukaemon_mmlu_astronomy] failed with code 1
11/12 02:03:04 - OpenCompass - ERROR - /home/hkustadmin/evaluation/opencompass/opencompass/runners/base.py - summarize - 63 - OpenICLInfer[llama-7b-hf/lukaemon_mmlu_high_school_physics,llama-7b-hf/lukaemon_mmlu_electrical_engineering,llama-7b-hf/lukaemon_mmlu_college_biology,llama-7b-hf/lukaemon_mmlu_anatomy,llama-7b-hf/lukaemon_mmlu_human_sexuality,llama-7b-hf/lukaemon_mmlu_formal_logic,llama-7b-hf/lukaemon_mmlu_international_law,llama-7b-hf/lukaemon_mmlu_econometrics,llama-7b-hf/lukaemon_mmlu_machine_learning,llama-7b-hf/lukaemon_mmlu_public_relations,llama-7b-hf/lukaemon_mmlu_jurisprudence,llama-7b-hf/lukaemon_mmlu_management,llama-7b-hf/lukaemon_mmlu_college_physics,llama-7b-hf/lukaemon_mmlu_college_chemistry,llama-7b-hf/lukaemon_mmlu_college_computer_science,llama-7b-hf/lukaemon_mmlu_college_mathematics,llama-7b-hf/lukaemon_mmlu_abstract_algebra,llama-7b-hf/lukaemon_mmlu_global_facts,llama-7b-hf/lukaemon_mmlu_computer_security,llama-7b-hf/lukaemon_mmlu_medical_genetics,llama-7b-hf/lukaemon_mmlu_high_school_computer_science,llama-7b-hf/lukaemon_mmlu_business_ethics,llama-7b-hf/lukaemon_mmlu_us_foreign_policy] failed with code 1
11/12 02:03:04 - OpenCompass - INFO - Partitioned into 57 tasks.

  0%|          | 0/57 [00:00<?, ?it/s]
                                      

  0%|          | 0/57 [00:00<?, ?it/s]
                                      

  0%|          | 0/57 [00:00<?, ?it/s]
                                      

  0%|          | 0/57 [00:00<?, ?it/s]
                                      

  0%|          | 0/57 [00:00<?, ?it/s]
                                      

  0%|          | 0/57 [00:00<?, ?it/s]
                                      

  0%|          | 0/57 [00:00<?, ?it/s]
                                      

  0%|          | 0/57 [00:01<?, ?it/s]
                                      

  0%|          | 0/57 [00:01<?, ?it/s]
                                      

  0%|          | 0/57 [00:01<?, ?it/s]
                                      

  0%|          | 0/57 [00:01<?, ?it/s]
                                      

  0%|          | 0/57 [00:02<?, ?it/s]
                                      

  0%|          | 0/57 [00:02<?, ?it/s]
                                      

  0%|          | 0/57 [00:03<?, ?it/s]
                                      

  0%|          | 0/57 [00:03<?, ?it/s]
                                      

  0%|          | 0/57 [00:03<?, ?it/s]
                                      

  0%|          | 0/57 [00:04<?, ?it/s]
                                      

  0%|          | 0/57 [00:05<?, ?it/s]
                                      

  0%|          | 0/57 [00:06<?, ?it/s]
                                      

  0%|          | 0/57 [00:06<?, ?it/s]
                                      

  0%|          | 0/57 [00:07<?, ?it/s]
                                      

  0%|          | 0/57 [00:07<?, ?it/s]
                                      

  0%|          | 0/57 [00:08<?, ?it/s]
                                      

  0%|          | 0/57 [00:09<?, ?it/s]
                                      

  0%|          | 0/57 [00:09<?, ?it/s]
                                      

  0%|          | 0/57 [00:11<?, ?it/s]
                                      

  0%|          | 0/57 [00:11<?, ?it/s]
                                      

  0%|          | 0/57 [00:12<?, ?it/s]
                                      

  0%|          | 0/57 [00:13<?, ?it/s]
                                      

  0%|          | 0/57 [00:14<?, ?it/s]
                                      

  0%|          | 0/57 [00:15<?, ?it/s]
                                      

  0%|          | 0/57 [00:16<?, ?it/s]
                                      

  0%|          | 0/57 [00:17<?, ?it/s]
  2%|▏         | 1/57 [00:24<23:18, 24.98s/it]
                                              

  2%|▏         | 1/57 [00:25<23:18, 24.98s/it]
  4%|▎         | 2/57 [00:25<09:43, 10.62s/it]
                                              

  5%|▌         | 3/57 [00:26<05:27,  6.06s/it]
  7%|▋         | 4/57 [00:26<02:32,  2.87s/it]
  9%|▉         | 5/57 [00:27<01:57,  2.26s/it]
                                              

 11%|█         | 6/57 [00:27<01:13,  1.45s/it]
 11%|█         | 6/57 [00:27<01:13,  1.45s/it]
 11%|█         | 6/57 [00:27<01:13,  1.45s/it]
                                              

 14%|█▍        | 8/57 [00:28<01:01,  1.25s/it]
                                              

 16%|█▌        | 9/57 [00:30<01:06,  1.39s/it]
 18%|█▊        | 10/57 [00:30<00:57,  1.23s/it]
                                               

 18%|█▊        | 10/57 [00:31<00:57,  1.23s/it]
 18%|█▊        | 10/57 [00:31<00:57,  1.23s/it]
 18%|█▊        | 10/57 [00:32<00:57,  1.23s/it]
 18%|█▊        | 10/57 [00:32<00:57,  1.23s/it]
                                               

 18%|█▊        | 10/57 [00:33<00:57,  1.23s/it]
                                               

 19%|█▉        | 11/57 [00:34<01:17,  1.67s/it]
                                               

 19%|█▉        | 11/57 [00:35<01:17,  1.67s/it]
                                               

 19%|█▉        | 11/57 [00:37<01:17,  1.67s/it]
 19%|█▉        | 11/57 [00:37<01:17,  1.67s/it]
                                               

 19%|█▉        | 11/57 [00:37<01:17,  1.67s/it]
 23%|██▎       | 13/57 [00:38<01:31,  2.08s/it]
 23%|██▎       | 13/57 [00:38<01:31,  2.08s/it]
                                               

 23%|██▎       | 13/57 [00:40<01:31,  2.08s/it]
                                               

 23%|██▎       | 13/57 [00:40<01:31,  2.08s/it]
 25%|██▍       | 14/57 [00:42<01:53,  2.64s/it]
                                               

 26%|██▋       | 15/57 [00:43<01:30,  2.15s/it]
 26%|██▋       | 15/57 [00:43<01:30,  2.15s/it]
                                               

 28%|██▊       | 16/57 [00:44<01:13,  1.80s/it]
 30%|██▉       | 17/57 [00:44<00:53,  1.33s/it]
 30%|██▉       | 17/57 [00:44<00:53,  1.33s/it]
                                               

 30%|██▉       | 17/57 [00:45<00:53,  1.33s/it]
                                               

 30%|██▉       | 17/57 [00:45<00:53,  1.33s/it]
 32%|███▏      | 18/57 [00:48<01:18,  2.00s/it]
                                               

 35%|███▌      | 20/57 [00:49<00:38,  1.05s/it]
 35%|███▌      | 20/57 [00:49<00:38,  1.05s/it]
 35%|███▌      | 20/57 [00:50<00:38,  1.05s/it]
                                               

 37%|███▋      | 21/57 [00:50<00:37,  1.05s/it]
 37%|███▋      | 21/57 [00:51<00:37,  1.05s/it]
                                               

 39%|███▊      | 22/57 [00:51<00:36,  1.04s/it]
                                               

 39%|███▊      | 22/57 [00:52<00:36,  1.04s/it]
 39%|███▊      | 22/57 [00:53<00:36,  1.04s/it]
                                               

 40%|████      | 23/57 [00:54<00:49,  1.44s/it]
 42%|████▏     | 24/57 [00:55<00:50,  1.54s/it]
 44%|████▍     | 25/57 [00:55<00:48,  1.52s/it]
                                               

 44%|████▍     | 25/57 [00:56<00:48,  1.52s/it]
 44%|████▍     | 25/57 [00:56<00:48,  1.52s/it]
                                               

 44%|████▍     | 25/57 [00:57<00:48,  1.52s/it]
                                               

 44%|████▍     | 25/57 [00:59<00:48,  1.52s/it]
 46%|████▌     | 26/57 [01:00<01:11,  2.31s/it]
 47%|████▋     | 27/57 [01:01<00:59,  1.97s/it]
 49%|████▉     | 28/57 [01:01<00:45,  1.56s/it]
 51%|█████     | 29/57 [01:05<01:04,  2.29s/it]
 53%|█████▎    | 30/57 [01:07<00:56,  2.10s/it]
 56%|█████▌    | 32/57 [01:08<00:30,  1.24s/it]
 56%|█████▌    | 32/57 [01:08<00:30,  1.24s/it]
 58%|█████▊    | 33/57 [01:12<00:55,  2.31s/it]
 60%|█████▉    | 34/57 [01:13<00:39,  1.73s/it]
 61%|██████▏   | 35/57 [01:13<00:28,  1.30s/it]
 63%|██████▎   | 36/57 [01:14<00:23,  1.14s/it]
 65%|██████▍   | 37/57 [01:16<00:28,  1.42s/it]
 67%|██████▋   | 38/57 [01:18<00:29,  1.58s/it]
 68%|██████▊   | 39/57 [01:18<00:21,  1.21s/it]
 70%|███████   | 40/57 [01:19<00:20,  1.20s/it]
 72%|███████▏  | 41/57 [01:21<00:22,  1.40s/it]
 74%|███████▎  | 42/57 [01:21<00:16,  1.13s/it]
 75%|███████▌  | 43/57 [01:22<00:13,  1.06it/s]
 77%|███████▋  | 44/57 [01:23<00:11,  1.16it/s]
 79%|███████▉  | 45/57 [01:23<00:07,  1.53it/s]
 81%|████████  | 46/57 [01:23<00:05,  1.93it/s]
 82%|████████▏ | 47/57 [01:24<00:05,  1.95it/s]
 84%|████████▍ | 48/57 [01:24<00:05,  1.53it/s]
 89%|████████▉ | 51/57 [01:25<00:02,  2.63it/s]
 91%|█████████ | 52/57 [01:26<00:02,  2.25it/s]
 93%|█████████▎| 53/57 [01:26<00:01,  2.73it/s]
 95%|█████████▍| 54/57 [01:26<00:01,  2.35it/s]
 96%|█████████▋| 55/57 [01:27<00:00,  2.32it/s]
100%|██████████| 57/57 [01:27<00:00,  3.69it/s]
100%|██████████| 57/57 [01:27<00:00,  1.53s/it]
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_college_biology] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_college_chemistry] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_college_computer_science] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_college_mathematics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_college_physics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_electrical_engineering] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_astronomy] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_anatomy] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_abstract_algebra] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_machine_learning] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_clinical_knowledge] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_global_facts] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_management] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_nutrition] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_marketing] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_professional_accounting] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_geography] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_international_law] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_moral_scenarios] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_computer_security] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_microeconomics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_professional_law] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_medical_genetics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_professional_psychology] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_jurisprudence] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_world_religions] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_philosophy] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_virology] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_chemistry] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_public_relations] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_macroeconomics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_human_sexuality] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_elementary_mathematics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_physics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_computer_science] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_european_history] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_business_ethics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_moral_disputes] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_statistics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_miscellaneous] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_formal_logic] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_government_and_politics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_prehistory] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_security_studies] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_biology] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_logical_fallacies] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_world_history] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_professional_medicine] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_mathematics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_college_medicine] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_us_history] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_sociology] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_econometrics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_psychology] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_human_aging] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_us_foreign_policy] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_conceptual_physics] on CPU 
dataset                       version    metric    mode    llama-7b-hf
----------------------------  ---------  --------  ------  -------------
------- MMLU details -------  -          -         -       -
mmlu-humanities               -          -         -       -
mmlu-stem                     -          -         -       -
mmlu-social-science           -          -         -       -
mmlu-other                    -          -         -       -
mmlu                          -          -         -       -
11/12 02:04:31 - OpenCompass - INFO - write summary to /home/hkustadmin/evaluation/opencompass/outputs/default/20231112_020133/summary/summary_20231112_020133.txt
11/12 02:04:31 - OpenCompass - INFO - write csv to /home/hkustadmin/evaluation/opencompass/outputs/default/20231112_020133/summary/summary_20231112_020133.csv
11/12 19:03:53 - OpenCompass - WARNING - SlurmRunner is not used, so the partition argument is ignored.
Traceback (most recent call last):
  File "/home/hkustadmin/evaluation/opencompass/run.py", line 342, in <module>
    main()
  File "/home/hkustadmin/evaluation/opencompass/run.py", line 285, in main
    tasks = partitioner(cfg)
  File "/home/hkustadmin/evaluation/opencompass/opencompass/partitioners/base.py", line 77, in __call__
    tasks = self.partition(models,
  File "/home/hkustadmin/evaluation/opencompass/opencompass/partitioners/size.py", line 87, in partition
    datasets = sorted(datasets,
  File "/home/hkustadmin/evaluation/opencompass/opencompass/partitioners/size.py", line 88, in <lambda>
    key=lambda x: self.get_cost(x),
  File "/home/hkustadmin/evaluation/opencompass/opencompass/partitioners/size.py", line 211, in get_cost
    dataset = build_dataset_from_cfg(dataset)
  File "/home/hkustadmin/evaluation/opencompass/opencompass/utils/build.py", line 13, in build_dataset_from_cfg
    return LOAD_DATASET.build(dataset_cfg)
  File "/home/hkustadmin/miniconda3/envs/opencompass/lib/python3.10/site-packages/mmengine/registry/registry.py", line 570, in build
    return self.build_func(cfg, *args, **kwargs, registry=self)
  File "/home/hkustadmin/miniconda3/envs/opencompass/lib/python3.10/site-packages/mmengine/registry/build_functions.py", line 121, in build_from_cfg
    obj = obj_cls(**args)  # type: ignore
  File "/home/hkustadmin/evaluation/opencompass/opencompass/datasets/base.py", line 12, in __init__
    self.dataset = self.load(**kwargs)
  File "/home/hkustadmin/evaluation/opencompass/opencompass/datasets/boolq.py", line 48, in load
    with open(path, 'r') as f:
FileNotFoundError: [Errno 2] No such file or directory: './data/SuperGLUE/BoolQ/val.jsonl'
11/12 19:18:17 - OpenCompass - WARNING - SlurmRunner is not used, so the partition argument is ignored.
11/12 19:18:17 - OpenCompass - INFO - Partitioned into 4 tasks.

  0%|          | 0/4 [00:00<?, ?it/s]
                                     

  0%|          | 0/4 [00:00<?, ?it/s]launch OpenICLInfer[llama-7b-hf/lukaemon_mmlu_professional_law_0] on GPU 0,1,2,3,4,5,6,7
11/12 19:24:09 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/lukaemon_mmlu_professional_law_0] fail, see
./outputs/default/20231112_191817/logs/infer/llama-7b-hf/lukaemon_mmlu_professional_law_0.out
 25%|██▌       | 1/4 [05:52<17:36, 352.11s/it]                                               25%|██▌       | 1/4 [05:52<17:36, 352.11s/it]launch OpenICLInfer[llama-7b-hf/lukaemon_mmlu_moral_scenarios,llama-7b-hf/lukaemon_mmlu_miscellaneous,llama-7b-hf/lukaemon_mmlu_professional_psychology,llama-7b-hf/lukaemon_mmlu_high_school_psychology,llama-7b-hf/lukaemon_mmlu_high_school_macroeconomics,llama-7b-hf/lukaemon_mmlu_elementary_mathematics,llama-7b-hf/lukaemon_mmlu_moral_disputes,llama-7b-hf/lukaemon_mmlu_prehistory,llama-7b-hf/lukaemon_mmlu_philosophy,llama-7b-hf/lukaemon_mmlu_high_school_biology,llama-7b-hf/lukaemon_mmlu_nutrition,llama-7b-hf/lukaemon_mmlu_professional_accounting,llama-7b-hf/lukaemon_mmlu_professional_medicine,llama-7b-hf/lukaemon_mmlu_high_school_mathematics,llama-7b-hf/lukaemon_mmlu_clinical_knowledge,llama-7b-hf/lukaemon_mmlu_security_studies,llama-7b-hf/lukaemon_mmlu_high_school_microeconomics,llama-7b-hf/lukaemon_mmlu_high_school_world_history,llama-7b-hf/lukaemon_mmlu_conceptual_physics,llama-7b-hf/lukaemon_mmlu_marketing,llama-7b-hf/lukaemon_mmlu_human_aging,llama-7b-hf/lukaemon_mmlu_high_school_statistics,llama-7b-hf/lukaemon_mmlu_high_school_us_history,llama-7b-hf/lukaemon_mmlu_high_school_chemistry,llama-7b-hf/lukaemon_mmlu_sociology,llama-7b-hf/lukaemon_mmlu_high_school_geography,llama-7b-hf/lukaemon_mmlu_high_school_government_and_politics,llama-7b-hf/lukaemon_mmlu_college_medicine,llama-7b-hf/lukaemon_mmlu_world_religions,llama-7b-hf/lukaemon_mmlu_virology,llama-7b-hf/lukaemon_mmlu_high_school_european_history,llama-7b-hf/lukaemon_mmlu_logical_fallacies,llama-7b-hf/lukaemon_mmlu_astronomy] on GPU 0,1,2,3,4,5,6,7
11/12 20:20:03 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/lukaemon_mmlu_moral_scenarios,llama-7b-hf/lukaemon_mmlu_miscellaneous,llama-7b-hf/lukaemon_mmlu_professional_psychology,llama-7b-hf/lukaemon_mmlu_high_school_psychology,llama-7b-hf/lukaemon_mmlu_high_school_macroeconomics,llama-7b-hf/lukaemon_mmlu_elementary_mathematics,llama-7b-hf/lukaemon_mmlu_moral_disputes,llama-7b-hf/lukaemon_mmlu_prehistory,llama-7b-hf/lukaemon_mmlu_philosophy,llama-7b-hf/lukaemon_mmlu_high_school_biology,llama-7b-hf/lukaemon_mmlu_nutrition,llama-7b-hf/lukaemon_mmlu_professional_accounting,llama-7b-hf/lukaemon_mmlu_professional_medicine,llama-7b-hf/lukaemon_mmlu_high_school_mathematics,llama-7b-hf/lukaemon_mmlu_clinical_knowledge,llama-7b-hf/lukaemon_mmlu_security_studies,llama-7b-hf/lukaemon_mmlu_high_school_microeconomics,llama-7b-hf/lukaemon_mmlu_high_school_world_history,llama-7b-hf/lukaemon_mmlu_conceptual_physics,llama-7b-hf/lukaemon_mmlu_marketing,llama-7b-hf/lukaemon_mmlu_human_aging,llama-7b-hf/lukaemon_mmlu_high_school_statistics,llama-7b-hf/lukaemon_mmlu_high_school_us_history,llama-7b-hf/lukaemon_mmlu_high_school_chemistry,llama-7b-hf/lukaemon_mmlu_sociology,llama-7b-hf/lukaemon_mmlu_high_school_geography,llama-7b-hf/lukaemon_mmlu_high_school_government_and_politics,llama-7b-hf/lukaemon_mmlu_college_medicine,llama-7b-hf/lukaemon_mmlu_world_religions,llama-7b-hf/lukaemon_mmlu_virology,llama-7b-hf/lukaemon_mmlu_high_school_european_history,llama-7b-hf/lukaemon_mmlu_logical_fallacies,llama-7b-hf/lukaemon_mmlu_astronomy] fail, see
./outputs/default/20231112_191817/logs/infer/llama-7b-hf/lukaemon_mmlu_moral_scenarios.out
 50%|█████     | 2/4 [1:01:46<1:10:36, 2118.04s/it]                                                    50%|█████     | 2/4 [1:01:46<1:10:36, 2118.04s/it]launch OpenICLInfer[llama-7b-hf/lukaemon_mmlu_high_school_physics,llama-7b-hf/lukaemon_mmlu_electrical_engineering,llama-7b-hf/lukaemon_mmlu_college_biology,llama-7b-hf/lukaemon_mmlu_anatomy,llama-7b-hf/lukaemon_mmlu_human_sexuality,llama-7b-hf/lukaemon_mmlu_formal_logic,llama-7b-hf/lukaemon_mmlu_international_law,llama-7b-hf/lukaemon_mmlu_econometrics,llama-7b-hf/lukaemon_mmlu_machine_learning,llama-7b-hf/lukaemon_mmlu_public_relations,llama-7b-hf/lukaemon_mmlu_jurisprudence,llama-7b-hf/lukaemon_mmlu_management,llama-7b-hf/lukaemon_mmlu_college_physics,llama-7b-hf/lukaemon_mmlu_college_chemistry,llama-7b-hf/lukaemon_mmlu_college_computer_science,llama-7b-hf/lukaemon_mmlu_college_mathematics,llama-7b-hf/lukaemon_mmlu_abstract_algebra,llama-7b-hf/lukaemon_mmlu_global_facts,llama-7b-hf/lukaemon_mmlu_computer_security,llama-7b-hf/lukaemon_mmlu_medical_genetics,llama-7b-hf/lukaemon_mmlu_high_school_computer_science,llama-7b-hf/lukaemon_mmlu_business_ethics,llama-7b-hf/lukaemon_mmlu_us_foreign_policy] on GPU 0,1,2,3,4,5,6,7
11/12 20:23:59 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/lukaemon_mmlu_high_school_physics,llama-7b-hf/lukaemon_mmlu_electrical_engineering,llama-7b-hf/lukaemon_mmlu_college_biology,llama-7b-hf/lukaemon_mmlu_anatomy,llama-7b-hf/lukaemon_mmlu_human_sexuality,llama-7b-hf/lukaemon_mmlu_formal_logic,llama-7b-hf/lukaemon_mmlu_international_law,llama-7b-hf/lukaemon_mmlu_econometrics,llama-7b-hf/lukaemon_mmlu_machine_learning,llama-7b-hf/lukaemon_mmlu_public_relations,llama-7b-hf/lukaemon_mmlu_jurisprudence,llama-7b-hf/lukaemon_mmlu_management,llama-7b-hf/lukaemon_mmlu_college_physics,llama-7b-hf/lukaemon_mmlu_college_chemistry,llama-7b-hf/lukaemon_mmlu_college_computer_science,llama-7b-hf/lukaemon_mmlu_college_mathematics,llama-7b-hf/lukaemon_mmlu_abstract_algebra,llama-7b-hf/lukaemon_mmlu_global_facts,llama-7b-hf/lukaemon_mmlu_computer_security,llama-7b-hf/lukaemon_mmlu_medical_genetics,llama-7b-hf/lukaemon_mmlu_high_school_computer_science,llama-7b-hf/lukaemon_mmlu_business_ethics,llama-7b-hf/lukaemon_mmlu_us_foreign_policy] fail, see
./outputs/default/20231112_191817/logs/infer/llama-7b-hf/lukaemon_mmlu_high_school_physics.out
 75%|███████▌  | 3/4 [1:05:42<20:58, 1258.76s/it]                                                    75%|███████▌  | 3/4 [1:05:43<20:58, 1258.76s/it]launch OpenICLInfer[llama-7b-hf/lukaemon_mmlu_professional_law_1] on GPU 0,1,2,3,4,5,6,7
11/12 20:25:02 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/lukaemon_mmlu_professional_law_1] fail, see
./outputs/default/20231112_191817/logs/infer/llama-7b-hf/lukaemon_mmlu_professional_law_1.out
100%|██████████| 4/4 [1:06:45<00:00, 786.53s/it] 100%|██████████| 4/4 [1:06:45<00:00, 1001.28s/it]
11/12 20:25:02 - OpenCompass - ERROR - /home/hkustadmin/evaluation/opencompass/opencompass/runners/base.py - summarize - 63 - OpenICLInfer[llama-7b-hf/lukaemon_mmlu_professional_law_0] failed with code 1
11/12 20:25:02 - OpenCompass - ERROR - /home/hkustadmin/evaluation/opencompass/opencompass/runners/base.py - summarize - 63 - OpenICLInfer[llama-7b-hf/lukaemon_mmlu_professional_law_1] failed with code 1
11/12 20:25:02 - OpenCompass - ERROR - /home/hkustadmin/evaluation/opencompass/opencompass/runners/base.py - summarize - 63 - OpenICLInfer[llama-7b-hf/lukaemon_mmlu_moral_scenarios,llama-7b-hf/lukaemon_mmlu_miscellaneous,llama-7b-hf/lukaemon_mmlu_professional_psychology,llama-7b-hf/lukaemon_mmlu_high_school_psychology,llama-7b-hf/lukaemon_mmlu_high_school_macroeconomics,llama-7b-hf/lukaemon_mmlu_elementary_mathematics,llama-7b-hf/lukaemon_mmlu_moral_disputes,llama-7b-hf/lukaemon_mmlu_prehistory,llama-7b-hf/lukaemon_mmlu_philosophy,llama-7b-hf/lukaemon_mmlu_high_school_biology,llama-7b-hf/lukaemon_mmlu_nutrition,llama-7b-hf/lukaemon_mmlu_professional_accounting,llama-7b-hf/lukaemon_mmlu_professional_medicine,llama-7b-hf/lukaemon_mmlu_high_school_mathematics,llama-7b-hf/lukaemon_mmlu_clinical_knowledge,llama-7b-hf/lukaemon_mmlu_security_studies,llama-7b-hf/lukaemon_mmlu_high_school_microeconomics,llama-7b-hf/lukaemon_mmlu_high_school_world_history,llama-7b-hf/lukaemon_mmlu_conceptual_physics,llama-7b-hf/lukaemon_mmlu_marketing,llama-7b-hf/lukaemon_mmlu_human_aging,llama-7b-hf/lukaemon_mmlu_high_school_statistics,llama-7b-hf/lukaemon_mmlu_high_school_us_history,llama-7b-hf/lukaemon_mmlu_high_school_chemistry,llama-7b-hf/lukaemon_mmlu_sociology,llama-7b-hf/lukaemon_mmlu_high_school_geography,llama-7b-hf/lukaemon_mmlu_high_school_government_and_politics,llama-7b-hf/lukaemon_mmlu_college_medicine,llama-7b-hf/lukaemon_mmlu_world_religions,llama-7b-hf/lukaemon_mmlu_virology,llama-7b-hf/lukaemon_mmlu_high_school_european_history,llama-7b-hf/lukaemon_mmlu_logical_fallacies,llama-7b-hf/lukaemon_mmlu_astronomy] failed with code 1
11/12 20:25:02 - OpenCompass - ERROR - /home/hkustadmin/evaluation/opencompass/opencompass/runners/base.py - summarize - 63 - OpenICLInfer[llama-7b-hf/lukaemon_mmlu_high_school_physics,llama-7b-hf/lukaemon_mmlu_electrical_engineering,llama-7b-hf/lukaemon_mmlu_college_biology,llama-7b-hf/lukaemon_mmlu_anatomy,llama-7b-hf/lukaemon_mmlu_human_sexuality,llama-7b-hf/lukaemon_mmlu_formal_logic,llama-7b-hf/lukaemon_mmlu_international_law,llama-7b-hf/lukaemon_mmlu_econometrics,llama-7b-hf/lukaemon_mmlu_machine_learning,llama-7b-hf/lukaemon_mmlu_public_relations,llama-7b-hf/lukaemon_mmlu_jurisprudence,llama-7b-hf/lukaemon_mmlu_management,llama-7b-hf/lukaemon_mmlu_college_physics,llama-7b-hf/lukaemon_mmlu_college_chemistry,llama-7b-hf/lukaemon_mmlu_college_computer_science,llama-7b-hf/lukaemon_mmlu_college_mathematics,llama-7b-hf/lukaemon_mmlu_abstract_algebra,llama-7b-hf/lukaemon_mmlu_global_facts,llama-7b-hf/lukaemon_mmlu_computer_security,llama-7b-hf/lukaemon_mmlu_medical_genetics,llama-7b-hf/lukaemon_mmlu_high_school_computer_science,llama-7b-hf/lukaemon_mmlu_business_ethics,llama-7b-hf/lukaemon_mmlu_us_foreign_policy] failed with code 1
11/12 20:25:02 - OpenCompass - INFO - Partitioned into 57 tasks.
  0%|          | 0/57 [00:00<?, ?it/s]                                        0%|          | 0/57 [00:00<?, ?it/s]                                        0%|          | 0/57 [00:00<?, ?it/s]                                        0%|          | 0/57 [00:00<?, ?it/s]                                        0%|          | 0/57 [00:00<?, ?it/s]                                        0%|          | 0/57 [00:00<?, ?it/s]                                        0%|          | 0/57 [00:00<?, ?it/s]                                        0%|          | 0/57 [00:00<?, ?it/s]                                        0%|          | 0/57 [00:01<?, ?it/s]                                        0%|          | 0/57 [00:01<?, ?it/s]                                        0%|          | 0/57 [00:01<?, ?it/s]                                        0%|          | 0/57 [00:02<?, ?it/s]                                        0%|          | 0/57 [00:02<?, ?it/s]                                        0%|          | 0/57 [00:02<?, ?it/s]                                        0%|          | 0/57 [00:03<?, ?it/s]                                        0%|          | 0/57 [00:03<?, ?it/s]                                        0%|          | 0/57 [00:04<?, ?it/s]                                        0%|          | 0/57 [00:05<?, ?it/s]                                        0%|          | 0/57 [00:06<?, ?it/s]                                        0%|          | 0/57 [00:06<?, ?it/s]                                        0%|          | 0/57 [00:07<?, ?it/s]                                        0%|          | 0/57 [00:07<?, ?it/s]                                        0%|          | 0/57 [00:09<?, ?it/s]                                        0%|          | 0/57 [00:10<?, ?it/s]                                        0%|          | 0/57 [00:11<?, ?it/s]                                        0%|          | 0/57 [00:12<?, ?it/s]                                        0%|          | 0/57 [00:13<?, ?it/s]                                        0%|          | 0/57 [00:14<?, ?it/s]                                        0%|          | 0/57 [00:14<?, ?it/s]                                        0%|          | 0/57 [00:15<?, ?it/s]                                        0%|          | 0/57 [00:15<?, ?it/s]                                        0%|          | 0/57 [00:16<?, ?it/s]                                        0%|          | 0/57 [00:18<?, ?it/s]  2%|▏         | 1/57 [00:20<19:21, 20.74s/it]                                                2%|▏         | 1/57 [00:21<19:21, 20.74s/it]  4%|▎         | 2/57 [00:22<08:59,  9.80s/it]                                                4%|▎         | 2/57 [00:23<08:59,  9.80s/it]  7%|▋         | 4/57 [00:23<02:20,  2.65s/it]  9%|▉         | 5/57 [00:24<01:43,  2.00s/it]                                               11%|█         | 6/57 [00:24<01:28,  1.73s/it] 11%|█         | 6/57 [00:24<01:28,  1.73s/it]                                               12%|█▏        | 7/57 [00:26<01:23,  1.68s/it] 14%|█▍        | 8/57 [00:26<01:07,  1.38s/it]                                               14%|█▍        | 8/57 [00:27<01:07,  1.38s/it] 14%|█▍        | 8/57 [00:27<01:07,  1.38s/it] 14%|█▍        | 8/57 [00:28<01:07,  1.38s/it]                                               16%|█▌        | 9/57 [00:29<01:22,  1.72s/it]                                               16%|█▌        | 9/57 [00:29<01:22,  1.72s/it] 16%|█▌        | 9/57 [00:29<01:22,  1.72s/it]                                               16%|█▌        | 9/57 [00:30<01:22,  1.72s/it]                                               16%|█▌        | 9/57 [00:31<01:22,  1.72s/it] 18%|█▊        | 10/57 [00:32<01:55,  2.45s/it]                                                19%|█▉        | 11/57 [00:33<01:52,  2.45s/it]                                                21%|██        | 12/57 [00:33<01:11,  1.60s/it] 21%|██        | 12/57 [00:34<01:11,  1.60s/it]                                                21%|██        | 12/57 [00:34<01:11,  1.60s/it] 23%|██▎       | 13/57 [00:34<01:02,  1.42s/it]                                                23%|██▎       | 13/57 [00:35<01:02,  1.42s/it] 25%|██▍       | 14/57 [00:39<01:40,  2.33s/it] 26%|██▋       | 15/57 [00:39<01:42,  2.45s/it]                                                28%|██▊       | 16/57 [00:40<01:21,  1.99s/it] 28%|██▊       | 16/57 [00:41<01:21,  1.99s/it]                                                28%|██▊       | 16/57 [00:42<01:21,  1.99s/it]                                                32%|███▏      | 18/57 [00:43<01:18,  2.01s/it] 32%|███▏      | 18/57 [00:44<01:18,  2.01s/it] 33%|███▎      | 19/57 [00:44<01:09,  1.82s/it]                                                33%|███▎      | 19/57 [00:44<01:09,  1.82s/it] 35%|███▌      | 20/57 [00:45<01:06,  1.80s/it]                                                37%|███▋      | 21/57 [00:46<01:05,  1.81s/it] 37%|███▋      | 21/57 [00:46<01:05,  1.81s/it]                                                37%|███▋      | 21/57 [00:46<01:05,  1.81s/it] 37%|███▋      | 21/57 [00:47<01:05,  1.81s/it]                                                40%|████      | 23/57 [00:48<00:57,  1.70s/it]                                                40%|████      | 23/57 [00:49<00:57,  1.70s/it] 42%|████▏     | 24/57 [00:49<00:46,  1.40s/it] 42%|████▏     | 24/57 [00:50<00:46,  1.40s/it] 42%|████▏     | 24/57 [00:50<00:46,  1.40s/it]                                                42%|████▏     | 24/57 [00:51<00:46,  1.40s/it]                                                42%|████▏     | 24/57 [00:51<00:46,  1.40s/it]                                                42%|████▏     | 24/57 [00:52<00:46,  1.40s/it] 44%|████▍     | 25/57 [00:54<01:06,  2.08s/it]                                                46%|████▌     | 26/57 [00:55<00:52,  1.70s/it] 46%|████▌     | 26/57 [00:55<00:52,  1.70s/it] 47%|████▋     | 27/57 [00:55<00:47,  1.58s/it] 49%|████▉     | 28/57 [00:57<00:46,  1.61s/it] 51%|█████     | 29/57 [00:59<00:47,  1.71s/it] 53%|█████▎    | 30/57 [01:00<00:38,  1.41s/it] 54%|█████▍    | 31/57 [01:00<00:30,  1.18s/it] 56%|█████▌    | 32/57 [01:01<00:26,  1.06s/it] 58%|█████▊    | 33/57 [01:01<00:18,  1.28it/s] 60%|█████▉    | 34/57 [01:05<00:33,  1.44s/it] 61%|██████▏   | 35/57 [01:05<00:34,  1.58s/it] 63%|██████▎   | 36/57 [01:07<00:35,  1.69s/it] 65%|██████▍   | 37/57 [01:07<00:28,  1.44s/it] 67%|██████▋   | 38/57 [01:11<00:36,  1.93s/it] 68%|██████▊   | 39/57 [01:13<00:36,  2.04s/it] 70%|███████   | 40/57 [01:14<00:28,  1.70s/it] 72%|███████▏  | 41/57 [01:14<00:18,  1.13s/it] 75%|███████▌  | 43/57 [01:14<00:10,  1.37it/s] 75%|███████▌  | 43/57 [01:14<00:10,  1.37it/s] 77%|███████▋  | 44/57 [01:14<00:09,  1.42it/s] 79%|███████▉  | 45/57 [01:15<00:07,  1.59it/s] 81%|████████  | 46/57 [01:17<00:12,  1.13s/it] 82%|████████▏ | 47/57 [01:18<00:10,  1.04s/it] 84%|████████▍ | 48/57 [01:18<00:07,  1.20it/s] 86%|████████▌ | 49/57 [01:19<00:06,  1.33it/s] 88%|████████▊ | 50/57 [01:19<00:04,  1.56it/s] 89%|████████▉ | 51/57 [01:20<00:02,  2.03it/s] 91%|█████████ | 52/57 [01:21<00:03,  1.54it/s] 93%|█████████▎| 53/57 [01:21<00:02,  1.92it/s] 96%|█████████▋| 55/57 [01:21<00:00,  2.64it/s] 98%|█████████▊| 56/57 [01:21<00:00,  2.86it/s]100%|██████████| 57/57 [01:22<00:00,  3.25it/s]100%|██████████| 57/57 [01:22<00:00,  1.44s/it]
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_college_biology] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_college_chemistry] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_college_computer_science] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_college_mathematics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_college_physics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_electrical_engineering] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_astronomy] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_anatomy] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_abstract_algebra] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_machine_learning] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_clinical_knowledge] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_global_facts] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_management] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_nutrition] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_marketing] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_professional_accounting] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_geography] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_international_law] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_moral_scenarios] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_computer_security] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_microeconomics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_professional_law] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_medical_genetics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_professional_psychology] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_jurisprudence] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_world_religions] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_philosophy] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_virology] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_chemistry] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_public_relations] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_macroeconomics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_human_sexuality] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_elementary_mathematics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_physics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_computer_science] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_european_history] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_business_ethics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_moral_disputes] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_statistics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_miscellaneous] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_formal_logic] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_government_and_politics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_prehistory] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_security_studies] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_biology] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_logical_fallacies] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_world_history] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_professional_medicine] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_mathematics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_college_medicine] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_us_history] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_sociology] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_econometrics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_psychology] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_human_aging] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_us_foreign_policy] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_conceptual_physics] on CPU 
dataset                       version    metric    mode    llama-7b-hf
----------------------------  ---------  --------  ------  -------------
------- MMLU details -------  -          -         -       -
mmlu-humanities               -          -         -       -
mmlu-stem                     -          -         -       -
mmlu-social-science           -          -         -       -
mmlu-other                    -          -         -       -
mmlu                          -          -         -       -
---- Standard Benchmarks ---  -          -         -       -
BoolQ                         -          -         -       -
piqa                          -          -         -       -
siqa                          -          -         -       -
hellaswag                     -          -         -       -
winogrande                    -          -         -       -
ARC-e                         -          -         -       -
ARC-c                         -          -         -       -
openbookqa_fact               -          -         -       -
commonsense_qa                -          -         -       -
mmlu                          -          -         -       -
------ Code Generation -----  -          -         -       -
openai_humaneval              -          -         -       -
mbpp                          -          -         -       -
------ World Knowledge -----  -          -         -       -
triviaqa                      -          -         -       -
--- Reading Comprehension --  -          -         -       -
squad2.0                      -          -         -       -
---------- Exams -----------  -          -         -       -
math                          -          -         -       -
gsm8k                         -          -         -       -
TheoremQA                     -          -         -       -
--------- Chinese ----------  -          -         -       -
ceval                         -          -         -       -
ceval-stem                    -          -         -       -
ceval-social-science          -          -         -       -
ceval-humanities              -          -         -       -
ceval-other                   -          -         -       -
ceval-hard                    -          -         -       -
ceval-test-stem               -          -         -       -
ceval-test-social-science     -          -         -       -
ceval-test-humanities         -          -         -       -
ceval-test-other              -          -         -       -
ceval-test-hard               -          -         -       -
ceval-test                    -          -         -       -
cmmlu                         -          -         -       -
cmmlu-humanities              -          -         -       -
cmmlu-stem                    -          -         -       -
cmmlu-social-science          -          -         -       -
cmmlu-other                   -          -         -       -
cmmlu-china-specific          -          -         -       -
11/12 20:26:24 - OpenCompass - INFO - write summary to /home/hkustadmin/evaluation/opencompass/outputs/default/20231112_191817/summary/summary_20231112_191817.txt
11/12 20:26:24 - OpenCompass - INFO - write csv to /home/hkustadmin/evaluation/opencompass/outputs/default/20231112_191817/summary/summary_20231112_191817.csv
11/12 22:14:00 - OpenCompass - WARNING - SlurmRunner is not used, so the partition argument is ignored.
11/12 22:14:00 - OpenCompass - INFO - Partitioned into 4 tasks.
  0%|          | 0/4 [00:00<?, ?it/s]                                       0%|          | 0/4 [00:00<?, ?it/s]                                       0%|          | 0/4 [00:00<?, ?it/s]launch OpenICLInfer[llama-7b-hf/lukaemon_mmlu_professional_law_0] on GPU 0,1,2,3
launch OpenICLInfer[llama-7b-hf/lukaemon_mmlu_professional_law_1] on GPU 4,5,6,7
11/12 22:14:14 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/lukaemon_mmlu_professional_law_1] fail, see
./outputs/default/20231112_221400/logs/infer/llama-7b-hf/lukaemon_mmlu_professional_law_1.out
 25%|██▌       | 1/4 [00:14<00:42, 14.26s/it]11/12 22:14:15 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/lukaemon_mmlu_professional_law_0] fail, see
./outputs/default/20231112_221400/logs/infer/llama-7b-hf/lukaemon_mmlu_professional_law_0.out
 50%|█████     | 2/4 [00:14<00:12,  6.01s/it]                                              50%|█████     | 2/4 [00:15<00:12,  6.01s/it]                                              50%|█████     | 2/4 [00:15<00:12,  6.01s/it]launch OpenICLInfer[llama-7b-hf/lukaemon_mmlu_moral_scenarios,llama-7b-hf/lukaemon_mmlu_miscellaneous,llama-7b-hf/lukaemon_mmlu_professional_psychology,llama-7b-hf/lukaemon_mmlu_high_school_psychology,llama-7b-hf/lukaemon_mmlu_high_school_macroeconomics,llama-7b-hf/lukaemon_mmlu_elementary_mathematics,llama-7b-hf/lukaemon_mmlu_moral_disputes,llama-7b-hf/lukaemon_mmlu_prehistory,llama-7b-hf/lukaemon_mmlu_philosophy,llama-7b-hf/lukaemon_mmlu_high_school_biology,llama-7b-hf/lukaemon_mmlu_nutrition,llama-7b-hf/lukaemon_mmlu_professional_accounting,llama-7b-hf/lukaemon_mmlu_professional_medicine,llama-7b-hf/lukaemon_mmlu_high_school_mathematics,llama-7b-hf/lukaemon_mmlu_clinical_knowledge,llama-7b-hf/lukaemon_mmlu_security_studies,llama-7b-hf/lukaemon_mmlu_high_school_microeconomics,llama-7b-hf/lukaemon_mmlu_high_school_world_history,llama-7b-hf/lukaemon_mmlu_conceptual_physics,llama-7b-hf/lukaemon_mmlu_marketing,llama-7b-hf/lukaemon_mmlu_human_aging,llama-7b-hf/lukaemon_mmlu_high_school_statistics,llama-7b-hf/lukaemon_mmlu_high_school_us_history,llama-7b-hf/lukaemon_mmlu_high_school_chemistry,llama-7b-hf/lukaemon_mmlu_sociology,llama-7b-hf/lukaemon_mmlu_high_school_geography,llama-7b-hf/lukaemon_mmlu_high_school_government_and_politics,llama-7b-hf/lukaemon_mmlu_college_medicine,llama-7b-hf/lukaemon_mmlu_world_religions,llama-7b-hf/lukaemon_mmlu_virology,llama-7b-hf/lukaemon_mmlu_high_school_european_history,llama-7b-hf/lukaemon_mmlu_logical_fallacies,llama-7b-hf/lukaemon_mmlu_astronomy] on GPU 0,1,2,3
launch OpenICLInfer[llama-7b-hf/lukaemon_mmlu_high_school_physics,llama-7b-hf/lukaemon_mmlu_electrical_engineering,llama-7b-hf/lukaemon_mmlu_college_biology,llama-7b-hf/lukaemon_mmlu_anatomy,llama-7b-hf/lukaemon_mmlu_human_sexuality,llama-7b-hf/lukaemon_mmlu_formal_logic,llama-7b-hf/lukaemon_mmlu_international_law,llama-7b-hf/lukaemon_mmlu_econometrics,llama-7b-hf/lukaemon_mmlu_machine_learning,llama-7b-hf/lukaemon_mmlu_public_relations,llama-7b-hf/lukaemon_mmlu_jurisprudence,llama-7b-hf/lukaemon_mmlu_management,llama-7b-hf/lukaemon_mmlu_college_physics,llama-7b-hf/lukaemon_mmlu_college_chemistry,llama-7b-hf/lukaemon_mmlu_college_computer_science,llama-7b-hf/lukaemon_mmlu_college_mathematics,llama-7b-hf/lukaemon_mmlu_abstract_algebra,llama-7b-hf/lukaemon_mmlu_global_facts,llama-7b-hf/lukaemon_mmlu_computer_security,llama-7b-hf/lukaemon_mmlu_medical_genetics,llama-7b-hf/lukaemon_mmlu_high_school_computer_science,llama-7b-hf/lukaemon_mmlu_business_ethics,llama-7b-hf/lukaemon_mmlu_us_foreign_policy] on GPU 4,5,6,7
11/12 22:14:31 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/lukaemon_mmlu_high_school_physics,llama-7b-hf/lukaemon_mmlu_electrical_engineering,llama-7b-hf/lukaemon_mmlu_college_biology,llama-7b-hf/lukaemon_mmlu_anatomy,llama-7b-hf/lukaemon_mmlu_human_sexuality,llama-7b-hf/lukaemon_mmlu_formal_logic,llama-7b-hf/lukaemon_mmlu_international_law,llama-7b-hf/lukaemon_mmlu_econometrics,llama-7b-hf/lukaemon_mmlu_machine_learning,llama-7b-hf/lukaemon_mmlu_public_relations,llama-7b-hf/lukaemon_mmlu_jurisprudence,llama-7b-hf/lukaemon_mmlu_management,llama-7b-hf/lukaemon_mmlu_college_physics,llama-7b-hf/lukaemon_mmlu_college_chemistry,llama-7b-hf/lukaemon_mmlu_college_computer_science,llama-7b-hf/lukaemon_mmlu_college_mathematics,llama-7b-hf/lukaemon_mmlu_abstract_algebra,llama-7b-hf/lukaemon_mmlu_global_facts,llama-7b-hf/lukaemon_mmlu_computer_security,llama-7b-hf/lukaemon_mmlu_medical_genetics,llama-7b-hf/lukaemon_mmlu_high_school_computer_science,llama-7b-hf/lukaemon_mmlu_business_ethics,llama-7b-hf/lukaemon_mmlu_us_foreign_policy] fail, see
./outputs/default/20231112_221400/logs/infer/llama-7b-hf/lukaemon_mmlu_high_school_physics.out
 75%|███████▌  | 3/4 [00:30<00:10, 10.64s/it]11/12 22:14:31 - OpenCompass - WARNING - task OpenICLInfer[llama-7b-hf/lukaemon_mmlu_moral_scenarios,llama-7b-hf/lukaemon_mmlu_miscellaneous,llama-7b-hf/lukaemon_mmlu_professional_psychology,llama-7b-hf/lukaemon_mmlu_high_school_psychology,llama-7b-hf/lukaemon_mmlu_high_school_macroeconomics,llama-7b-hf/lukaemon_mmlu_elementary_mathematics,llama-7b-hf/lukaemon_mmlu_moral_disputes,llama-7b-hf/lukaemon_mmlu_prehistory,llama-7b-hf/lukaemon_mmlu_philosophy,llama-7b-hf/lukaemon_mmlu_high_school_biology,llama-7b-hf/lukaemon_mmlu_nutrition,llama-7b-hf/lukaemon_mmlu_professional_accounting,llama-7b-hf/lukaemon_mmlu_professional_medicine,llama-7b-hf/lukaemon_mmlu_high_school_mathematics,llama-7b-hf/lukaemon_mmlu_clinical_knowledge,llama-7b-hf/lukaemon_mmlu_security_studies,llama-7b-hf/lukaemon_mmlu_high_school_microeconomics,llama-7b-hf/lukaemon_mmlu_high_school_world_history,llama-7b-hf/lukaemon_mmlu_conceptual_physics,llama-7b-hf/lukaemon_mmlu_marketing,llama-7b-hf/lukaemon_mmlu_human_aging,llama-7b-hf/lukaemon_mmlu_high_school_statistics,llama-7b-hf/lukaemon_mmlu_high_school_us_history,llama-7b-hf/lukaemon_mmlu_high_school_chemistry,llama-7b-hf/lukaemon_mmlu_sociology,llama-7b-hf/lukaemon_mmlu_high_school_geography,llama-7b-hf/lukaemon_mmlu_high_school_government_and_politics,llama-7b-hf/lukaemon_mmlu_college_medicine,llama-7b-hf/lukaemon_mmlu_world_religions,llama-7b-hf/lukaemon_mmlu_virology,llama-7b-hf/lukaemon_mmlu_high_school_european_history,llama-7b-hf/lukaemon_mmlu_logical_fallacies,llama-7b-hf/lukaemon_mmlu_astronomy] fail, see
./outputs/default/20231112_221400/logs/infer/llama-7b-hf/lukaemon_mmlu_moral_scenarios.out
100%|██████████| 4/4 [00:30<00:00,  6.52s/it]100%|██████████| 4/4 [00:30<00:00,  7.71s/it]
11/12 22:14:31 - OpenCompass - ERROR - /home/hkustadmin/evaluation/opencompass/opencompass/runners/base.py - summarize - 63 - OpenICLInfer[llama-7b-hf/lukaemon_mmlu_professional_law_0] failed with code 1
11/12 22:14:31 - OpenCompass - ERROR - /home/hkustadmin/evaluation/opencompass/opencompass/runners/base.py - summarize - 63 - OpenICLInfer[llama-7b-hf/lukaemon_mmlu_professional_law_1] failed with code 1
11/12 22:14:31 - OpenCompass - ERROR - /home/hkustadmin/evaluation/opencompass/opencompass/runners/base.py - summarize - 63 - OpenICLInfer[llama-7b-hf/lukaemon_mmlu_moral_scenarios,llama-7b-hf/lukaemon_mmlu_miscellaneous,llama-7b-hf/lukaemon_mmlu_professional_psychology,llama-7b-hf/lukaemon_mmlu_high_school_psychology,llama-7b-hf/lukaemon_mmlu_high_school_macroeconomics,llama-7b-hf/lukaemon_mmlu_elementary_mathematics,llama-7b-hf/lukaemon_mmlu_moral_disputes,llama-7b-hf/lukaemon_mmlu_prehistory,llama-7b-hf/lukaemon_mmlu_philosophy,llama-7b-hf/lukaemon_mmlu_high_school_biology,llama-7b-hf/lukaemon_mmlu_nutrition,llama-7b-hf/lukaemon_mmlu_professional_accounting,llama-7b-hf/lukaemon_mmlu_professional_medicine,llama-7b-hf/lukaemon_mmlu_high_school_mathematics,llama-7b-hf/lukaemon_mmlu_clinical_knowledge,llama-7b-hf/lukaemon_mmlu_security_studies,llama-7b-hf/lukaemon_mmlu_high_school_microeconomics,llama-7b-hf/lukaemon_mmlu_high_school_world_history,llama-7b-hf/lukaemon_mmlu_conceptual_physics,llama-7b-hf/lukaemon_mmlu_marketing,llama-7b-hf/lukaemon_mmlu_human_aging,llama-7b-hf/lukaemon_mmlu_high_school_statistics,llama-7b-hf/lukaemon_mmlu_high_school_us_history,llama-7b-hf/lukaemon_mmlu_high_school_chemistry,llama-7b-hf/lukaemon_mmlu_sociology,llama-7b-hf/lukaemon_mmlu_high_school_geography,llama-7b-hf/lukaemon_mmlu_high_school_government_and_politics,llama-7b-hf/lukaemon_mmlu_college_medicine,llama-7b-hf/lukaemon_mmlu_world_religions,llama-7b-hf/lukaemon_mmlu_virology,llama-7b-hf/lukaemon_mmlu_high_school_european_history,llama-7b-hf/lukaemon_mmlu_logical_fallacies,llama-7b-hf/lukaemon_mmlu_astronomy] failed with code 1
11/12 22:14:31 - OpenCompass - ERROR - /home/hkustadmin/evaluation/opencompass/opencompass/runners/base.py - summarize - 63 - OpenICLInfer[llama-7b-hf/lukaemon_mmlu_high_school_physics,llama-7b-hf/lukaemon_mmlu_electrical_engineering,llama-7b-hf/lukaemon_mmlu_college_biology,llama-7b-hf/lukaemon_mmlu_anatomy,llama-7b-hf/lukaemon_mmlu_human_sexuality,llama-7b-hf/lukaemon_mmlu_formal_logic,llama-7b-hf/lukaemon_mmlu_international_law,llama-7b-hf/lukaemon_mmlu_econometrics,llama-7b-hf/lukaemon_mmlu_machine_learning,llama-7b-hf/lukaemon_mmlu_public_relations,llama-7b-hf/lukaemon_mmlu_jurisprudence,llama-7b-hf/lukaemon_mmlu_management,llama-7b-hf/lukaemon_mmlu_college_physics,llama-7b-hf/lukaemon_mmlu_college_chemistry,llama-7b-hf/lukaemon_mmlu_college_computer_science,llama-7b-hf/lukaemon_mmlu_college_mathematics,llama-7b-hf/lukaemon_mmlu_abstract_algebra,llama-7b-hf/lukaemon_mmlu_global_facts,llama-7b-hf/lukaemon_mmlu_computer_security,llama-7b-hf/lukaemon_mmlu_medical_genetics,llama-7b-hf/lukaemon_mmlu_high_school_computer_science,llama-7b-hf/lukaemon_mmlu_business_ethics,llama-7b-hf/lukaemon_mmlu_us_foreign_policy] failed with code 1
11/12 22:14:31 - OpenCompass - INFO - Partitioned into 57 tasks.
  0%|          | 0/57 [00:00<?, ?it/s]                                        0%|          | 0/57 [00:00<?, ?it/s]                                        0%|          | 0/57 [00:00<?, ?it/s]                                        0%|          | 0/57 [00:00<?, ?it/s]                                        0%|          | 0/57 [00:00<?, ?it/s]                                        0%|          | 0/57 [00:00<?, ?it/s]                                        0%|          | 0/57 [00:00<?, ?it/s]                                        0%|          | 0/57 [00:00<?, ?it/s]                                        0%|          | 0/57 [00:00<?, ?it/s]                                        0%|          | 0/57 [00:00<?, ?it/s]                                        0%|          | 0/57 [00:01<?, ?it/s]                                        0%|          | 0/57 [00:01<?, ?it/s]                                        0%|          | 0/57 [00:03<?, ?it/s]                                        0%|          | 0/57 [00:03<?, ?it/s]                                        0%|          | 0/57 [00:04<?, ?it/s]                                        0%|          | 0/57 [00:05<?, ?it/s]                                        0%|          | 0/57 [00:05<?, ?it/s]                                        0%|          | 0/57 [00:07<?, ?it/s]                                        0%|          | 0/57 [00:08<?, ?it/s]                                        0%|          | 0/57 [00:09<?, ?it/s]                                        0%|          | 0/57 [00:10<?, ?it/s]                                        0%|          | 0/57 [00:11<?, ?it/s]                                        0%|          | 0/57 [00:11<?, ?it/s]                                        0%|          | 0/57 [00:11<?, ?it/s]                                        0%|          | 0/57 [00:12<?, ?it/s]                                        0%|          | 0/57 [00:12<?, ?it/s]                                        0%|          | 0/57 [00:13<?, ?it/s]                                        0%|          | 0/57 [00:13<?, ?it/s]                                        0%|          | 0/57 [00:14<?, ?it/s]                                        2%|▏         | 1/57 [00:15<14:39, 15.70s/it]                                                5%|▌         | 3/57 [00:16<06:31,  7.25s/it]                                                5%|▌         | 3/57 [00:16<06:31,  7.25s/it]                                                7%|▋         | 4/57 [00:17<04:56,  5.59s/it]  9%|▉         | 5/57 [00:17<03:57,  4.56s/it]  9%|▉         | 5/57 [00:19<03:57,  4.56s/it]  9%|▉         | 5/57 [00:19<03:57,  4.56s/it]  9%|▉         | 5/57 [00:19<03:57,  4.56s/it]  9%|▉         | 5/57 [00:20<03:57,  4.56s/it]                                                9%|▉         | 5/57 [00:20<03:57,  4.56s/it]                                                9%|▉         | 5/57 [00:21<03:57,  4.56s/it]                                                9%|▉         | 5/57 [00:21<03:57,  4.56s/it]                                               11%|█         | 6/57 [00:23<03:57,  4.65s/it]                                               11%|█         | 6/57 [00:23<03:57,  4.65s/it] 11%|█         | 6/57 [00:24<03:57,  4.65s/it]                                               11%|█         | 6/57 [00:25<03:57,  4.65s/it] 12%|█▏        | 7/57 [00:27<03:50,  4.60s/it]                                               12%|█▏        | 7/57 [00:27<03:50,  4.60s/it] 14%|█▍        | 8/57 [00:28<03:22,  4.13s/it]                                               14%|█▍        | 8/57 [00:29<03:22,  4.13s/it] 16%|█▌        | 9/57 [00:32<03:14,  4.05s/it]                                               18%|█▊        | 10/57 [00:32<02:30,  3.20s/it] 18%|█▊        | 10/57 [00:33<02:30,  3.20s/it]                                                18%|█▊        | 10/57 [00:34<02:30,  3.20s/it] 19%|█▉        | 11/57 [00:34<02:14,  2.93s/it]                                                21%|██        | 12/57 [00:35<01:40,  2.23s/it] 21%|██        | 12/57 [00:35<01:40,  2.23s/it]                                                21%|██        | 12/57 [00:36<01:40,  2.23s/it] 23%|██▎       | 13/57 [00:37<01:39,  2.26s/it]                                                23%|██▎       | 13/57 [00:38<01:39,  2.26s/it] 25%|██▍       | 14/57 [00:39<01:33,  2.17s/it]                                                25%|██▍       | 14/57 [00:40<01:33,  2.17s/it] 26%|██▋       | 15/57 [00:45<02:11,  3.12s/it]                                                26%|██▋       | 15/57 [00:45<02:11,  3.12s/it] 28%|██▊       | 16/57 [00:49<02:25,  3.56s/it] 30%|██▉       | 17/57 [00:49<02:01,  3.05s/it]                                                30%|██▉       | 17/57 [00:50<02:01,  3.05s/it]                                                30%|██▉       | 17/57 [00:51<02:01,  3.05s/it] 32%|███▏      | 18/57 [00:51<01:45,  2.70s/it]                                                32%|███▏      | 18/57 [00:53<01:45,  2.70s/it] 33%|███▎      | 19/57 [00:53<01:33,  2.45s/it]                                                33%|███▎      | 19/57 [00:54<01:33,  2.45s/it] 35%|███▌      | 20/57 [00:55<01:32,  2.50s/it]                                                35%|███▌      | 20/57 [00:56<01:32,  2.50s/it] 37%|███▋      | 21/57 [00:57<01:21,  2.25s/it]                                                37%|███▋      | 21/57 [00:57<01:21,  2.25s/it] 39%|███▊      | 22/57 [00:58<01:05,  1.86s/it]                                                40%|████      | 23/57 [00:58<01:03,  1.86s/it]                                                42%|████▏     | 24/57 [01:00<00:47,  1.44s/it] 42%|████▏     | 24/57 [01:00<00:47,  1.44s/it] 46%|████▌     | 26/57 [01:01<00:31,  1.03s/it]                                                49%|████▉     | 28/57 [01:02<00:22,  1.30it/s] 51%|█████     | 29/57 [01:02<00:17,  1.59it/s]                                                53%|█████▎    | 30/57 [01:03<00:23,  1.16it/s] 54%|█████▍    | 31/57 [01:03<00:25,  1.03it/s] 54%|█████▍    | 31/57 [01:03<00:25,  1.03it/s] 54%|█████▍    | 31/57 [01:03<00:25,  1.03it/s] 54%|█████▍    | 31/57 [01:05<00:25,  1.03it/s] 54%|█████▍    | 31/57 [01:05<00:25,  1.03it/s] 58%|█████▊    | 33/57 [01:05<00:37,  1.57s/it] 60%|█████▉    | 34/57 [01:06<00:29,  1.28s/it] 60%|█████▉    | 34/57 [01:06<00:29,  1.28s/it] 61%|██████▏   | 35/57 [01:11<00:51,  2.33s/it] 65%|██████▍   | 37/57 [01:12<00:33,  1.65s/it] 67%|██████▋   | 38/57 [01:12<00:21,  1.11s/it] 68%|██████▊   | 39/57 [01:13<00:17,  1.00it/s] 70%|███████   | 40/57 [01:16<00:24,  1.41s/it] 72%|███████▏  | 41/57 [01:18<00:25,  1.59s/it] 77%|███████▋  | 44/57 [01:18<00:10,  1.22it/s] 79%|███████▉  | 45/57 [01:19<00:09,  1.20it/s] 81%|████████  | 46/57 [01:19<00:08,  1.34it/s] 82%|████████▏ | 47/57 [01:20<00:08,  1.24it/s] 84%|████████▍ | 48/57 [01:23<00:10,  1.20s/it] 86%|████████▌ | 49/57 [01:23<00:08,  1.03s/it] 89%|████████▉ | 51/57 [01:24<00:04,  1.35it/s] 91%|█████████ | 52/57 [01:25<00:04,  1.18it/s] 93%|█████████▎| 53/57 [01:26<00:02,  1.43it/s] 95%|█████████▍| 54/57 [01:26<00:02,  1.45it/s] 96%|█████████▋| 55/57 [01:26<00:01,  1.80it/s] 98%|█████████▊| 56/57 [01:27<00:00,  2.32it/s]100%|██████████| 57/57 [01:27<00:00,  2.93it/s]100%|██████████| 57/57 [01:27<00:00,  1.53s/it]
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_college_biology] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_college_chemistry] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_college_computer_science] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_college_mathematics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_college_physics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_electrical_engineering] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_astronomy] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_anatomy] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_abstract_algebra] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_machine_learning] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_clinical_knowledge] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_global_facts] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_management] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_nutrition] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_marketing] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_professional_accounting] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_geography] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_international_law] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_moral_scenarios] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_computer_security] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_microeconomics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_professional_law] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_medical_genetics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_professional_psychology] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_jurisprudence] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_world_religions] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_philosophy] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_virology] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_chemistry] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_public_relations] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_macroeconomics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_human_sexuality] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_elementary_mathematics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_physics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_computer_science] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_european_history] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_business_ethics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_moral_disputes] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_statistics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_miscellaneous] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_formal_logic] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_government_and_politics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_prehistory] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_security_studies] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_biology] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_logical_fallacies] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_world_history] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_professional_medicine] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_mathematics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_college_medicine] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_us_history] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_sociology] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_econometrics] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_high_school_psychology] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_human_aging] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_us_foreign_policy] on CPU 
launch OpenICLEval[llama-7b-hf/lukaemon_mmlu_conceptual_physics] on CPU 
dataset                                            version    metric    mode    llama-7b-hf
-------------------------------------------------  ---------  --------  ------  -------------
lukaemon_mmlu_college_biology                      -          -         -       -
lukaemon_mmlu_college_chemistry                    -          -         -       -
lukaemon_mmlu_college_computer_science             -          -         -       -
lukaemon_mmlu_college_mathematics                  -          -         -       -
lukaemon_mmlu_college_physics                      -          -         -       -
lukaemon_mmlu_electrical_engineering               -          -         -       -
lukaemon_mmlu_astronomy                            -          -         -       -
lukaemon_mmlu_anatomy                              -          -         -       -
lukaemon_mmlu_abstract_algebra                     -          -         -       -
lukaemon_mmlu_machine_learning                     -          -         -       -
lukaemon_mmlu_clinical_knowledge                   -          -         -       -
lukaemon_mmlu_global_facts                         -          -         -       -
lukaemon_mmlu_management                           -          -         -       -
lukaemon_mmlu_nutrition                            -          -         -       -
lukaemon_mmlu_marketing                            -          -         -       -
lukaemon_mmlu_professional_accounting              -          -         -       -
lukaemon_mmlu_high_school_geography                -          -         -       -
lukaemon_mmlu_international_law                    -          -         -       -
lukaemon_mmlu_moral_scenarios                      -          -         -       -
lukaemon_mmlu_computer_security                    -          -         -       -
lukaemon_mmlu_high_school_microeconomics           -          -         -       -
lukaemon_mmlu_professional_law                     -          -         -       -
lukaemon_mmlu_medical_genetics                     -          -         -       -
lukaemon_mmlu_professional_psychology              -          -         -       -
lukaemon_mmlu_jurisprudence                        -          -         -       -
lukaemon_mmlu_world_religions                      -          -         -       -
lukaemon_mmlu_philosophy                           -          -         -       -
lukaemon_mmlu_virology                             -          -         -       -
lukaemon_mmlu_high_school_chemistry                -          -         -       -
lukaemon_mmlu_public_relations                     -          -         -       -
lukaemon_mmlu_high_school_macroeconomics           -          -         -       -
lukaemon_mmlu_human_sexuality                      -          -         -       -
lukaemon_mmlu_elementary_mathematics               -          -         -       -
lukaemon_mmlu_high_school_physics                  -          -         -       -
lukaemon_mmlu_high_school_computer_science         -          -         -       -
lukaemon_mmlu_high_school_european_history         -          -         -       -
lukaemon_mmlu_business_ethics                      -          -         -       -
lukaemon_mmlu_moral_disputes                       -          -         -       -
lukaemon_mmlu_high_school_statistics               -          -         -       -
lukaemon_mmlu_miscellaneous                        -          -         -       -
lukaemon_mmlu_formal_logic                         -          -         -       -
lukaemon_mmlu_high_school_government_and_politics  -          -         -       -
lukaemon_mmlu_prehistory                           -          -         -       -
lukaemon_mmlu_security_studies                     -          -         -       -
lukaemon_mmlu_high_school_biology                  -          -         -       -
lukaemon_mmlu_logical_fallacies                    -          -         -       -
lukaemon_mmlu_high_school_world_history            -          -         -       -
lukaemon_mmlu_professional_medicine                -          -         -       -
lukaemon_mmlu_high_school_mathematics              -          -         -       -
lukaemon_mmlu_college_medicine                     -          -         -       -
lukaemon_mmlu_high_school_us_history               -          -         -       -
lukaemon_mmlu_sociology                            -          -         -       -
lukaemon_mmlu_econometrics                         -          -         -       -
lukaemon_mmlu_high_school_psychology               -          -         -       -
lukaemon_mmlu_human_aging                          -          -         -       -
lukaemon_mmlu_us_foreign_policy                    -          -         -       -
lukaemon_mmlu_conceptual_physics                   -          -         -       -
11/12 22:15:58 - OpenCompass - INFO - write summary to /home/hkustadmin/evaluation/opencompass/outputs/default/20231112_221400/summary/summary_20231112_221400.txt
11/12 22:15:58 - OpenCompass - INFO - write csv to /home/hkustadmin/evaluation/opencompass/outputs/default/20231112_221400/summary/summary_20231112_221400.csv
11/13 01:44:32 - OpenCompass - WARNING - SlurmRunner is not used, so the partition argument is ignored.
11/13 01:44:32 - OpenCompass - INFO - Partitioned into 62 tasks.
  0%|          | 0/62 [00:00<?, ?it/s]                                        0%|          | 0/62 [00:00<?, ?it/s]                                        0%|          | 0/62 [00:00<?, ?it/s]                                        0%|          | 0/62 [00:00<?, ?it/s]                                        0%|          | 0/62 [00:00<?, ?it/s]                                        0%|          | 0/62 [00:00<?, ?it/s]                                        0%|          | 0/62 [00:00<?, ?it/s]                                        0%|          | 0/62 [00:00<?, ?it/s]                                        0%|          | 0/62 [00:00<?, ?it/s]  2%|▏         | 1/62 [34:23<34:57:51, 2063.46s/it]                                                     2%|▏         | 1/62 [34:23<34:57:51, 2063.46s/it]  3%|▎         | 2/62 [34:28<14:12:20, 852.34s/it]                                                     3%|▎         | 2/62 [34:28<14:12:20, 852.34s/it]  5%|▍         | 3/62 [35:24<8:00:39, 488.81s/it]                                                    5%|▍         | 3/62 [35:24<8:00:39, 488.81s/it]  6%|▋         | 4/62 [35:28<4:47:44, 297.66s/it]                                                   6%|▋         | 4/62 [35:28<4:47:44, 297.66s/it]  8%|▊         | 5/62 [39:54<4:31:40, 285.97s/it]                                                   8%|▊         | 5/62 [39:54<4:31:40, 285.97s/it] 10%|▉         | 6/62 [40:08<3:00:40, 193.59s/it]                                                  10%|▉         | 6/62 [40:08<3:00:40, 193.59s/it] 11%|█▏        | 7/62 [40:34<2:07:10, 138.75s/it]                                                  11%|█▏        | 7/62 [40:34<2:07:10, 138.75s/it] 13%|█▎        | 8/62 [41:04<1:33:44, 104.15s/it]                                                  13%|█▎        | 8/62 [41:04<1:33:44, 104.15s/it] 15%|█▍        | 9/62 [1:05:07<7:41:39, 522.64s/it]                                                    15%|█▍        | 9/62 [1:05:07<7:41:39, 522.64s/it] 16%|█▌        | 10/62 [1:05:07<5:13:13, 361.41s/it]                                                     16%|█▌        | 10/62 [1:05:07<5:13:13, 361.41s/it] 18%|█▊        | 11/62 [1:07:08<4:04:32, 287.70s/it]                                                     18%|█▊        | 11/62 [1:07:08<4:04:32, 287.70s/it] 19%|█▉        | 12/62 [1:07:23<2:50:41, 204.84s/it]                                                     19%|█▉        | 12/62 [1:07:23<2:50:41, 204.84s/it]launch OpenICLInfer[hf_llama-7b/math_0] on GPU 0
launch OpenICLInfer[hf_llama-7b/math_1] on GPU 1
launch OpenICLInfer[hf_llama-7b/math_2] on GPU 2
launch OpenICLInfer[hf_llama-7b/math_3] on GPU 3
launch OpenICLInfer[hf_llama-7b/math_4] on GPU 4
launch OpenICLInfer[hf_llama-7b/math_5] on GPU 5
launch OpenICLInfer[hf_llama-7b/math_6] on GPU 6
launch OpenICLInfer[hf_llama-7b/math_7] on GPU 7
launch OpenICLInfer[hf_llama-7b/squad2.0_0] on GPU 1
launch OpenICLInfer[hf_llama-7b/squad2.0_1] on GPU 0
launch OpenICLInfer[hf_llama-7b/squad2.0_2] on GPU 2
launch OpenICLInfer[hf_llama-7b/squad2.0_3] on GPU 3
launch OpenICLInfer[hf_llama-7b/squad2.0_4] on GPU 7
launch OpenICLInfer[hf_llama-7b/squad2.0_5] on GPU 6
launch OpenICLInfer[hf_llama-7b/triviaqa_0] on GPU 4
launch OpenICLInfer[hf_llama-7b/triviaqa_1] on GPU 5
launch OpenICLInfer[hf_llama-7b/triviaqa_2] on GPU 0
launch OpenICLInfer[hf_llama-7b/triviaqa_3] on GPU 1
launch OpenICLInfer[hf_llama-7b/triviaqa_4] on GPU 3
launch OpenICLInfer[hf_llama-7b/triviaqa_1shot_0] on GPU 2
11/13 02:56:13 - OpenCompass - WARNING - task OpenICLInfer[hf_llama-7b/triviaqa_2] fail, see
./outputs/default/20231113_014431/logs/infer/hf_llama-7b/triviaqa_2.out
 21%|██        | 13/62 [1:11:41<3:00:21, 220.84s/it]                                                     21%|██        | 13/62 [1:11:41<3:00:21, 220.84s/it] 23%|██▎       | 14/62 [1:13:03<2:23:11, 178.99s/it]                                                     23%|██▎       | 14/62 [1:13:03<2:23:11, 178.99s/it] 24%|██▍       | 15/62 [1:13:08<1:39:08, 126.57s/it]                                                     24%|██▍       | 15/62 [1:13:08<1:39:08, 126.57s/it] 26%|██▌       | 16/62 [1:16:53<1:59:45, 156.21s/it]                                                     26%|██▌       | 16/62 [1:16:53<1:59:45, 156.21s/it] 27%|██▋       | 17/62 [1:17:07<1:25:09, 113.54s/it]                                                     27%|██▋       | 17/62 [1:17:07<1:25:09, 113.54s/it]launch OpenICLInfer[hf_llama-7b/triviaqa_1shot_1] on GPU 0
launch OpenICLInfer[hf_llama-7b/triviaqa_1shot_2] on GPU 5
launch OpenICLInfer[hf_llama-7b/triviaqa_1shot_3] on GPU 4
launch OpenICLInfer[hf_llama-7b/triviaqa_1shot_4] on GPU 7
launch OpenICLInfer[hf_llama-7b/triviaqa_5shot_0] on GPU 6
11/13 03:09:06 - OpenCompass - WARNING - task OpenICLInfer[hf_llama-7b/triviaqa_1shot_1] fail, see
./outputs/default/20231113_014431/logs/infer/hf_llama-7b/triviaqa_1shot_1.out
 29%|██▉       | 18/62 [1:24:34<2:36:39, 213.63s/it]                                                     29%|██▉       | 18/62 [1:24:34<2:36:39, 213.63s/it]launch OpenICLInfer[hf_llama-7b/triviaqa_5shot_1] on GPU 0
11/13 03:10:07 - OpenCompass - WARNING - task OpenICLInfer[hf_llama-7b/triviaqa_5shot_0] fail, see
./outputs/default/20231113_014431/logs/infer/hf_llama-7b/triviaqa_5shot_0.out
 31%|███       | 19/62 [1:25:35<2:00:15, 167.80s/it]                                                     31%|███       | 19/62 [1:25:35<2:00:15, 167.80s/it] 32%|███▏      | 20/62 [1:32:27<2:48:45, 241.08s/it]                                                     32%|███▏      | 20/62 [1:32:27<2:48:45, 241.08s/it] 34%|███▍      | 21/62 [1:34:06<2:15:42, 198.59s/it]                                                     34%|███▍      | 21/62 [1:34:06<2:15:42, 198.59s/it] 35%|███▌      | 22/62 [1:34:47<1:40:45, 151.13s/it]                                                     35%|███▌      | 22/62 [1:34:47<1:40:45, 151.13s/it]launch OpenICLInfer[hf_llama-7b/triviaqa_5shot_2] on GPU 6
launch OpenICLInfer[hf_llama-7b/triviaqa_5shot_3] on GPU 1
launch OpenICLInfer[hf_llama-7b/triviaqa_5shot_4] on GPU 3
launch OpenICLInfer[hf_llama-7b/lukaemon_mmlu_professional_law_0] on GPU 2
11/13 03:22:36 - OpenCompass - WARNING - task OpenICLInfer[hf_llama-7b/triviaqa_5shot_4] fail, see
./outputs/default/20231113_014431/logs/infer/hf_llama-7b/triviaqa_5shot_4.out
 37%|███▋      | 23/62 [1:38:04<1:47:11, 164.91s/it]                                                     37%|███▋      | 23/62 [1:38:04<1:47:11, 164.91s/it]launch OpenICLInfer[hf_llama-7b/lukaemon_mmlu_professional_law_1] on GPU 3
11/13 03:29:25 - OpenCompass - WARNING - task OpenICLInfer[hf_llama-7b/triviaqa_5shot_1] fail, see
./outputs/default/20231113_014431/logs/infer/hf_llama-7b/triviaqa_5shot_1.out
 39%|███▊      | 24/62 [1:44:53<2:30:49, 238.14s/it]                                                     39%|███▊      | 24/62 [1:44:53<2:30:49, 238.14s/it] 40%|████      | 25/62 [1:45:17<1:47:16, 173.97s/it]                                                     40%|████      | 25/62 [1:45:17<1:47:16, 173.97s/it] 42%|████▏     | 26/62 [1:45:40<1:17:08, 128.57s/it]                                                     42%|████▏     | 26/62 [1:45:40<1:17:08, 128.57s/it] 44%|████▎     | 27/62 [1:45:42<52:54, 90.70s/it]                                                     44%|████▎     | 27/62 [1:45:42<52:54, 90.70s/it]launch OpenICLInfer[hf_llama-7b/hellaswag_0] on GPU 0
launch OpenICLInfer[hf_llama-7b/hellaswag_1] on GPU 4
launch OpenICLInfer[hf_llama-7b/TheoremQA,hf_llama-7b/mbpp,hf_llama-7b/cmmlu-professional_law] on GPU 2
launch OpenICLInfer[hf_llama-7b/BoolQ,hf_llama-7b/commonsense_qa,hf_llama-7b/siqa,hf_llama-7b/piqa,hf_llama-7b/lukaemon_mmlu_moral_scenarios,hf_llama-7b/openai_humaneval,hf_llama-7b/lukaemon_mmlu_miscellaneous,hf_llama-7b/winogrande,hf_llama-7b/lukaemon_mmlu_professional_psychology,hf_llama-7b/ARC-e] on GPU 5
11/13 03:33:11 - OpenCompass - WARNING - task OpenICLInfer[hf_llama-7b/hellaswag_1] fail, see
./outputs/default/20231113_014431/logs/infer/hf_llama-7b/hellaswag_1.out
 45%|████▌     | 28/62 [1:48:39<1:06:03, 116.59s/it]                                                     45%|████▌     | 28/62 [1:48:39<1:06:03, 116.59s/it] 47%|████▋     | 29/62 [1:48:57<47:47, 86.91s/it]                                                     47%|████▋     | 29/62 [1:48:57<47:47, 86.91s/it] 48%|████▊     | 30/62 [1:49:27<37:20, 70.01s/it]                                                  48%|████▊     | 30/62 [1:49:27<37:20, 70.01s/it]launch OpenICLInfer[hf_llama-7b/lukaemon_mmlu_high_school_psychology,hf_llama-7b/openbookqa_fact,hf_llama-7b/cmmlu-jurisprudence,hf_llama-7b/lukaemon_mmlu_high_school_macroeconomics,hf_llama-7b/lukaemon_mmlu_elementary_mathematics,hf_llama-7b/cmmlu-professional_medicine,hf_llama-7b/lukaemon_mmlu_moral_disputes,hf_llama-7b/lukaemon_mmlu_prehistory,hf_llama-7b/cmmlu-chinese_history,hf_llama-7b/lukaemon_mmlu_philosophy,hf_llama-7b/lukaemon_mmlu_high_school_biology,hf_llama-7b/lukaemon_mmlu_nutrition,hf_llama-7b/ARC-c,hf_llama-7b/lukaemon_mmlu_professional_accounting,hf_llama-7b/cmmlu-college_medicine,hf_llama-7b/lukaemon_mmlu_professional_medicine,hf_llama-7b/lukaemon_mmlu_high_school_mathematics,hf_llama-7b/lukaemon_mmlu_clinical_knowledge,hf_llama-7b/cmmlu-elementary_chinese,hf_llama-7b/lukaemon_mmlu_security_studies,hf_llama-7b/lukaemon_mmlu_high_school_microeconomics,hf_llama-7b/cmmlu-elementary_information_and_technology,hf_llama-7b/lukaemon_mmlu_high_school_world_history,hf_llama-7b/cmmlu-clinical_knowledge,hf_llama-7b/lukaemon_mmlu_conceptual_physics,hf_llama-7b/lukaemon_mmlu_marketing,hf_llama-7b/cmmlu-professional_psychology,hf_llama-7b/cmmlu-elementary_mathematics,hf_llama-7b/cmmlu-sociology,hf_llama-7b/lukaemon_mmlu_human_aging,hf_llama-7b/lukaemon_mmlu_high_school_statistics,hf_llama-7b/cmmlu-legal_and_moral_basis,hf_llama-7b/cmmlu-management,hf_llama-7b/cmmlu-business_ethics] on GPU 4
launch OpenICLInfer[hf_llama-7b/lukaemon_mmlu_high_school_us_history,hf_llama-7b/cmmlu-chinese_literature,hf_llama-7b/cmmlu-computer_science,hf_llama-7b/lukaemon_mmlu_high_school_chemistry,hf_llama-7b/lukaemon_mmlu_sociology,hf_llama-7b/lukaemon_mmlu_high_school_geography,hf_llama-7b/cmmlu-elementary_commonsense,hf_llama-7b/lukaemon_mmlu_high_school_government_and_politics,hf_llama-7b/cmmlu-marxist_theory,hf_llama-7b/cmmlu-international_law,hf_llama-7b/cmmlu-traditional_chinese_medicine,hf_llama-7b/cmmlu-marketing,hf_llama-7b/cmmlu-chinese_teacher_qualification,hf_llama-7b/cmmlu-genetics,hf_llama-7b/cmmlu-professional_accounting,hf_llama-7b/cmmlu-public_relations,hf_llama-7b/lukaemon_mmlu_college_medicine,hf_llama-7b/cmmlu-electrical_engineering,hf_llama-7b/cmmlu-journalism,hf_llama-7b/lukaemon_mmlu_world_religions,hf_llama-7b/cmmlu-computer_security,hf_llama-7b/cmmlu-agronomy,hf_llama-7b/cmmlu-high_school_biology,hf_llama-7b/cmmlu-virology,hf_llama-7b/lukaemon_mmlu_virology,hf_llama-7b/lukaemon_mmlu_high_school_european_history,hf_llama-7b/cmmlu-astronomy,hf_llama-7b/cmmlu-sports_science,hf_llama-7b/cmmlu-ancient_chinese,hf_llama-7b/cmmlu-high_school_mathematics,hf_llama-7b/lukaemon_mmlu_logical_fallacies,hf_llama-7b/cmmlu-education,hf_llama-7b/cmmlu-world_history,hf_llama-7b/cmmlu-arts,hf_llama-7b/cmmlu-chinese_civil_service_exam,hf_llama-7b/cmmlu-world_religions,hf_llama-7b/cmmlu-economics,hf_llama-7b/lukaemon_mmlu_astronomy,hf_llama-7b/lukaemon_mmlu_high_school_physics,hf_llama-7b/cmmlu-global_facts,hf_llama-7b/cmmlu-anatomy,hf_llama-7b/cmmlu-conceptual_physics,hf_llama-7b/lukaemon_mmlu_electrical_engineering,hf_llama-7b/cmmlu-nutrition,hf_llama-7b/lukaemon_mmlu_college_biology,hf_llama-7b/cmmlu-food_science,hf_llama-7b/cmmlu-high_school_politics,hf_llama-7b/cmmlu-construction_project_management,hf_llama-7b/cmmlu-chinese_food_culture,hf_llama-7b/lukaemon_mmlu_anatomy,hf_llama-7b/cmmlu-ethnology,hf_llama-7b/cmmlu-security_study,hf_llama-7b/cmmlu-high_school_chemistry,hf_llama-7b/lukaemon_mmlu_human_sexuality,hf_llama-7b/cmmlu-chinese_driving_rule,hf_llama-7b/lukaemon_mmlu_formal_logic,hf_llama-7b/cmmlu-human_sexuality,hf_llama-7b/cmmlu-logical,hf_llama-7b/cmmlu-machine_learning,hf_llama-7b/lukaemon_mmlu_international_law,hf_llama-7b/cmmlu-high_school_geography,hf_llama-7b/cmmlu-modern_chinese] on GPU 3
launch OpenICLInfer[hf_llama-7b/lukaemon_mmlu_econometrics,hf_llama-7b/lukaemon_mmlu_machine_learning,hf_llama-7b/lukaemon_mmlu_public_relations,hf_llama-7b/cmmlu-high_school_physics,hf_llama-7b/lukaemon_mmlu_jurisprudence,hf_llama-7b/cmmlu-college_law,hf_llama-7b/cmmlu-chinese_foreign_policy,hf_llama-7b/cmmlu-college_education,hf_llama-7b/cmmlu-college_actuarial_science,hf_llama-7b/cmmlu-college_engineering_hydrology,hf_llama-7b/cmmlu-college_medical_statistics,hf_llama-7b/cmmlu-college_mathematics,hf_llama-7b/cmmlu-philosophy,hf_llama-7b/lukaemon_mmlu_management,hf_llama-7b/lukaemon_mmlu_college_physics,hf_llama-7b/lukaemon_mmlu_college_chemistry,hf_llama-7b/lukaemon_mmlu_college_computer_science,hf_llama-7b/lukaemon_mmlu_college_mathematics,hf_llama-7b/lukaemon_mmlu_abstract_algebra,hf_llama-7b/lukaemon_mmlu_global_facts,hf_llama-7b/lukaemon_mmlu_computer_security,hf_llama-7b/lukaemon_mmlu_medical_genetics,hf_llama-7b/lukaemon_mmlu_high_school_computer_science,hf_llama-7b/lukaemon_mmlu_business_ethics,hf_llama-7b/lukaemon_mmlu_us_foreign_policy,hf_llama-7b/ceval-college_economics,hf_llama-7b/ceval-accountant,hf_llama-7b/ceval-tax_accountant,hf_llama-7b/ceval-physician,hf_llama-7b/ceval-civil_servant,hf_llama-7b/ceval-urban_and_rural_planner,hf_llama-7b/ceval-teacher_qualification,hf_llama-7b/ceval-college_programming,hf_llama-7b/ceval-electrical_engineer,hf_llama-7b/ceval-business_administration,hf_llama-7b/ceval-art_studies,hf_llama-7b/ceval-fire_engineer,hf_llama-7b/ceval-environmental_impact_assessment_engineer,hf_llama-7b/ceval-education_science,hf_llama-7b/ceval-professional_tour_guide,hf_llama-7b/ceval-college_chemistry,hf_llama-7b/ceval-metrology_engineer,hf_llama-7b/ceval-mao_zedong_thought,hf_llama-7b/ceval-law,hf_llama-7b/ceval-veterinary_medicine,hf_llama-7b/ceval-modern_chinese_history,hf_llama-7b/ceval-chinese_language_and_literature,hf_llama-7b/ceval-legal_professional,hf_llama-7b/ceval-logic,hf_llama-7b/ceval-middle_school_history,hf_llama-7b/ceval-plant_protection,hf_llama-7b/ceval-clinical_medicine,hf_llama-7b/ceval-computer_architecture,hf_llama-7b/ceval-middle_school_biology,hf_llama-7b/ceval-middle_school_politics,hf_llama-7b/ceval-middle_school_chemistry,hf_llama-7b/ceval-high_school_history,hf_llama-7b/ceval-computer_network,hf_llama-7b/ceval-operating_system,hf_llama-7b/ceval-college_physics,hf_llama-7b/ceval-advanced_mathematics,hf_llama-7b/ceval-high_school_physics,hf_llama-7b/ceval-high_school_chemistry,hf_llama-7b/ceval-high_school_biology,hf_llama-7b/ceval-middle_school_mathematics,hf_llama-7b/ceval-middle_school_physics,hf_llama-7b/ceval-marxism,hf_llama-7b/ceval-high_school_politics,hf_llama-7b/ceval-high_school_geography,hf_llama-7b/ceval-ideological_and_moral_cultivation,hf_llama-7b/ceval-high_school_chinese,hf_llama-7b/ceval-sports_science,hf_llama-7b/ceval-basic_medicine,hf_llama-7b/ceval-probability_and_statistics,hf_llama-7b/ceval-high_school_mathematics,hf_llama-7b/ceval-discrete_mathematics,hf_llama-7b/ceval-middle_school_geography] on GPU 7
11/13 03:34:27 - OpenCompass - WARNING - task OpenICLInfer[hf_llama-7b/BoolQ,hf_llama-7b/commonsense_qa,hf_llama-7b/siqa,hf_llama-7b/piqa,hf_llama-7b/lukaemon_mmlu_moral_scenarios,hf_llama-7b/openai_humaneval,hf_llama-7b/lukaemon_mmlu_miscellaneous,hf_llama-7b/winogrande,hf_llama-7b/lukaemon_mmlu_professional_psychology,hf_llama-7b/ARC-e] fail, see
./outputs/default/20231113_014431/logs/infer/hf_llama-7b/BoolQ.out
 50%|█████     | 31/62 [1:49:54<29:32, 57.18s/it]                                                  50%|█████     | 31/62 [1:49:55<29:32, 57.18s/it] 52%|█████▏    | 32/62 [1:52:40<44:51, 89.71s/it]                                                  52%|█████▏    | 32/62 [1:52:40<44:51, 89.71s/it]launch OpenICLInfer[hf_llama-7b/math_19] on GPU 5
launch OpenICLInfer[hf_llama-7b/gsm8k_6] on GPU 0
11/13 03:41:05 - OpenCompass - WARNING - task OpenICLInfer[hf_llama-7b/TheoremQA,hf_llama-7b/mbpp,hf_llama-7b/cmmlu-professional_law] fail, see
./outputs/default/20231113_014431/logs/infer/hf_llama-7b/TheoremQA.out
 53%|█████▎    | 33/62 [1:56:32<1:04:02, 132.51s/it]                                                     53%|█████▎    | 33/62 [1:56:33<1:04:02, 132.51s/it] 55%|█████▍    | 34/62 [1:58:49<1:02:25, 133.77s/it]                                                     55%|█████▍    | 34/62 [1:58:49<1:02:25, 133.77s/it] 56%|█████▋    | 35/62 [2:00:41<57:12, 127.11s/it]                                                     56%|█████▋    | 35/62 [2:00:41<57:12, 127.11s/it] 58%|█████▊    | 36/62 [2:15:14<2:32:06, 351.03s/it]                                                     58%|█████▊    | 36/62 [2:15:14<2:32:06, 351.03s/it]launch OpenICLInfer[hf_llama-7b/math_15] on GPU 2
launch OpenICLInfer[hf_llama-7b/math_17] on GPU 6
launch OpenICLInfer[hf_llama-7b/math_21] on GPU 1
launch OpenICLInfer[hf_llama-7b/math_14] on GPU 7
11/13 04:01:20 - OpenCompass - WARNING - task OpenICLInfer[hf_llama-7b/math_19] fail, see
./outputs/default/20231113_014431/logs/infer/hf_llama-7b/math_19.out
 60%|█████▉    | 37/62 [2:16:48<1:54:07, 273.88s/it]                                                     60%|█████▉    | 37/62 [2:16:48<1:54:07, 273.88s/it] 61%|██████▏   | 38/62 [2:27:14<2:31:50, 379.61s/it]                                                     61%|██████▏   | 38/62 [2:27:14<2:31:50, 379.61s/it]launch OpenICLInfer[hf_llama-7b/math_13] on GPU 5
launch OpenICLInfer[hf_llama-7b/math_20] on GPU 0
11/13 04:15:35 - OpenCompass - WARNING - task OpenICLInfer[hf_llama-7b/math_14] fail, see
./outputs/default/20231113_014431/logs/infer/hf_llama-7b/math_14.out
 63%|██████▎   | 39/62 [2:31:02<2:08:03, 334.08s/it]                                                     63%|██████▎   | 39/62 [2:31:03<2:08:03, 334.08s/it] 65%|██████▍   | 40/62 [2:31:27<1:28:25, 241.15s/it]                                                     65%|██████▍   | 40/62 [2:31:27<1:28:25, 241.15s/it]launch OpenICLInfer[hf_llama-7b/math_16] on GPU 7
launch OpenICLInfer[hf_llama-7b/gsm8k_0] on GPU 2
11/13 04:17:24 - OpenCompass - WARNING - task OpenICLInfer[hf_llama-7b/math_20] fail, see
./outputs/default/20231113_014431/logs/infer/hf_llama-7b/math_20.out
 66%|██████▌   | 41/62 [2:32:52<1:08:02, 194.43s/it]                                                     66%|██████▌   | 41/62 [2:32:52<1:08:02, 194.43s/it] 68%|██████▊   | 42/62 [2:35:20<1:00:10, 180.54s/it]                                                     68%|██████▊   | 42/62 [2:35:20<1:00:10, 180.54s/it] 69%|██████▉   | 43/62 [2:37:39<53:14, 168.14s/it]                                                     69%|██████▉   | 43/62 [2:37:39<53:14, 168.14s/it] 71%|███████   | 44/62 [2:38:19<38:50, 129.47s/it]                                                   71%|███████   | 44/62 [2:38:19<38:50, 129.47s/it] 73%|███████▎  | 45/62 [2:38:25<26:15, 92.68s/it]                                                   73%|███████▎  | 45/62 [2:38:26<26:15, 92.68s/it] 74%|███████▍  | 46/62 [2:48:07<1:03:50, 239.42s/it]                                                     74%|███████▍  | 46/62 [2:48:07<1:03:50, 239.42s/it]launch OpenICLInfer[hf_llama-7b/gsm8k_2] on GPU 0
launch OpenICLInfer[hf_llama-7b/math_22] on GPU 1
launch OpenICLInfer[hf_llama-7b/gsm8k_4] on GPU 3
launch OpenICLInfer[hf_llama-7b/math_12] on GPU 6
launch OpenICLInfer[hf_llama-7b/math_18] on GPU 4
launch OpenICLInfer[hf_llama-7b/math_10] on GPU 5
11/13 04:35:00 - OpenCompass - WARNING - task OpenICLInfer[hf_llama-7b/math_22] fail, see
./outputs/default/20231113_014431/logs/infer/hf_llama-7b/math_22.out
 76%|███████▌  | 47/62 [2:50:28<52:27, 209.86s/it]                                                     76%|███████▌  | 47/62 [2:50:28<52:27, 209.86s/it]launch OpenICLInfer[hf_llama-7b/gsm8k_5] on GPU 1
11/13 04:37:28 - OpenCompass - WARNING - task OpenICLInfer[hf_llama-7b/gsm8k_5] fail, see
./outputs/default/20231113_014431/logs/infer/hf_llama-7b/gsm8k_5.out
 77%|███████▋  | 48/62 [2:52:55<44:34, 191.01s/it]                                                   77%|███████▋  | 48/62 [2:52:55<44:34, 191.01s/it] 79%|███████▉  | 49/62 [2:55:46<40:04, 184.96s/it]                                                   79%|███████▉  | 49/62 [2:55:46<40:04, 184.96s/it]launch OpenICLInfer[hf_llama-7b/math_9] on GPU 1
launch OpenICLInfer[hf_llama-7b/math_11] on GPU 7
11/13 04:42:00 - OpenCompass - WARNING - task OpenICLInfer[hf_llama-7b/math_9] fail, see
./outputs/default/20231113_014431/logs/infer/hf_llama-7b/math_9.out
 81%|████████  | 50/62 [2:57:28<31:59, 159.93s/it]                                                   81%|████████  | 50/62 [2:57:28<31:59, 159.93s/it] 82%|████████▏ | 51/62 [3:00:17<29:51, 162.89s/it]                                                   82%|████████▏ | 51/62 [3:00:17<29:51, 162.89s/it] 84%|████████▍ | 52/62 [3:01:04<21:20, 128.09s/it]                                                   84%|████████▍ | 52/62 [3:01:04<21:20, 128.09s/it]launch OpenICLInfer[hf_llama-7b/gsm8k_3] on GPU 1
launch OpenICLInfer[hf_llama-7b/gsm8k_1] on GPU 6
launch OpenICLInfer[hf_llama-7b/math_24] on GPU 4
11/13 04:47:10 - OpenCompass - WARNING - task OpenICLInfer[hf_llama-7b/gsm8k_4] fail, see
./outputs/default/20231113_014431/logs/infer/hf_llama-7b/gsm8k_4.out
 85%|████████▌ | 53/62 [3:02:38<17:40, 117.82s/it]                                                   85%|████████▌ | 53/62 [3:02:38<17:40, 117.82s/it]launch OpenICLInfer[hf_llama-7b/math_23] on GPU 3
11/13 04:51:33 - OpenCompass - WARNING - task OpenICLInfer[hf_llama-7b/gsm8k_0] fail, see
./outputs/default/20231113_014431/logs/infer/hf_llama-7b/gsm8k_0.out
 87%|████████▋ | 54/62 [3:07:01<21:30, 161.28s/it]                                                   87%|████████▋ | 54/62 [3:07:01<21:30, 161.28s/it] 89%|████████▊ | 55/62 [3:08:06<15:27, 132.47s/it]launch OpenICLInfer[hf_llama-7b/math_8] on GPU 2
11/13 04:53:36 - OpenCompass - WARNING - task OpenICLInfer[hf_llama-7b/math_8] fail, see
./outputs/default/20231113_014431/logs/infer/hf_llama-7b/math_8.out
 90%|█████████ | 56/62 [3:09:03<10:59, 109.95s/it] 92%|█████████▏| 57/62 [3:12:46<11:58, 143.71s/it] 94%|█████████▎| 58/62 [3:18:04<13:04, 196.15s/it] 95%|█████████▌| 59/62 [3:22:41<11:00, 220.17s/it] 97%|█████████▋| 60/62 [3:25:03<06:33, 196.74s/it] 98%|█████████▊| 61/62 [3:32:52<04:38, 278.39s/it]100%|██████████| 62/62 [3:37:07<00:00, 271.60s/it]100%|██████████| 62/62 [3:37:07<00:00, 210.13s/it]
11/13 05:21:40 - OpenCompass - ERROR - /home/hkustadmin/evaluation/opencompass/opencompass/runners/base.py - summarize - 63 - OpenICLInfer[hf_llama-7b/math_8] failed with code 1
11/13 05:21:40 - OpenCompass - ERROR - /home/hkustadmin/evaluation/opencompass/opencompass/runners/base.py - summarize - 63 - OpenICLInfer[hf_llama-7b/math_9] failed with code 1
11/13 05:21:40 - OpenCompass - ERROR - /home/hkustadmin/evaluation/opencompass/opencompass/runners/base.py - summarize - 63 - OpenICLInfer[hf_llama-7b/math_14] failed with code 1
11/13 05:21:40 - OpenCompass - ERROR - /home/hkustadmin/evaluation/opencompass/opencompass/runners/base.py - summarize - 63 - OpenICLInfer[hf_llama-7b/math_19] failed with code 1
11/13 05:21:40 - OpenCompass - ERROR - /home/hkustadmin/evaluation/opencompass/opencompass/runners/base.py - summarize - 63 - OpenICLInfer[hf_llama-7b/math_20] failed with code 1
11/13 05:21:40 - OpenCompass - ERROR - /home/hkustadmin/evaluation/opencompass/opencompass/runners/base.py - summarize - 63 - OpenICLInfer[hf_llama-7b/math_22] failed with code 1
11/13 05:21:40 - OpenCompass - ERROR - /home/hkustadmin/evaluation/opencompass/opencompass/runners/base.py - summarize - 63 - OpenICLInfer[hf_llama-7b/gsm8k_0] failed with code 1
11/13 05:21:40 - OpenCompass - ERROR - /home/hkustadmin/evaluation/opencompass/opencompass/runners/base.py - summarize - 63 - OpenICLInfer[hf_llama-7b/gsm8k_4] failed with code 1
11/13 05:21:40 - OpenCompass - ERROR - /home/hkustadmin/evaluation/opencompass/opencompass/runners/base.py - summarize - 63 - OpenICLInfer[hf_llama-7b/gsm8k_5] failed with code 1
11/13 05:21:40 - OpenCompass - ERROR - /home/hkustadmin/evaluation/opencompass/opencompass/runners/base.py - summarize - 63 - OpenICLInfer[hf_llama-7b/triviaqa_2] failed with code 1
11/13 05:21:40 - OpenCompass - ERROR - /home/hkustadmin/evaluation/opencompass/opencompass/runners/base.py - summarize - 63 - OpenICLInfer[hf_llama-7b/triviaqa_1shot_1] failed with code 1
11/13 05:21:40 - OpenCompass - ERROR - /home/hkustadmin/evaluation/opencompass/opencompass/runners/base.py - summarize - 63 - OpenICLInfer[hf_llama-7b/triviaqa_5shot_0] failed with code 1
11/13 05:21:40 - OpenCompass - ERROR - /home/hkustadmin/evaluation/opencompass/opencompass/runners/base.py - summarize - 63 - OpenICLInfer[hf_llama-7b/triviaqa_5shot_1] failed with code 1
11/13 05:21:40 - OpenCompass - ERROR - /home/hkustadmin/evaluation/opencompass/opencompass/runners/base.py - summarize - 63 - OpenICLInfer[hf_llama-7b/triviaqa_5shot_4] failed with code 1
11/13 05:21:40 - OpenCompass - ERROR - /home/hkustadmin/evaluation/opencompass/opencompass/runners/base.py - summarize - 63 - OpenICLInfer[hf_llama-7b/hellaswag_1] failed with code 1
11/13 05:21:40 - OpenCompass - ERROR - /home/hkustadmin/evaluation/opencompass/opencompass/runners/base.py - summarize - 63 - OpenICLInfer[hf_llama-7b/TheoremQA,hf_llama-7b/mbpp,hf_llama-7b/cmmlu-professional_law] failed with code 1
11/13 05:21:40 - OpenCompass - ERROR - /home/hkustadmin/evaluation/opencompass/opencompass/runners/base.py - summarize - 63 - OpenICLInfer[hf_llama-7b/BoolQ,hf_llama-7b/commonsense_qa,hf_llama-7b/siqa,hf_llama-7b/piqa,hf_llama-7b/lukaemon_mmlu_moral_scenarios,hf_llama-7b/openai_humaneval,hf_llama-7b/lukaemon_mmlu_miscellaneous,hf_llama-7b/winogrande,hf_llama-7b/lukaemon_mmlu_professional_psychology,hf_llama-7b/ARC-e] failed with code 1
11/13 05:21:40 - OpenCompass - INFO - Partitioned into 194 tasks.
  0%|          | 0/194 [00:00<?, ?it/s]                                         0%|          | 0/194 [00:00<?, ?it/s]                                         0%|          | 0/194 [00:00<?, ?it/s]                                         0%|          | 0/194 [00:00<?, ?it/s]                                         0%|          | 0/194 [00:00<?, ?it/s]                                         0%|          | 0/194 [00:00<?, ?it/s]                                         0%|          | 0/194 [00:00<?, ?it/s]                                         0%|          | 0/194 [00:00<?, ?it/s]                                         0%|          | 0/194 [00:00<?, ?it/s]                                         0%|          | 0/194 [00:00<?, ?it/s]                                         0%|          | 0/194 [00:00<?, ?it/s]                                         0%|          | 0/194 [00:01<?, ?it/s]                                         0%|          | 0/194 [00:01<?, ?it/s]                                         0%|          | 0/194 [00:01<?, ?it/s]                                         0%|          | 0/194 [00:02<?, ?it/s]                                         0%|          | 0/194 [00:02<?, ?it/s]                                         0%|          | 0/194 [00:02<?, ?it/s]                                         0%|          | 0/194 [00:03<?, ?it/s]                                         0%|          | 0/194 [00:03<?, ?it/s]                                         0%|          | 0/194 [00:03<?, ?it/s]                                         0%|          | 0/194 [00:04<?, ?it/s]                                         0%|          | 0/194 [00:05<?, ?it/s]                                         0%|          | 0/194 [00:06<?, ?it/s]                                         0%|          | 0/194 [00:06<?, ?it/s]                                         0%|          | 0/194 [00:07<?, ?it/s]                                         1%|          | 1/194 [00:08<25:52,  8.05s/it]                                                 1%|          | 1/194 [00:08<25:52,  8.05s/it]                                                 1%|          | 2/194 [00:09<17:27,  5.46s/it]                                                 1%|          | 2/194 [00:09<17:27,  5.46s/it]                                                 1%|          | 2/194 [00:10<17:27,  5.46s/it]                                                 2%|▏         | 4/194 [00:11<11:03,  3.49s/it]                                                 2%|▏         | 4/194 [00:11<11:03,  3.49s/it]                                                 2%|▏         | 4/194 [00:12<11:03,  3.49s/it]  2%|▏         | 4/194 [00:12<11:03,  3.49s/it]  2%|▏         | 4/194 [00:13<11:03,  3.49s/it]  2%|▏         | 4/194 [00:13<11:03,  3.49s/it]  2%|▏         | 4/194 [00:14<11:03,  3.49s/it]                                                 2%|▏         | 4/194 [00:14<11:03,  3.49s/it]                                                 2%|▏         | 4/194 [00:15<11:03,  3.49s/it]                                                 2%|▏         | 4/194 [00:16<11:03,  3.49s/it]                                                 2%|▏         | 4/194 [00:17<11:03,  3.49s/it]  3%|▎         | 5/194 [00:17<12:35,  4.00s/it]                                                 3%|▎         | 5/194 [00:18<12:35,  4.00s/it]  3%|▎         | 6/194 [00:28<16:13,  5.18s/it]                                                 4%|▎         | 7/194 [00:28<13:01,  4.18s/it]  4%|▎         | 7/194 [00:29<13:01,  4.18s/it]  4%|▍         | 8/194 [00:29<08:39,  2.79s/it]                                                 4%|▍         | 8/194 [00:30<08:39,  2.79s/it]                                                 5%|▍         | 9/194 [00:30<07:29,  2.43s/it]  5%|▍         | 9/194 [00:31<07:29,  2.43s/it]                                                 5%|▍         | 9/194 [00:31<07:29,  2.43s/it]  5%|▌         | 10/194 [00:34<08:50,  2.88s/it]                                                  5%|▌         | 10/194 [00:34<08:50,  2.88s/it]  6%|▌         | 11/194 [00:37<08:34,  2.81s/it]                                                  6%|▌         | 11/194 [00:37<08:34,  2.81s/it]  6%|▌         | 12/194 [00:39<07:54,  2.60s/it]                                                  6%|▌         | 12/194 [00:39<07:54,  2.60s/it]  7%|▋         | 13/194 [00:41<07:13,  2.40s/it]                                                  7%|▋         | 13/194 [00:42<07:13,  2.40s/it]  7%|▋         | 14/194 [00:42<06:12,  2.07s/it]                                                  8%|▊         | 15/194 [00:42<06:10,  2.07s/it]                                                  8%|▊         | 15/194 [00:42<06:10,  2.07s/it]  8%|▊         | 16/194 [00:43<04:12,  1.42s/it]                                                  8%|▊         | 16/194 [00:43<04:12,  1.42s/it]  9%|▉         | 17/194 [00:44<03:52,  1.31s/it]                                                 10%|▉         | 19/194 [00:45<02:02,  1.43it/s] 10%|▉         | 19/194 [00:45<02:02,  1.43it/s] 10%|█         | 20/194 [00:45<01:28,  1.96it/s] 10%|█         | 20/194 [00:45<01:28,  1.96it/s]                                                 11%|█         | 21/194 [00:47<02:02,  1.41it/s]                                                 12%|█▏        | 23/194 [00:47<02:04,  1.38it/s]                                                 12%|█▏        | 24/194 [00:47<01:47,  1.59it/s] 12%|█▏        | 24/194 [00:48<01:47,  1.59it/s] 13%|█▎        | 25/194 [00:48<02:14,  1.25it/s] 13%|█▎        | 25/194 [00:49<02:14,  1.25it/s] 13%|█▎        | 25/194 [00:49<02:14,  1.25it/s]                                                 13%|█▎        | 25/194 [00:49<02:14,  1.25it/s] 13%|█▎        | 25/194 [00:49<02:14,  1.25it/s]                                                 13%|█▎        | 25/194 [00:50<02:14,  1.25it/s]                                                 13%|█▎        | 25/194 [00:50<02:14,  1.25it/s]                                                 13%|█▎        | 25/194 [00:50<02:14,  1.25it/s]                                                 13%|█▎        | 26/194 [00:51<02:59,  1.07s/it] 13%|█▎        | 26/194 [00:51<02:59,  1.07s/it]                                                 14%|█▍        | 27/194 [00:52<02:47,  1.00s/it] 14%|█▍        | 27/194 [00:52<02:47,  1.00s/it]                                                 14%|█▍        | 27/194 [00:52<02:47,  1.00s/it] 14%|█▍        | 28/194 [00:53<03:20,  1.21s/it] 16%|█▌        | 31/194 [00:54<01:46,  1.52it/s]                                                 16%|█▋        | 32/194 [00:54<01:30,  1.79it/s] 17%|█▋        | 33/194 [00:54<01:15,  2.13it/s] 17%|█▋        | 33/194 [00:55<01:15,  2.13it/s]                                                 17%|█▋        | 33/194 [00:55<01:15,  2.13it/s] 17%|█▋        | 33/194 [00:56<01:15,  2.13it/s] 18%|█▊        | 34/194 [00:57<02:07,  1.25it/s]                                                 18%|█▊        | 34/194 [00:58<02:07,  1.25it/s]                                                 18%|█▊        | 34/194 [00:58<02:07,  1.25it/s]                                                 18%|█▊        | 35/194 [01:00<04:29,  1.69s/it] 18%|█▊        | 35/194 [01:00<04:29,  1.69s/it]                                                 18%|█▊        | 35/194 [01:02<04:29,  1.69s/it] 18%|█▊        | 35/194 [01:02<04:29,  1.69s/it]                                                 18%|█▊        | 35/194 [01:03<04:29,  1.69s/it]                                                 18%|█▊        | 35/194 [01:04<04:29,  1.69s/it] 19%|█▊        | 36/194 [01:05<06:47,  2.58s/it]                                                 19%|█▊        | 36/194 [01:05<06:47,  2.58s/it] 19%|█▉        | 37/194 [01:07<06:45,  2.58s/it]                                                 19%|█▉        | 37/194 [01:07<06:45,  2.58s/it] 20%|█▉        | 38/194 [01:09<06:11,  2.38s/it]                                                 20%|█▉        | 38/194 [01:09<06:11,  2.38s/it] 20%|██        | 39/194 [01:10<05:29,  2.13s/it]                                                 20%|██        | 39/194 [01:10<05:29,  2.13s/it] 21%|██        | 40/194 [01:12<05:39,  2.21s/it]                                                 21%|██        | 40/194 [01:13<05:39,  2.21s/it] 21%|██        | 41/194 [01:14<05:30,  2.16s/it]                                                 21%|██        | 41/194 [01:15<05:30,  2.16s/it] 22%|██▏       | 42/194 [01:16<05:20,  2.11s/it]                                                 22%|██▏       | 42/194 [01:19<05:20,  2.11s/it] 22%|██▏       | 43/194 [01:19<05:22,  2.13s/it]                                                 22%|██▏       | 43/194 [01:19<05:22,  2.13s/it] 23%|██▎       | 44/194 [01:24<07:21,  2.95s/it]                                                 23%|██▎       | 44/194 [01:25<07:21,  2.95s/it] 23%|██▎       | 45/194 [01:25<06:34,  2.65s/it]                                                 24%|██▎       | 46/194 [01:26<06:31,  2.65s/it]                                                 25%|██▍       | 48/194 [01:27<02:19,  1.05it/s] 25%|██▍       | 48/194 [01:27<02:19,  1.05it/s] 25%|██▍       | 48/194 [01:27<02:19,  1.05it/s]                                                 25%|██▍       | 48/194 [01:28<02:19,  1.05it/s]                                                 25%|██▌       | 49/194 [01:29<02:32,  1.05s/it] 26%|██▌       | 50/194 [01:29<02:34,  1.07s/it] 26%|██▌       | 50/194 [01:29<02:34,  1.07s/it]                                                 26%|██▌       | 50/194 [01:29<02:34,  1.07s/it]                                                 26%|██▌       | 50/194 [01:31<02:34,  1.07s/it] 26%|██▋       | 51/194 [01:31<03:10,  1.33s/it] 27%|██▋       | 53/194 [01:31<02:36,  1.11s/it]                                                 28%|██▊       | 54/194 [01:32<02:17,  1.02it/s] 28%|██▊       | 55/194 [01:33<01:56,  1.19it/s]                                                 29%|██▉       | 56/194 [01:33<02:15,  1.02it/s] 29%|██▉       | 56/194 [01:33<02:15,  1.02it/s] 29%|██▉       | 56/194 [01:34<02:15,  1.02it/s]                                                 30%|██▉       | 58/194 [01:35<03:24,  1.50s/it] 30%|██▉       | 58/194 [01:36<03:24,  1.50s/it]                                                 30%|██▉       | 58/194 [01:36<03:24,  1.50s/it]                                                 30%|██▉       | 58/194 [01:37<03:24,  1.50s/it] 30%|██▉       | 58/194 [01:37<03:24,  1.50s/it] 30%|██▉       | 58/194 [01:37<03:24,  1.50s/it]                                                 30%|██▉       | 58/194 [01:38<03:24,  1.50s/it]                                                 31%|███       | 60/194 [01:39<03:52,  1.73s/it]                                                 31%|███       | 60/194 [01:40<03:52,  1.73s/it] 31%|███▏      | 61/194 [01:40<03:46,  1.70s/it] 31%|███▏      | 61/194 [01:41<03:46,  1.70s/it] 31%|███▏      | 61/194 [01:41<03:46,  1.70s/it]                                                 31%|███▏      | 61/194 [01:41<03:46,  1.70s/it]                                                 31%|███▏      | 61/194 [01:42<03:46,  1.70s/it]                                                 32%|███▏      | 62/194 [01:43<04:37,  2.10s/it] 32%|███▏      | 62/194 [01:43<04:37,  2.10s/it]                                                 32%|███▏      | 62/194 [01:43<04:37,  2.10s/it] 32%|███▏      | 63/194 [01:44<04:15,  1.95s/it]                                                 32%|███▏      | 63/194 [01:44<04:15,  1.95s/it] 33%|███▎      | 64/194 [01:45<03:51,  1.78s/it]                                                 34%|███▎      | 65/194 [01:45<03:00,  1.40s/it] 34%|███▎      | 65/194 [01:46<03:00,  1.40s/it]                                                 35%|███▍      | 67/194 [01:47<02:32,  1.20s/it] 35%|███▌      | 68/194 [01:48<02:09,  1.03s/it] 35%|███▌      | 68/194 [01:49<02:09,  1.03s/it] 36%|███▌      | 69/194 [01:50<02:49,  1.36s/it]                                                 36%|███▌      | 70/194 [01:50<03:18,  1.60s/it]                                                 36%|███▌      | 70/194 [01:51<03:18,  1.60s/it] 36%|███▌      | 70/194 [01:51<03:18,  1.60s/it]                                                 36%|███▌      | 70/194 [01:51<03:18,  1.60s/it] 36%|███▌      | 70/194 [01:51<03:18,  1.60s/it]                                                 37%|███▋      | 71/194 [01:52<03:21,  1.64s/it]                                                 37%|███▋      | 71/194 [01:54<03:21,  1.64s/it] 38%|███▊      | 73/194 [01:55<03:19,  1.65s/it] 38%|███▊      | 73/194 [01:55<03:19,  1.65s/it] 38%|███▊      | 73/194 [01:55<03:19,  1.65s/it]                                                 38%|███▊      | 73/194 [01:56<03:19,  1.65s/it]                                                 38%|███▊      | 74/194 [01:57<03:14,  1.62s/it]                                                 38%|███▊      | 74/194 [01:57<03:14,  1.62s/it] 38%|███▊      | 74/194 [01:57<03:14,  1.62s/it]                                                 39%|███▊      | 75/194 [01:59<03:15,  1.64s/it] 39%|███▊      | 75/194 [02:00<03:15,  1.64s/it]                                                 39%|███▊      | 75/194 [02:00<03:15,  1.64s/it] 39%|███▉      | 76/194 [02:17<10:56,  5.56s/it]                                                 39%|███▉      | 76/194 [02:17<10:56,  5.56s/it] 40%|███▉      | 77/194 [02:22<10:34,  5.43s/it]                                                 40%|███▉      | 77/194 [02:22<10:34,  5.43s/it] 40%|████      | 78/194 [02:30<11:52,  6.15s/it] 41%|████      | 79/194 [02:30<10:10,  5.31s/it]                                                 41%|████      | 79/194 [02:31<10:10,  5.31s/it]                                                 41%|████      | 79/194 [02:32<10:10,  5.31s/it] 41%|████      | 80/194 [02:35<09:52,  5.20s/it]                                                 41%|████      | 80/194 [02:35<09:52,  5.20s/it] 42%|████▏     | 81/194 [02:38<09:02,  4.81s/it]                                                 42%|████▏     | 81/194 [02:39<09:02,  4.81s/it] 42%|████▏     | 82/194 [02:40<07:24,  3.97s/it]                                                 42%|████▏     | 82/194 [02:40<07:24,  3.97s/it] 43%|████▎     | 83/194 [02:41<05:34,  3.01s/it]                                                 43%|████▎     | 83/194 [02:41<05:34,  3.01s/it] 43%|████▎     | 84/194 [02:43<05:29,  3.00s/it]                                                 44%|████▍     | 85/194 [02:44<04:00,  2.20s/it] 44%|████▍     | 85/194 [02:44<04:00,  2.20s/it]                                                 44%|████▍     | 85/194 [02:45<04:00,  2.20s/it] 44%|████▍     | 86/194 [02:48<05:10,  2.88s/it]                                                 44%|████▍     | 86/194 [02:48<05:10,  2.88s/it] 45%|████▍     | 87/194 [02:50<04:26,  2.49s/it] 46%|████▌     | 89/194 [02:50<02:02,  1.17s/it] 46%|████▌     | 89/194 [02:51<02:02,  1.17s/it]                                                 46%|████▌     | 89/194 [02:51<02:02,  1.17s/it]                                                 47%|████▋     | 91/194 [02:53<02:24,  1.40s/it]                                                 48%|████▊     | 93/194 [02:53<01:37,  1.03it/s] 48%|████▊     | 93/194 [02:53<01:37,  1.03it/s] 48%|████▊     | 93/194 [02:54<01:37,  1.03it/s] 49%|████▉     | 95/194 [02:54<01:31,  1.08it/s] 49%|████▉     | 95/194 [02:54<01:31,  1.08it/s]                                                 49%|████▉     | 95/194 [02:55<01:31,  1.08it/s]                                                 49%|████▉     | 95/194 [02:56<01:31,  1.08it/s] 49%|████▉     | 95/194 [02:56<01:31,  1.08it/s] 49%|████▉     | 95/194 [02:56<01:31,  1.08it/s]                                                launch OpenICLEval[hf_llama-7b/BoolQ] on CPU 
launch OpenICLEval[hf_llama-7b/piqa] on CPU 
launch OpenICLEval[hf_llama-7b/siqa] on CPU 
launch OpenICLEval[hf_llama-7b/hellaswag] on CPU 
launch OpenICLEval[hf_llama-7b/winogrande] on CPU 
launch OpenICLEval[hf_llama-7b/ARC-e] on CPU 
launch OpenICLEval[hf_llama-7b/ARC-c] on CPU 
launch OpenICLEval[hf_llama-7b/openbookqa_fact] on CPU 
launch OpenICLEval[hf_llama-7b/commonsense_qa] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_college_biology] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_college_chemistry] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_college_computer_science] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_college_mathematics] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_college_physics] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_electrical_engineering] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_astronomy] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_anatomy] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_abstract_algebra] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_machine_learning] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_clinical_knowledge] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_global_facts] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_management] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_nutrition] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_marketing] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_professional_accounting] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_high_school_geography] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_international_law] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_moral_scenarios] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_computer_security] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_high_school_microeconomics] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_professional_law] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_medical_genetics] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_professional_psychology] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_jurisprudence] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_world_religions] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_philosophy] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_virology] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_high_school_chemistry] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_public_relations] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_high_school_macroeconomics] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_human_sexuality] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_elementary_mathematics] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_high_school_physics] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_high_school_computer_science] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_high_school_european_history] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_business_ethics] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_moral_disputes] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_high_school_statistics] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_miscellaneous] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_formal_logic] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_high_school_government_and_politics] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_prehistory] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_security_studies] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_high_school_biology] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_logical_fallacies] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_high_school_world_history] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_professional_medicine] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_high_school_mathematics] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_college_medicine] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_high_school_us_history] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_sociology] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_econometrics] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_high_school_psychology] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_human_aging] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_us_foreign_policy] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_conceptual_physics] on CPU 
launch OpenICLEval[hf_llama-7b/openai_humaneval] on CPU 
launch OpenICLEval[hf_llama-7b/mbpp] on CPU 
launch OpenICLEval[hf_llama-7b/triviaqa] on CPU 
launch OpenICLEval[hf_llama-7b/triviaqa_1shot] on CPU 
launch OpenICLEval[hf_llama-7b/triviaqa_5shot] on CPU 
launch OpenICLEval[hf_llama-7b/squad2.0] on CPU 
launch OpenICLEval[hf_llama-7b/gsm8k] on CPU 
launch OpenICLEval[hf_llama-7b/math] on CPU 
launch OpenICLEval[hf_llama-7b/TheoremQA] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-computer_network] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-operating_system] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-computer_architecture] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-college_programming] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-college_physics] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-college_chemistry] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-advanced_mathematics] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-probability_and_statistics] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-discrete_mathematics] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-electrical_engineer] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-metrology_engineer] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-high_school_mathematics] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-high_school_physics] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-high_school_chemistry] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-high_school_biology] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-middle_school_mathematics] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-middle_school_biology] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-middle_school_physics] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-middle_school_chemistry] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-veterinary_medicine] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-college_economics] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-business_administration] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-marxism] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-mao_zedong_thought] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-education_science] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-teacher_qualification] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-high_school_politics] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-high_school_geography] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-middle_school_politics] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-middle_school_geography] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-modern_chinese_history] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-ideological_and_moral_cultivation] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-logic] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-law] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-chinese_language_and_literature] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-art_studies] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-professional_tour_guide] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-legal_professional] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-high_school_chinese] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-high_school_history] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-middle_school_history] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-civil_servant] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-sports_science] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-plant_protection] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-basic_medicine] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-clinical_medicine] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-urban_and_rural_planner] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-accountant] on CPU 
 49%|████▉     | 95/194 [02:57<01:31,  1.08it/s]                                                 49%|████▉     | 95/194 [02:57<01:31,  1.08it/s]                                                 49%|████▉     | 95/194 [02:57<01:31,  1.08it/s]                                                 49%|████▉     | 95/194 [02:58<01:31,  1.08it/s] 49%|████▉     | 96/194 [03:00<02:48,  1.72s/it]                                                 49%|████▉     | 96/194 [03:00<02:48,  1.72s/it] 50%|█████     | 97/194 [03:01<02:28,  1.54s/it]                                                 50%|█████     | 97/194 [03:01<02:28,  1.54s/it] 51%|█████     | 98/194 [03:01<02:07,  1.33s/it] 51%|█████     | 99/194 [03:02<01:30,  1.05it/s]                                                 52%|█████▏    | 100/194 [03:02<01:18,  1.20it/s]                                                  53%|█████▎    | 102/194 [03:04<00:56,  1.63it/s] 53%|█████▎    | 102/194 [03:04<00:56,  1.63it/s] 53%|█████▎    | 102/194 [03:05<00:56,  1.63it/s] 53%|█████▎    | 102/194 [03:05<00:56,  1.63it/s]                                                  53%|█████▎    | 103/194 [03:05<01:21,  1.12it/s]                                                  54%|█████▎    | 104/194 [03:06<01:34,  1.04s/it]                                                  54%|█████▍    | 105/194 [03:06<01:38,  1.11s/it] 54%|█████▍    | 105/194 [03:07<01:38,  1.11s/it] 54%|█████▍    | 105/194 [03:07<01:38,  1.11s/it]                                                  54%|█████▍    | 105/194 [03:08<01:38,  1.11s/it]                                                  54%|█████▍    | 105/194 [03:10<01:38,  1.11s/it] 54%|█████▍    | 105/194 [03:10<01:38,  1.11s/it]                                                  55%|█████▍    | 106/194 [03:11<02:22,  1.62s/it] 55%|█████▍    | 106/194 [03:12<02:22,  1.62s/it]                                                  55%|█████▍    | 106/194 [03:12<02:22,  1.62s/it] 55%|█████▌    | 107/194 [03:18<04:07,  2.84s/it]                                                  55%|█████▌    | 107/194 [03:19<04:07,  2.84s/it] 56%|█████▌    | 108/194 [03:28<06:07,  4.27s/it]                                                  56%|█████▌    | 108/194 [03:28<06:07,  4.27s/it] 56%|█████▌    | 109/194 [03:29<04:56,  3.49s/it]                                                  56%|█████▌    | 109/194 [03:29<04:56,  3.49s/it] 57%|█████▋    | 110/194 [03:40<07:40,  5.48s/it]                                                  57%|█████▋    | 110/194 [03:40<07:40,  5.48s/it] 57%|█████▋    | 111/194 [03:47<07:52,  5.70s/it]                                                  57%|█████▋    | 111/194 [03:47<07:52,  5.70s/it] 58%|█████▊    | 112/194 [03:48<06:00,  4.40s/it]                                                  58%|█████▊    | 112/194 [03:48<06:00,  4.40s/it] 58%|█████▊    | 113/194 [03:49<04:43,  3.50s/it]                                                  58%|█████▊    | 113/194 [03:50<04:43,  3.50s/it] 59%|█████▉    | 114/194 [03:54<05:21,  4.02s/it] 59%|█████▉    | 115/194 [03:55<04:31,  3.44s/it]                                                  59%|█████▉    | 115/194 [03:55<04:31,  3.44s/it]                                                  59%|█████▉    | 115/194 [03:55<04:31,  3.44s/it] 60%|█████▉    | 116/194 [03:55<03:42,  2.86s/it]                                                  60%|██████    | 117/194 [03:56<02:48,  2.18s/it] 60%|██████    | 117/194 [03:56<02:48,  2.18s/it]                                                  61%|██████    | 118/194 [03:57<02:20,  1.85s/it] 61%|██████    | 118/194 [03:57<02:20,  1.85s/it]                                                  61%|██████    | 118/194 [03:57<02:20,  1.85s/it] 61%|██████▏   | 119/194 [03:59<02:33,  2.04s/it]                                                  61%|██████▏   | 119/194 [03:59<02:33,  2.04s/it] 62%|██████▏   | 120/194 [04:01<02:35,  2.10s/it] 62%|██████▏   | 121/194 [04:02<02:04,  1.71s/it]                                                  62%|██████▏   | 121/194 [04:02<02:04,  1.71s/it]                                                  63%|██████▎   | 123/194 [04:04<01:53,  1.60s/it] 64%|██████▍   | 124/194 [04:04<01:30,  1.29s/it] 64%|██████▍   | 124/194 [04:05<01:30,  1.29s/it] 64%|██████▍   | 124/194 [04:05<01:30,  1.29s/it]                                                  64%|██████▍   | 124/194 [04:06<01:30,  1.29s/it]                                                  64%|██████▍   | 125/194 [04:06<01:32,  1.34s/it]                                                  64%|██████▍   | 125/194 [04:06<01:32,  1.34s/it] 64%|██████▍   | 125/194 [04:07<01:32,  1.34s/it]                                                  64%|██████▍   | 125/194 [04:08<01:32,  1.34s/it] 65%|██████▍   | 126/194 [04:12<02:35,  2.29s/it] 65%|██████▌   | 127/194 [04:13<02:51,  2.56s/it]                                                  66%|██████▌   | 128/194 [04:13<02:28,  2.24s/it]                                                  66%|██████▋   | 129/194 [04:14<01:49,  1.69s/it] 66%|██████▋   | 129/194 [04:14<01:49,  1.69s/it] 68%|██████▊   | 131/194 [04:14<01:20,  1.28s/it] 68%|██████▊   | 131/194 [04:14<01:20,  1.28s/it]                                                  68%|██████▊   | 131/194 [04:14<01:20,  1.28s/it] 68%|██████▊   | 131/194 [04:15<01:20,  1.28s/it]                                                  68%|██████▊   | 131/194 [04:15<01:20,  1.28s/it]                                                  68%|██████▊   | 131/194 [04:15<01:20,  1.28s/it]                                                  68%|██████▊   | 131/194 [04:16<01:20,  1.28s/it] 68%|██████▊   | 132/194 [04:18<01:52,  1.82s/it] 69%|██████▊   | 133/194 [04:19<02:00,  1.97s/it]                                                  69%|██████▊   | 133/194 [04:20<02:00,  1.97s/it]                                                  70%|██████▉   | 135/194 [04:20<01:21,  1.39s/it] 70%|███████   | 136/194 [04:20<00:58,  1.02s/it] 70%|███████   | 136/194 [04:21<00:58,  1.02s/it] 70%|███████   | 136/194 [04:21<00:58,  1.02s/it]                                                  71%|███████   | 137/194 [04:22<01:00,  1.07s/it]                                                  71%|███████   | 137/194 [04:22<01:00,  1.07s/it]                                                  71%|███████   | 137/194 [04:24<01:00,  1.07s/it] 71%|███████   | 138/194 [04:24<01:19,  1.41s/it] 71%|███████   | 138/194 [04:25<01:19,  1.41s/it]                                                  71%|███████   | 138/194 [04:26<01:19,  1.41s/it]                                                  71%|███████   | 138/194 [04:27<01:19,  1.41s/it] 72%|███████▏  | 139/194 [04:36<03:00,  3.28s/it]                                                  72%|███████▏  | 139/194 [04:36<03:00,  3.28s/it] 72%|███████▏  | 140/194 [04:38<02:43,  3.03s/it]                                                  72%|███████▏  | 140/194 [04:38<02:43,  3.03s/it] 73%|███████▎  | 141/194 [04:41<02:41,  3.05s/it]                                                  73%|███████▎  | 141/194 [04:41<02:41,  3.05s/it] 73%|███████▎  | 142/194 [04:54<04:49,  5.56s/it]                                                  73%|███████▎  | 142/194 [04:55<04:49,  5.56s/it] 74%|███████▎  | 143/194 [04:59<04:39,  5.47s/it]                                                  74%|███████▎  | 143/194 [04:59<04:39,  5.47s/it] 74%|███████▍  | 144/194 [05:00<03:29,  4.20s/it]                                                  74%|███████▍  | 144/194 [05:00<03:29,  4.20s/it] 75%|███████▍  | 145/194 [05:00<02:30,  3.07s/it]                                                  75%|███████▍  | 145/194 [05:01<02:30,  3.07s/it] 75%|███████▌  | 146/194 [05:02<02:10,  2.72s/it]                                                  75%|███████▌  | 146/194 [05:03<02:10,  2.72s/it] 76%|███████▌  | 147/194 [05:03<01:41,  2.16s/it]                                                  76%|███████▌  | 147/194 [05:03<01:41,  2.16s/it] 76%|███████▋  | 148/194 [05:04<01:25,  1.86s/it]                                                  76%|███████▋  | 148/194 [05:06<01:25,  1.86s/it] 77%|███████▋  | 149/194 [05:06<01:26,  1.93s/it]                                                  77%|███████▋  | 149/194 [05:07<01:26,  1.93s/it] 77%|███████▋  | 150/194 [05:08<01:26,  1.96s/it]                                                  77%|███████▋  | 150/194 [05:09<01:26,  1.96s/it] 78%|███████▊  | 151/194 [05:12<01:50,  2.56s/it]                                                  78%|███████▊  | 152/194 [05:13<01:21,  1.93s/it] 78%|███████▊  | 152/194 [05:13<01:21,  1.93s/it]                                                  78%|███████▊  | 152/194 [05:13<01:21,  1.93s/it] 79%|███████▉  | 153/194 [05:14<01:14,  1.82s/it] 79%|███████▉  | 154/194 [05:16<00:54,  1.36s/it]                                                  80%|████████  | 156/194 [05:17<00:54,  1.43s/it]                                                  80%|████████  | 156/194 [05:17<00:54,  1.43s/it] 80%|████████  | 156/194 [05:17<00:54,  1.43s/it] 80%|████████  | 156/194 [05:17<00:54,  1.43s/it]                                                  80%|████████  | 156/194 [05:18<00:54,  1.43s/it]                                                  81%|████████  | 157/194 [05:18<00:51,  1.38s/it] 81%|████████  | 157/194 [05:18<00:51,  1.38s/it]                                                  81%|████████  | 157/194 [05:18<00:51,  1.38s/it] 81%|████████▏ | 158/194 [05:19<00:43,  1.21s/it]                                                  81%|████████▏ | 158/194 [05:19<00:43,  1.21s/it] 82%|████████▏ | 159/194 [05:19<00:36,  1.04s/it]                                                  82%|████████▏ | 159/194 [05:20<00:36,  1.04s/it] 82%|████████▏ | 160/194 [05:22<00:54,  1.61s/it] 83%|████████▎ | 161/194 [05:23<00:53,  1.61s/it]                                                  84%|████████▍ | 163/194 [05:23<00:31,  1.00s/it]                                                  84%|████████▍ | 163/194 [05:24<00:31,  1.00s/it] 85%|████████▍ | 164/194 [05:24<00:24,  1.23it/s] 85%|████████▍ | 164/194 [05:25<00:24,  1.23it/s] 85%|████████▍ | 164/194 [05:25<00:24,  1.23it/s]                                                  85%|████████▍ | 164/194 [05:25<00:24,  1.23it/s] 85%|████████▌ | 165/194 [05:29<00:43,  1.51s/it] 86%|████████▌ | 166/194 [05:29<00:37,  1.34s/it] 86%|████████▌ | 167/194 [05:31<00:36,  1.36s/it] 87%|████████▋ | 168/194 [05:31<00:28,  1.09s/it] 87%|████████▋ | 169/194 [05:37<00:59,  2.37s/it] 88%|████████▊ | 170/194 [05:43<01:16,  3.19s/it] 88%|████████▊ | 171/194 [05:48<01:26,  3.74s/it] 89%|████████▊ | 172/194 [05:48<01:00,  2.74s/it] 89%|████████▉ | 173/194 [05:49<00:48,  2.32s/it] 90%|████████▉ | 174/194 [05:53<00:51,  2.60s/it] 90%|█████████ | 175/194 [05:53<00:38,  2.04s/it] 91%|█████████ | 176/194 [05:59<00:54,  3.02s/it] 91%|█████████ | 177/194 [06:01<00:50,  2.96s/it] 92%|█████████▏| 178/194 [06:02<00:36,  2.26s/it] 92%|█████████▏| 179/194 [06:03<00:28,  1.91s/it] 93%|█████████▎| 180/194 [06:05<00:26,  1.87s/it] 93%|█████████▎| 181/194 [06:06<00:19,  1.54s/it] 94%|█████████▍| 182/194 [06:07<00:17,  1.45s/it] 94%|█████████▍| 183/194 [06:08<00:14,  1.28s/it] 95%|█████████▌| 185/194 [06:08<00:07,  1.23it/s] 96%|█████████▌| 186/194 [06:09<00:06,  1.20it/s] 96%|█████████▋| 187/194 [06:10<00:05,  1.33it/s] 97%|█████████▋| 188/194 [06:10<00:04,  1.48it/s] 97%|█████████▋| 189/194 [06:11<00:03,  1.64it/s] 98%|█████████▊| 191/194 [06:11<00:01,  2.51it/s] 99%|█████████▉| 192/194 [06:11<00:00,  2.48it/s] 99%|█████████▉| 193/194 [06:12<00:00,  2.70it/s]100%|██████████| 194/194 [06:12<00:00,  2.93it/s]100%|██████████| 194/194 [06:12<00:00,  1.92s/it]
launch OpenICLEval[hf_llama-7b/ceval-fire_engineer] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-environmental_impact_assessment_engineer] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-tax_accountant] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-physician] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-agronomy] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-anatomy] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-ancient_chinese] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-arts] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-astronomy] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-business_ethics] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-chinese_civil_service_exam] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-chinese_food_culture] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-chinese_driving_rule] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-chinese_foreign_policy] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-chinese_history] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-chinese_literature] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-chinese_teacher_qualification] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-clinical_knowledge] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-college_actuarial_science] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-college_education] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-college_engineering_hydrology] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-college_law] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-college_mathematics] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-college_medical_statistics] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-college_medicine] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-computer_science] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-computer_security] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-conceptual_physics] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-construction_project_management] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-economics] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-education] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-electrical_engineering] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-elementary_chinese] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-elementary_commonsense] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-elementary_information_and_technology] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-elementary_mathematics] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-ethnology] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-food_science] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-genetics] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-global_facts] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-high_school_biology] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-high_school_chemistry] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-high_school_geography] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-high_school_mathematics] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-high_school_physics] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-high_school_politics] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-human_sexuality] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-international_law] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-journalism] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-jurisprudence] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-legal_and_moral_basis] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-logical] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-machine_learning] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-management] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-marketing] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-marxist_theory] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-modern_chinese] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-nutrition] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-philosophy] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-professional_accounting] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-professional_law] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-professional_medicine] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-professional_psychology] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-public_relations] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-security_study] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-sociology] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-sports_science] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-traditional_chinese_medicine] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-virology] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-world_history] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-world_religions] on CPU 
dataset                       version    metric         mode    hf_llama-7b
----------------------------  ---------  -------------  ------  -------------
------- MMLU details -------  -          -              -       -
mmlu-humanities               -          -              -       -
mmlu-stem                     -          naive_average  ppl     31.12
mmlu-social-science           -          -              -       -
mmlu-other                    -          -              -       -
mmlu                          -          -              -       -
---- Standard Benchmarks ---  -          -              -       -
BoolQ                         314797     accuracy       ppl     75.50
piqa                          -          -              -       -
siqa                          -          -              -       -
hellaswag                     -          -              -       -
winogrande                    -          -              -       -
ARC-e                         -          -              -       -
ARC-c                         2ef631     accuracy       ppl     32.20
openbookqa_fact               6aac9e     accuracy       ppl     29.80
commonsense_qa                -          -              -       -
mmlu                          -          -              -       -
------ Code Generation -----  -          -              -       -
openai_humaneval              -          -              -       -
mbpp                          -          -              -       -
------ World Knowledge -----  -          -              -       -
triviaqa                      -          -              -       -
--- Reading Comprehension --  -          -              -       -
squad2.0                      1710bc     score          gen     35.00
---------- Exams -----------  -          -              -       -
math                          -          -              -       -
gsm8k                         -          -              -       -
TheoremQA                     -          -              -       -
--------- Chinese ----------  -          -              -       -
ceval                         -          naive_average  ppl     27.38
ceval-stem                    -          naive_average  ppl     26.90
ceval-social-science          -          naive_average  ppl     29.68
ceval-humanities              -          naive_average  ppl     24.18
ceval-other                   -          naive_average  ppl     29.36
ceval-hard                    -          naive_average  ppl     27.68
ceval-test-stem               -          -              -       -
ceval-test-social-science     -          -              -       -
ceval-test-humanities         -          -              -       -
ceval-test-other              -          -              -       -
ceval-test-hard               -          -              -       -
ceval-test                    -          -              -       -
cmmlu                         -          -              -       -
cmmlu-humanities              -          -              -       -
cmmlu-stem                    -          naive_average  ppl     25.34
cmmlu-social-science          -          naive_average  ppl     27.31
cmmlu-other                   -          naive_average  ppl     27.62
cmmlu-china-specific          -          naive_average  ppl     25.62
11/13 05:27:52 - OpenCompass - INFO - write summary to /home/hkustadmin/evaluation/opencompass/outputs/default/20231113_014431/summary/summary_20231113_014431.txt
11/13 05:27:52 - OpenCompass - INFO - write csv to /home/hkustadmin/evaluation/opencompass/outputs/default/20231113_014431/summary/summary_20231113_014431.csv
11/13 16:46:13 - OpenCompass - WARNING - SlurmRunner is not used, so the partition argument is ignored.
11/13 16:46:13 - OpenCompass - INFO - Partitioned into 62 tasks.
  0%|          | 0/62 [00:00<?, ?it/s]                                        0%|          | 0/62 [00:00<?, ?it/s]                                        0%|          | 0/62 [00:00<?, ?it/s]                                        0%|          | 0/62 [00:00<?, ?it/s]                                        0%|          | 0/62 [00:00<?, ?it/s]                                        0%|          | 0/62 [00:00<?, ?it/s]                                        0%|          | 0/62 [00:00<?, ?it/s]                                        0%|          | 0/62 [00:00<?, ?it/s]                                        0%|          | 0/62 [00:00<?, ?it/s]  2%|▏         | 1/62 [22:26<22:49:26, 1346.99s/it]                                                     2%|▏         | 1/62 [22:26<22:49:26, 1346.99s/it]  3%|▎         | 2/62 [22:37<9:20:45, 560.76s/it]                                                     3%|▎         | 2/62 [22:37<9:20:45, 560.76s/it]  5%|▍         | 3/62 [22:42<5:01:51, 306.98s/it]                                                   5%|▍         | 3/62 [22:42<5:01:51, 306.98s/it]  6%|▋         | 4/62 [22:57<3:05:19, 191.71s/it]                                                   6%|▋         | 4/62 [22:57<3:05:19, 191.71s/it]  8%|▊         | 5/62 [23:42<2:12:02, 138.99s/it]                                                   8%|▊         | 5/62 [23:42<2:12:02, 138.99s/it] 10%|▉         | 6/62 [24:23<1:38:27, 105.48s/it]                                                  10%|▉         | 6/62 [24:23<1:38:27, 105.48s/it] 11%|█▏        | 7/62 [24:33<1:08:05, 74.27s/it]                                                  11%|█▏        | 7/62 [24:33<1:08:05, 74.27s/it] 13%|█▎        | 8/62 [24:43<48:21, 53.73s/it]                                                 13%|█▎        | 8/62 [24:43<48:21, 53.73s/it] 15%|█▍        | 9/62 [43:41<5:46:57, 392.78s/it]                                                  15%|█▍        | 9/62 [43:41<5:46:57, 392.78s/it] 16%|█▌        | 10/62 [43:41<3:55:23, 271.61s/it]                                                   16%|█▌        | 10/62 [43:41<3:55:23, 271.61s/it] 18%|█▊        | 11/62 [43:45<2:41:16, 189.73s/it]                                                   18%|█▊        | 11/62 [43:45<2:41:16, 189.73s/it] 19%|█▉        | 12/62 [44:40<2:03:58, 148.76s/it]                                                   19%|█▉        | 12/62 [44:40<2:03:58, 148.76s/it] 21%|██        | 13/62 [45:10<1:32:08, 112.84s/it]                                                   21%|██        | 13/62 [45:10<1:32:08, 112.84s/it] 23%|██▎       | 14/62 [45:20<1:05:18, 81.63s/it]                                                   23%|██▎       | 14/62 [45:20<1:05:18, 81.63s/it] 24%|██▍       | 15/62 [46:21<59:04, 75.42s/it]                                                  24%|██▍       | 15/62 [46:21<59:04, 75.42s/it] 26%|██▌       | 16/62 [46:37<43:59, 57.38s/it]                                                26%|██▌       | 16/62 [46:37<43:59, 57.38s/it] 27%|██▋       | 17/62 [1:02:38<4:07:01, 329.38s/it]                                                     27%|██▋       | 17/62 [1:02:38<4:07:01, 329.38s/it] 29%|██▉       | 18/62 [1:02:50<2:51:31, 233.90s/it]                                                     29%|██▉       | 18/62 [1:02:50<2:51:31, 233.90s/it] 31%|███       | 19/62 [1:03:10<2:01:32, 169.60s/it]                                                     31%|███       | 19/62 [1:03:10<2:01:32, 169.60s/it] 32%|███▏      | 20/62 [1:04:34<1:40:42, 143.88s/it]                                                     32%|███▏      | 20/62 [1:04:34<1:40:42, 143.88s/it] 34%|███▍      | 21/62 [1:04:39<1:09:53, 102.28s/it]                                                     34%|███▍      | 21/62 [1:04:39<1:09:53, 102.28s/it] 35%|███▌      | 22/62 [1:05:08<53:36, 80.41s/it]                                                     35%|███▌      | 22/62 [1:05:08<53:36, 80.41s/it] 37%|███▋      | 23/62 [1:06:15<49:28, 76.12s/it]                                                  37%|███▋      | 23/62 [1:06:15<49:28, 76.12s/it] 39%|███▊      | 24/62 [1:08:00<53:45, 84.88s/it]                                                  39%|███▊      | 24/62 [1:08:00<53:45, 84.88s/it] 40%|████      | 25/62 [1:11:51<1:19:24, 128.76s/it]                                                     40%|████      | 25/62 [1:11:51<1:19:24, 128.76s/it] 42%|████▏     | 26/62 [1:12:57<1:05:58, 109.97s/it]                                                     42%|████▏     | 26/62 [1:12:57<1:05:58, 109.97s/it] 44%|████▎     | 27/62 [1:13:07<46:36, 79.91s/it]                                                     44%|████▎     | 27/62 [1:13:07<46:36, 79.91s/it]launch OpenICLInfer[hf_llama-7b/math_0] on GPU 0
launch OpenICLInfer[hf_llama-7b/math_1] on GPU 1
launch OpenICLInfer[hf_llama-7b/math_2] on GPU 2
launch OpenICLInfer[hf_llama-7b/math_3] on GPU 3
launch OpenICLInfer[hf_llama-7b/math_4] on GPU 4
launch OpenICLInfer[hf_llama-7b/math_5] on GPU 5
launch OpenICLInfer[hf_llama-7b/math_6] on GPU 6
launch OpenICLInfer[hf_llama-7b/math_7] on GPU 7
launch OpenICLInfer[hf_llama-7b/squad2.0_0] on GPU 2
launch OpenICLInfer[hf_llama-7b/squad2.0_1] on GPU 0
launch OpenICLInfer[hf_llama-7b/squad2.0_2] on GPU 4
launch OpenICLInfer[hf_llama-7b/squad2.0_3] on GPU 1
launch OpenICLInfer[hf_llama-7b/squad2.0_4] on GPU 3
launch OpenICLInfer[hf_llama-7b/squad2.0_5] on GPU 7
launch OpenICLInfer[hf_llama-7b/triviaqa_0] on GPU 5
launch OpenICLInfer[hf_llama-7b/triviaqa_1] on GPU 6
launch OpenICLInfer[hf_llama-7b/triviaqa_2] on GPU 6
launch OpenICLInfer[hf_llama-7b/triviaqa_3] on GPU 5
launch OpenICLInfer[hf_llama-7b/triviaqa_4] on GPU 4
launch OpenICLInfer[hf_llama-7b/triviaqa_1shot_0] on GPU 1
launch OpenICLInfer[hf_llama-7b/triviaqa_1shot_1] on GPU 0
launch OpenICLInfer[hf_llama-7b/triviaqa_1shot_2] on GPU 2
launch OpenICLInfer[hf_llama-7b/triviaqa_1shot_3] on GPU 3
launch OpenICLInfer[hf_llama-7b/triviaqa_1shot_4] on GPU 7
launch OpenICLInfer[hf_llama-7b/triviaqa_5shot_0] on GPU 4
launch OpenICLInfer[hf_llama-7b/triviaqa_5shot_1] on GPU 5
launch OpenICLInfer[hf_llama-7b/triviaqa_5shot_2] on GPU 6
launch OpenICLInfer[hf_llama-7b/triviaqa_5shot_3] on GPU 1
launch OpenICLInfer[hf_llama-7b/triviaqa_5shot_4] on GPU 0
launch OpenICLInfer[hf_llama-7b/lukaemon_mmlu_professional_law_0] on GPU 2
launch OpenICLInfer[hf_llama-7b/lukaemon_mmlu_professional_law_1] on GPU 3
launch OpenICLInfer[hf_llama-7b/hellaswag_0] on GPU 7
launch OpenICLInfer[hf_llama-7b/hellaswag_1] on GPU 2
launch OpenICLInfer[hf_llama-7b/TheoremQA,hf_llama-7b/mbpp,hf_llama-7b/cmmlu-professional_law] on GPU 3
launch OpenICLInfer[hf_llama-7b/BoolQ,hf_llama-7b/commonsense_qa,hf_llama-7b/siqa,hf_llama-7b/piqa,hf_llama-7b/lukaemon_mmlu_moral_scenarios,hf_llama-7b/openai_humaneval,hf_llama-7b/lukaemon_mmlu_miscellaneous,hf_llama-7b/winogrande,hf_llama-7b/lukaemon_mmlu_professional_psychology,hf_llama-7b/ARC-e] on GPU 7
11/13 18:01:33 - OpenCompass - WARNING - task OpenICLInfer[hf_llama-7b/BoolQ,hf_llama-7b/commonsense_qa,hf_llama-7b/siqa,hf_llama-7b/piqa,hf_llama-7b/lukaemon_mmlu_moral_scenarios,hf_llama-7b/openai_humaneval,hf_llama-7b/lukaemon_mmlu_miscellaneous,hf_llama-7b/winogrande,hf_llama-7b/lukaemon_mmlu_professional_psychology,hf_llama-7b/ARC-e] fail, see
./outputs/default/20231113_164612/logs/infer/hf_llama-7b/BoolQ.out
 45%|████▌     | 28/62 [1:15:19<54:11, 95.64s/it]                                                  45%|████▌     | 28/62 [1:15:19<54:11, 95.64s/it] 47%|████▋     | 29/62 [1:17:28<58:06, 105.64s/it]                                                   47%|████▋     | 29/62 [1:17:28<58:06, 105.64s/it] 48%|████▊     | 30/62 [1:21:48<1:21:02, 151.97s/it]                                                     48%|████▊     | 30/62 [1:21:48<1:21:02, 151.97s/it] 50%|█████     | 31/62 [1:23:07<1:07:08, 129.96s/it]                                                     50%|█████     | 31/62 [1:23:07<1:07:08, 129.96s/it] 52%|█████▏    | 32/62 [1:24:13<55:20, 110.69s/it]                                                     52%|█████▏    | 32/62 [1:24:13<55:20, 110.69s/it] 53%|█████▎    | 33/62 [1:24:38<41:10, 85.17s/it]                                                   53%|█████▎    | 33/62 [1:24:38<41:10, 85.17s/it] 55%|█████▍    | 34/62 [1:24:42<28:22, 60.80s/it]                                                  55%|█████▍    | 34/62 [1:24:42<28:22, 60.80s/it] 56%|█████▋    | 35/62 [1:35:24<1:45:49, 235.18s/it]                                                     56%|█████▋    | 35/62 [1:35:25<1:45:49, 235.18s/it] 58%|█████▊    | 36/62 [1:42:09<2:03:58, 286.09s/it]                                                     58%|█████▊    | 36/62 [1:42:09<2:03:58, 286.09s/it] 60%|█████▉    | 37/62 [1:45:25<1:47:58, 259.15s/it]                                                     60%|█████▉    | 37/62 [1:45:26<1:47:58, 259.15s/it] 61%|██████▏   | 38/62 [1:46:47<1:22:19, 205.80s/it]                                                     61%|██████▏   | 38/62 [1:46:47<1:22:19, 205.80s/it] 63%|██████▎   | 39/62 [1:47:01<56:54, 148.44s/it]                                                     63%|██████▎   | 39/62 [1:47:01<56:54, 148.44s/it] 65%|██████▍   | 40/62 [1:47:20<40:07, 109.42s/it]                                                   65%|██████▍   | 40/62 [1:47:20<40:07, 109.42s/it] 66%|██████▌   | 41/62 [1:47:21<26:54, 76.88s/it]                                                   66%|██████▌   | 41/62 [1:47:21<26:54, 76.88s/it] 68%|██████▊   | 42/62 [1:58:03<1:22:09, 246.47s/it]                                                     68%|██████▊   | 42/62 [1:58:03<1:22:09, 246.47s/it] 69%|██████▉   | 43/62 [2:04:33<1:31:39, 289.47s/it]                                                     69%|██████▉   | 43/62 [2:04:33<1:31:39, 289.47s/it] 71%|███████   | 44/62 [2:07:59<1:19:20, 264.46s/it]                                                     71%|███████   | 44/62 [2:08:00<1:19:20, 264.46s/it] 73%|███████▎  | 45/62 [2:09:00<57:40, 203.55s/it]                                                     73%|███████▎  | 45/62 [2:09:01<57:40, 203.55s/it] 74%|███████▍  | 46/62 [2:09:55<42:21, 158.82s/it]                                                   74%|███████▍  | 46/62 [2:09:55<42:21, 158.82s/it] 76%|███████▌  | 47/62 [2:10:15<29:17, 117.17s/it]                                                   76%|███████▌  | 47/62 [2:10:15<29:17, 117.17s/it] 77%|███████▋  | 48/62 [2:10:39<20:49, 89.26s/it]                                                   77%|███████▋  | 48/62 [2:10:39<20:49, 89.26s/it] 79%|███████▉  | 49/62 [2:20:26<51:43, 238.71s/it]                                                   79%|███████▉  | 49/62 [2:20:26<51:43, 238.71s/it] 81%|████████  | 50/62 [2:29:02<1:04:21, 321.78s/it]                                                     81%|████████  | 50/62 [2:29:02<1:04:21, 321.78s/it] 82%|████████▏ | 51/62 [2:30:08<44:55, 245.05s/it]                                                     82%|████████▏ | 51/62 [2:30:08<44:55, 245.05s/it] 84%|████████▍ | 52/62 [2:32:13<34:50, 209.09s/it]                                                   84%|████████▍ | 52/62 [2:32:13<34:50, 209.09s/it] 85%|████████▌ | 53/62 [2:33:03<24:12, 161.38s/it]                                                   85%|████████▌ | 53/62 [2:33:04<24:12, 161.38s/it] 87%|████████▋ | 54/62 [2:33:24<15:54, 119.29s/it]                                                   87%|████████▋ | 54/62 [2:33:25<15:54, 119.29s/it] 89%|████████▊ | 55/62 [2:33:37<10:11, 87.40s/it]  90%|█████████ | 56/62 [2:42:35<22:14, 222.47s/it] 92%|█████████▏| 57/62 [2:50:30<24:51, 298.38s/it] 94%|█████████▎| 58/62 [2:52:42<16:32, 248.24s/it] 95%|█████████▌| 59/62 [2:54:32<10:20, 206.78s/it] 97%|█████████▋| 60/62 [2:56:22<05:55, 177.88s/it] 98%|█████████▊| 61/62 [2:57:18<02:21, 141.30s/it]100%|██████████| 62/62 [3:43:43<00:00, 934.48s/it]100%|██████████| 62/62 [3:43:43<00:00, 216.51s/it]
launch OpenICLInfer[hf_llama-7b/lukaemon_mmlu_high_school_psychology,hf_llama-7b/openbookqa_fact,hf_llama-7b/cmmlu-jurisprudence,hf_llama-7b/lukaemon_mmlu_high_school_macroeconomics,hf_llama-7b/lukaemon_mmlu_elementary_mathematics,hf_llama-7b/cmmlu-professional_medicine,hf_llama-7b/lukaemon_mmlu_moral_disputes,hf_llama-7b/lukaemon_mmlu_prehistory,hf_llama-7b/cmmlu-chinese_history,hf_llama-7b/lukaemon_mmlu_philosophy,hf_llama-7b/lukaemon_mmlu_high_school_biology,hf_llama-7b/lukaemon_mmlu_nutrition,hf_llama-7b/ARC-c,hf_llama-7b/lukaemon_mmlu_professional_accounting,hf_llama-7b/cmmlu-college_medicine,hf_llama-7b/lukaemon_mmlu_professional_medicine,hf_llama-7b/lukaemon_mmlu_high_school_mathematics,hf_llama-7b/lukaemon_mmlu_clinical_knowledge,hf_llama-7b/cmmlu-elementary_chinese,hf_llama-7b/lukaemon_mmlu_security_studies,hf_llama-7b/lukaemon_mmlu_high_school_microeconomics,hf_llama-7b/cmmlu-elementary_information_and_technology,hf_llama-7b/lukaemon_mmlu_high_school_world_history,hf_llama-7b/cmmlu-clinical_knowledge,hf_llama-7b/lukaemon_mmlu_conceptual_physics,hf_llama-7b/lukaemon_mmlu_marketing,hf_llama-7b/cmmlu-professional_psychology,hf_llama-7b/cmmlu-elementary_mathematics,hf_llama-7b/cmmlu-sociology,hf_llama-7b/lukaemon_mmlu_human_aging,hf_llama-7b/lukaemon_mmlu_high_school_statistics,hf_llama-7b/cmmlu-legal_and_moral_basis,hf_llama-7b/cmmlu-management,hf_llama-7b/cmmlu-business_ethics] on GPU 7
launch OpenICLInfer[hf_llama-7b/lukaemon_mmlu_high_school_us_history,hf_llama-7b/cmmlu-chinese_literature,hf_llama-7b/cmmlu-computer_science,hf_llama-7b/lukaemon_mmlu_high_school_chemistry,hf_llama-7b/lukaemon_mmlu_sociology,hf_llama-7b/lukaemon_mmlu_high_school_geography,hf_llama-7b/cmmlu-elementary_commonsense,hf_llama-7b/lukaemon_mmlu_high_school_government_and_politics,hf_llama-7b/cmmlu-marxist_theory,hf_llama-7b/cmmlu-international_law,hf_llama-7b/cmmlu-traditional_chinese_medicine,hf_llama-7b/cmmlu-marketing,hf_llama-7b/cmmlu-chinese_teacher_qualification,hf_llama-7b/cmmlu-genetics,hf_llama-7b/cmmlu-professional_accounting,hf_llama-7b/cmmlu-public_relations,hf_llama-7b/lukaemon_mmlu_college_medicine,hf_llama-7b/cmmlu-electrical_engineering,hf_llama-7b/cmmlu-journalism,hf_llama-7b/lukaemon_mmlu_world_religions,hf_llama-7b/cmmlu-computer_security,hf_llama-7b/cmmlu-agronomy,hf_llama-7b/cmmlu-high_school_biology,hf_llama-7b/cmmlu-virology,hf_llama-7b/lukaemon_mmlu_virology,hf_llama-7b/lukaemon_mmlu_high_school_european_history,hf_llama-7b/cmmlu-astronomy,hf_llama-7b/cmmlu-sports_science,hf_llama-7b/cmmlu-ancient_chinese,hf_llama-7b/cmmlu-high_school_mathematics,hf_llama-7b/lukaemon_mmlu_logical_fallacies,hf_llama-7b/cmmlu-education,hf_llama-7b/cmmlu-world_history,hf_llama-7b/cmmlu-arts,hf_llama-7b/cmmlu-chinese_civil_service_exam,hf_llama-7b/cmmlu-world_religions,hf_llama-7b/cmmlu-economics,hf_llama-7b/lukaemon_mmlu_astronomy,hf_llama-7b/lukaemon_mmlu_high_school_physics,hf_llama-7b/cmmlu-global_facts,hf_llama-7b/cmmlu-anatomy,hf_llama-7b/cmmlu-conceptual_physics,hf_llama-7b/lukaemon_mmlu_electrical_engineering,hf_llama-7b/cmmlu-nutrition,hf_llama-7b/lukaemon_mmlu_college_biology,hf_llama-7b/cmmlu-food_science,hf_llama-7b/cmmlu-high_school_politics,hf_llama-7b/cmmlu-construction_project_management,hf_llama-7b/cmmlu-chinese_food_culture,hf_llama-7b/lukaemon_mmlu_anatomy,hf_llama-7b/cmmlu-ethnology,hf_llama-7b/cmmlu-security_study,hf_llama-7b/cmmlu-high_school_chemistry,hf_llama-7b/lukaemon_mmlu_human_sexuality,hf_llama-7b/cmmlu-chinese_driving_rule,hf_llama-7b/lukaemon_mmlu_formal_logic,hf_llama-7b/cmmlu-human_sexuality,hf_llama-7b/cmmlu-logical,hf_llama-7b/cmmlu-machine_learning,hf_llama-7b/lukaemon_mmlu_international_law,hf_llama-7b/cmmlu-high_school_geography,hf_llama-7b/cmmlu-modern_chinese] on GPU 2
launch OpenICLInfer[hf_llama-7b/lukaemon_mmlu_econometrics,hf_llama-7b/lukaemon_mmlu_machine_learning,hf_llama-7b/lukaemon_mmlu_public_relations,hf_llama-7b/cmmlu-high_school_physics,hf_llama-7b/lukaemon_mmlu_jurisprudence,hf_llama-7b/cmmlu-college_law,hf_llama-7b/cmmlu-chinese_foreign_policy,hf_llama-7b/cmmlu-college_education,hf_llama-7b/cmmlu-college_actuarial_science,hf_llama-7b/cmmlu-college_engineering_hydrology,hf_llama-7b/cmmlu-college_medical_statistics,hf_llama-7b/cmmlu-college_mathematics,hf_llama-7b/cmmlu-philosophy,hf_llama-7b/lukaemon_mmlu_management,hf_llama-7b/lukaemon_mmlu_college_physics,hf_llama-7b/lukaemon_mmlu_college_chemistry,hf_llama-7b/lukaemon_mmlu_college_computer_science,hf_llama-7b/lukaemon_mmlu_college_mathematics,hf_llama-7b/lukaemon_mmlu_abstract_algebra,hf_llama-7b/lukaemon_mmlu_global_facts,hf_llama-7b/lukaemon_mmlu_computer_security,hf_llama-7b/lukaemon_mmlu_medical_genetics,hf_llama-7b/lukaemon_mmlu_high_school_computer_science,hf_llama-7b/lukaemon_mmlu_business_ethics,hf_llama-7b/lukaemon_mmlu_us_foreign_policy,hf_llama-7b/ceval-college_economics,hf_llama-7b/ceval-accountant,hf_llama-7b/ceval-tax_accountant,hf_llama-7b/ceval-physician,hf_llama-7b/ceval-civil_servant,hf_llama-7b/ceval-urban_and_rural_planner,hf_llama-7b/ceval-teacher_qualification,hf_llama-7b/ceval-college_programming,hf_llama-7b/ceval-electrical_engineer,hf_llama-7b/ceval-business_administration,hf_llama-7b/ceval-art_studies,hf_llama-7b/ceval-fire_engineer,hf_llama-7b/ceval-environmental_impact_assessment_engineer,hf_llama-7b/ceval-education_science,hf_llama-7b/ceval-professional_tour_guide,hf_llama-7b/ceval-college_chemistry,hf_llama-7b/ceval-metrology_engineer,hf_llama-7b/ceval-mao_zedong_thought,hf_llama-7b/ceval-law,hf_llama-7b/ceval-veterinary_medicine,hf_llama-7b/ceval-modern_chinese_history,hf_llama-7b/ceval-chinese_language_and_literature,hf_llama-7b/ceval-legal_professional,hf_llama-7b/ceval-logic,hf_llama-7b/ceval-middle_school_history,hf_llama-7b/ceval-plant_protection,hf_llama-7b/ceval-clinical_medicine,hf_llama-7b/ceval-computer_architecture,hf_llama-7b/ceval-middle_school_biology,hf_llama-7b/ceval-middle_school_politics,hf_llama-7b/ceval-middle_school_chemistry,hf_llama-7b/ceval-high_school_history,hf_llama-7b/ceval-computer_network,hf_llama-7b/ceval-operating_system,hf_llama-7b/ceval-college_physics,hf_llama-7b/ceval-advanced_mathematics,hf_llama-7b/ceval-high_school_physics,hf_llama-7b/ceval-high_school_chemistry,hf_llama-7b/ceval-high_school_biology,hf_llama-7b/ceval-middle_school_mathematics,hf_llama-7b/ceval-middle_school_physics,hf_llama-7b/ceval-marxism,hf_llama-7b/ceval-high_school_politics,hf_llama-7b/ceval-high_school_geography,hf_llama-7b/ceval-ideological_and_moral_cultivation,hf_llama-7b/ceval-high_school_chinese,hf_llama-7b/ceval-sports_science,hf_llama-7b/ceval-basic_medicine,hf_llama-7b/ceval-probability_and_statistics,hf_llama-7b/ceval-high_school_mathematics,hf_llama-7b/ceval-discrete_mathematics,hf_llama-7b/ceval-middle_school_geography] on GPU 5
launch OpenICLInfer[hf_llama-7b/gsm8k_3] on GPU 4
launch OpenICLInfer[hf_llama-7b/math_10] on GPU 0
launch OpenICLInfer[hf_llama-7b/math_24] on GPU 6
launch OpenICLInfer[hf_llama-7b/math_17] on GPU 1
launch OpenICLInfer[hf_llama-7b/gsm8k_5] on GPU 5
launch OpenICLInfer[hf_llama-7b/math_8] on GPU 7
launch OpenICLInfer[hf_llama-7b/gsm8k_2] on GPU 4
launch OpenICLInfer[hf_llama-7b/math_18] on GPU 6
launch OpenICLInfer[hf_llama-7b/math_19] on GPU 0
launch OpenICLInfer[hf_llama-7b/math_12] on GPU 2
launch OpenICLInfer[hf_llama-7b/gsm8k_0] on GPU 1
launch OpenICLInfer[hf_llama-7b/gsm8k_1] on GPU 5
launch OpenICLInfer[hf_llama-7b/math_11] on GPU 7
launch OpenICLInfer[hf_llama-7b/gsm8k_4] on GPU 4
launch OpenICLInfer[hf_llama-7b/math_9] on GPU 6
launch OpenICLInfer[hf_llama-7b/math_20] on GPU 1
launch OpenICLInfer[hf_llama-7b/math_23] on GPU 0
launch OpenICLInfer[hf_llama-7b/math_15] on GPU 2
launch OpenICLInfer[hf_llama-7b/math_21] on GPU 5
launch OpenICLInfer[hf_llama-7b/gsm8k_6] on GPU 7
launch OpenICLInfer[hf_llama-7b/math_16] on GPU 4
launch OpenICLInfer[hf_llama-7b/math_13] on GPU 1
launch OpenICLInfer[hf_llama-7b/math_14] on GPU 0
launch OpenICLInfer[hf_llama-7b/math_22] on GPU 6
11/13 20:29:57 - OpenCompass - ERROR - /home/hkustadmin/evaluation/opencompass/opencompass/runners/base.py - summarize - 63 - OpenICLInfer[hf_llama-7b/BoolQ,hf_llama-7b/commonsense_qa,hf_llama-7b/siqa,hf_llama-7b/piqa,hf_llama-7b/lukaemon_mmlu_moral_scenarios,hf_llama-7b/openai_humaneval,hf_llama-7b/lukaemon_mmlu_miscellaneous,hf_llama-7b/winogrande,hf_llama-7b/lukaemon_mmlu_professional_psychology,hf_llama-7b/ARC-e] failed with code 1
11/13 20:29:57 - OpenCompass - INFO - Partitioned into 194 tasks.
  0%|          | 0/194 [00:00<?, ?it/s]                                         0%|          | 0/194 [00:00<?, ?it/s]                                         0%|          | 0/194 [00:00<?, ?it/s]                                         0%|          | 0/194 [00:00<?, ?it/s]                                         0%|          | 0/194 [00:00<?, ?it/s]                                         0%|          | 0/194 [00:00<?, ?it/s]                                         0%|          | 0/194 [00:00<?, ?it/s]                                         0%|          | 0/194 [00:00<?, ?it/s]                                         0%|          | 0/194 [00:00<?, ?it/s]                                         0%|          | 0/194 [00:01<?, ?it/s]                                         0%|          | 0/194 [00:01<?, ?it/s]                                         0%|          | 0/194 [00:01<?, ?it/s]                                         0%|          | 0/194 [00:01<?, ?it/s]                                         0%|          | 0/194 [00:02<?, ?it/s]                                         0%|          | 0/194 [00:02<?, ?it/s]                                         0%|          | 0/194 [00:03<?, ?it/s]                                         0%|          | 0/194 [00:03<?, ?it/s]                                         0%|          | 0/194 [00:03<?, ?it/s]                                         0%|          | 0/194 [00:04<?, ?it/s]                                         0%|          | 0/194 [00:04<?, ?it/s]                                         0%|          | 0/194 [00:04<?, ?it/s]                                         0%|          | 0/194 [00:04<?, ?it/s]                                         0%|          | 0/194 [00:05<?, ?it/s]                                         0%|          | 0/194 [00:06<?, ?it/s]                                         0%|          | 0/194 [00:07<?, ?it/s]                                         0%|          | 0/194 [00:07<?, ?it/s]                                         1%|          | 1/194 [00:08<26:28,  8.23s/it]                                                 2%|▏         | 3/194 [00:09<13:32,  4.25s/it]                                                 2%|▏         | 3/194 [00:10<13:32,  4.25s/it]                                                 2%|▏         | 4/194 [00:11<10:39,  3.36s/it]                                                 2%|▏         | 4/194 [00:12<10:39,  3.36s/it]                                                 2%|▏         | 4/194 [00:12<10:39,  3.36s/it]                                                 2%|▏         | 4/194 [00:13<10:39,  3.36s/it]  2%|▏         | 4/194 [00:13<10:39,  3.36s/it]  2%|▏         | 4/194 [00:14<10:39,  3.36s/it]  2%|▏         | 4/194 [00:15<10:39,  3.36s/it]  2%|▏         | 4/194 [00:15<10:39,  3.36s/it]                                                 3%|▎         | 5/194 [00:16<11:51,  3.77s/it]                                                 3%|▎         | 5/194 [00:17<11:51,  3.77s/it]                                                 3%|▎         | 5/194 [00:17<11:51,  3.77s/it]                                                 3%|▎         | 5/194 [00:19<11:51,  3.77s/it]  3%|▎         | 5/194 [00:19<11:51,  3.77s/it]  3%|▎         | 6/194 [00:20<12:40,  4.05s/it]                                                 3%|▎         | 6/194 [00:20<12:40,  4.05s/it]                                                 3%|▎         | 6/194 [00:21<12:40,  4.05s/it]  4%|▎         | 7/194 [00:25<13:31,  4.34s/it]                                                 4%|▎         | 7/194 [00:26<13:31,  4.34s/it]  4%|▍         | 8/194 [00:31<14:45,  4.76s/it]                                                 4%|▍         | 8/194 [00:32<14:45,  4.76s/it]  5%|▍         | 9/194 [00:32<12:06,  3.93s/it]                                                 5%|▌         | 10/194 [00:33<09:16,  3.02s/it]  5%|▌         | 10/194 [00:33<09:16,  3.02s/it]                                                  5%|▌         | 10/194 [00:33<09:16,  3.02s/it]  6%|▌         | 11/194 [00:34<08:01,  2.63s/it]                                                  6%|▌         | 11/194 [00:34<08:01,  2.63s/it]  6%|▌         | 12/194 [00:36<07:07,  2.35s/it]                                                  7%|▋         | 13/194 [00:36<05:19,  1.77s/it]  7%|▋         | 13/194 [00:36<05:19,  1.77s/it]                                                  7%|▋         | 13/194 [00:37<05:19,  1.77s/it]  7%|▋         | 14/194 [00:37<04:41,  1.56s/it]                                                  7%|▋         | 14/194 [00:37<04:41,  1.56s/it]  8%|▊         | 15/194 [00:38<03:53,  1.30s/it]                                                  8%|▊         | 16/194 [00:38<02:50,  1.04it/s]  8%|▊         | 16/194 [00:38<02:50,  1.04it/s]                                                  8%|▊         | 16/194 [00:38<02:50,  1.04it/s]  9%|▉         | 17/194 [00:39<02:51,  1.03it/s]  9%|▉         | 18/194 [00:40<02:19,  1.26it/s]                                                 10%|█         | 20/194 [00:41<02:13,  1.30it/s]                                                 11%|█         | 21/194 [00:41<01:53,  1.53it/s] 11%|█         | 21/194 [00:41<01:53,  1.53it/s] 11%|█         | 21/194 [00:41<01:53,  1.53it/s] 11%|█         | 21/194 [00:42<01:53,  1.53it/s]                                                 11%|█▏        | 22/194 [00:42<02:16,  1.26it/s]                                                 13%|█▎        | 25/194 [00:44<02:32,  1.11it/s]                                                 13%|█▎        | 26/194 [00:44<02:10,  1.28it/s] 13%|█▎        | 26/194 [00:45<02:10,  1.28it/s] 14%|█▍        | 27/194 [00:45<02:05,  1.33it/s] 14%|█▍        | 27/194 [00:46<02:05,  1.33it/s] 14%|█▍        | 27/194 [00:46<02:05,  1.33it/s] 14%|█▍        | 28/194 [00:46<02:28,  1.12it/s] 15%|█▍        | 29/194 [00:47<02:37,  1.05it/s]                                                 15%|█▍        | 29/194 [00:47<02:37,  1.05it/s]                                                 15%|█▍        | 29/194 [00:48<02:37,  1.05it/s]                                                 15%|█▍        | 29/194 [00:49<02:37,  1.05it/s]                                                 15%|█▍        | 29/194 [00:49<02:37,  1.05it/s] 15%|█▍        | 29/194 [00:49<02:37,  1.05it/s] 15%|█▌        | 30/194 [00:49<03:32,  1.30s/it]                                                 16%|█▌        | 31/194 [00:51<05:04,  1.87s/it]                                                 16%|█▌        | 31/194 [00:52<05:04,  1.87s/it]                                                 16%|█▌        | 31/194 [00:52<05:04,  1.87s/it] 16%|█▌        | 31/194 [00:52<05:04,  1.87s/it]                                                 16%|█▌        | 31/194 [00:53<05:04,  1.87s/it] 16%|█▋        | 32/194 [00:53<05:52,  2.17s/it]                                                 16%|█▋        | 32/194 [00:54<05:52,  2.17s/it] 16%|█▋        | 32/194 [00:54<05:52,  2.17s/it]                                                 16%|█▋        | 32/194 [00:55<05:52,  2.17s/it]                                                 16%|█▋        | 32/194 [00:56<05:52,  2.17s/it] 17%|█▋        | 33/194 [00:57<06:39,  2.48s/it]                                                 18%|█▊        | 34/194 [00:57<05:20,  2.00s/it] 18%|█▊        | 34/194 [00:58<05:20,  2.00s/it]                                                 18%|█▊        | 34/194 [00:59<05:20,  2.00s/it] 18%|█▊        | 35/194 [01:00<05:51,  2.21s/it]                                                 18%|█▊        | 35/194 [01:00<05:51,  2.21s/it] 19%|█▊        | 36/194 [01:01<05:03,  1.92s/it]                                                 19%|█▉        | 37/194 [01:01<03:47,  1.45s/it] 19%|█▉        | 37/194 [01:02<03:47,  1.45s/it]                                                 19%|█▉        | 37/194 [01:02<03:47,  1.45s/it] 20%|█▉        | 38/194 [01:07<06:34,  2.53s/it]                                                 20%|██        | 39/194 [01:07<05:00,  1.94s/it] 20%|██        | 39/194 [01:08<05:00,  1.94s/it]                                                 20%|██        | 39/194 [01:08<05:00,  1.94s/it] 21%|██        | 40/194 [01:09<04:48,  1.87s/it]                                                 21%|██        | 40/194 [01:09<04:48,  1.87s/it] 21%|██        | 41/194 [01:11<05:14,  2.06s/it]                                                 21%|██        | 41/194 [01:11<05:14,  2.06s/it] 22%|██▏       | 42/194 [01:12<04:30,  1.78s/it]                                                 22%|██▏       | 42/194 [01:13<04:30,  1.78s/it] 22%|██▏       | 43/194 [01:16<06:12,  2.46s/it]                                                 22%|██▏       | 43/194 [01:17<06:12,  2.46s/it] 23%|██▎       | 44/194 [01:18<05:10,  2.07s/it] 23%|██▎       | 45/194 [01:18<03:27,  1.39s/it]                                                 23%|██▎       | 45/194 [01:18<03:27,  1.39s/it]                                                 23%|██▎       | 45/194 [01:19<03:27,  1.39s/it] 24%|██▎       | 46/194 [01:19<03:40,  1.49s/it]                                                 24%|██▎       | 46/194 [01:21<03:40,  1.49s/it] 25%|██▌       | 49/194 [01:21<02:10,  1.11it/s] 25%|██▌       | 49/194 [01:22<02:10,  1.11it/s] 25%|██▌       | 49/194 [01:22<02:10,  1.11it/s]                                                 26%|██▌       | 50/194 [01:23<02:15,  1.07it/s]                                                 27%|██▋       | 52/194 [01:23<02:29,  1.06s/it] 27%|██▋       | 52/194 [01:23<02:29,  1.06s/it]                                                 27%|██▋       | 52/194 [01:23<02:29,  1.06s/it] 27%|██▋       | 52/194 [01:24<02:29,  1.06s/it] 27%|██▋       | 52/194 [01:24<02:29,  1.06s/it]                                                 27%|██▋       | 53/194 [01:26<02:24,  1.02s/it]                                                 28%|██▊       | 54/194 [01:26<03:31,  1.51s/it] 28%|██▊       | 54/194 [01:27<03:31,  1.51s/it]                                                 28%|██▊       | 54/194 [01:27<03:31,  1.51s/it] 28%|██▊       | 54/194 [01:27<03:31,  1.51s/it]                                                 28%|██▊       | 54/194 [01:28<03:31,  1.51s/it]                                                 28%|██▊       | 54/194 [01:29<03:31,  1.51s/it] 28%|██▊       | 55/194 [01:29<04:15,  1.84s/it]                                                 28%|██▊       | 55/194 [01:30<04:15,  1.84s/it] 29%|██▉       | 56/194 [01:34<06:07,  2.67s/it]                                                 29%|██▉       | 57/194 [01:34<04:35,  2.01s/it] 29%|██▉       | 57/194 [01:35<04:35,  2.01s/it]                                                 30%|██▉       | 58/194 [01:35<03:39,  1.61s/it] 30%|███       | 59/194 [01:35<02:31,  1.12s/it] 30%|███       | 59/194 [01:36<02:31,  1.12s/it]                                                 31%|███       | 60/194 [01:37<02:54,  1.30s/it] 31%|███▏      | 61/194 [01:37<03:12,  1.45s/it]                                                 31%|███▏      | 61/194 [01:38<03:12,  1.45s/it] 31%|███▏      | 61/194 [01:39<03:12,  1.45s/it]                                                 32%|███▏      | 62/194 [01:39<03:29,  1.59s/it]                                                 32%|███▏      | 63/194 [01:40<03:00,  1.37s/it] 33%|███▎      | 64/194 [01:40<02:36,  1.20s/it] 33%|███▎      | 64/194 [01:40<02:36,  1.20s/it] 33%|███▎      | 64/194 [01:41<02:36,  1.20s/it]                                                 34%|███▎      | 65/194 [01:42<03:21,  1.56s/it]                                                 34%|███▎      | 65/194 [01:43<03:21,  1.56s/it]                                                 35%|███▍      | 67/194 [01:43<03:13,  1.52s/it] 35%|███▍      | 67/194 [01:44<03:13,  1.52s/it] 35%|███▍      | 67/194 [01:44<03:13,  1.52s/it] 35%|███▍      | 67/194 [01:44<03:13,  1.52s/it]                                                 35%|███▍      | 67/194 [01:46<03:13,  1.52s/it]                                                 36%|███▌      | 70/194 [01:47<03:12,  1.55s/it]                                                 36%|███▌      | 70/194 [01:48<03:12,  1.55s/it] 36%|███▌      | 70/194 [01:48<03:12,  1.55s/it] 36%|███▌      | 70/194 [01:48<03:12,  1.55s/it] 36%|███▌      | 70/194 [01:49<03:12,  1.55s/it]                                                 37%|███▋      | 71/194 [01:49<03:21,  1.64s/it]                                                 38%|███▊      | 74/194 [01:51<02:31,  1.26s/it]                                                 38%|███▊      | 74/194 [01:52<02:31,  1.26s/it] 38%|███▊      | 74/194 [01:52<02:31,  1.26s/it] 38%|███▊      | 74/194 [01:52<02:31,  1.26s/it] 39%|███▊      | 75/194 [01:53<02:57,  1.49s/it] 39%|███▊      | 75/194 [01:53<02:57,  1.49s/it]                                                 39%|███▊      | 75/194 [01:54<02:57,  1.49s/it]                                                 39%|███▊      | 75/194 [01:54<02:57,  1.49s/it] 39%|███▊      | 75/194 [01:54<02:57,  1.49s/it]                                                 39%|███▊      | 75/194 [01:56<02:57,  1.49s/it]                                                 39%|███▊      | 75/194 [01:57<02:57,  1.49s/it]                                                 39%|███▊      | 75/194 [01:58<02:57,  1.49s/it] 39%|███▉      | 76/194 [02:17<10:08,  5.16s/it]                                                 39%|███▉      | 76/194 [02:17<10:08,  5.16s/it] 40%|███▉      | 77/194 [02:24<10:58,  5.63s/it] 40%|████      | 78/194 [02:25<09:41,  5.01s/it]                                                 40%|████      | 78/194 [02:26<09:41,  5.01s/it]                                                 40%|████      | 78/194 [02:26<09:41,  5.01s/it] 41%|████      | 79/194 [02:28<09:04,  4.73s/it]                                                 41%|████      | 80/194 [02:28<08:59,  4.73s/it]                                                 41%|████      | 80/194 [02:29<08:59,  4.73s/it] 42%|████▏     | 81/194 [02:30<06:22,  3.38s/it]                                                 42%|████▏     | 81/194 [02:30<06:22,  3.38s/it] 42%|████▏     | 82/194 [02:32<05:38,  3.02s/it]                                                 42%|████▏     | 82/194 [02:32<05:38,  3.02s/it] 43%|████▎     | 83/194 [02:34<05:08,  2.78s/it]                                                 43%|████▎     | 83/194 [02:34<05:08,  2.78s/it] 43%|████▎     | 84/194 [02:35<04:23,  2.39s/it]                                                 43%|████▎     | 84/194 [02:35<04:23,  2.39s/it] 44%|████▍     | 85/194 [02:37<04:21,  2.40s/it]                                                 45%|████▌     | 88/194 [02:38<01:04,  1.64it/s] 46%|████▌     | 89/194 [02:38<00:40,  2.58it/s] 46%|████▌     | 89/194 [02:39<00:40,  2.58it/s] 46%|████▌     | 89/194 [02:39<00:40,  2.58it/s] 46%|████▌     | 89/194 [02:39<00:40,  2.58it/s]                                                 46%|████▋     | 90/194 [02:40<00:58,  1.78it/s]                                                 46%|████▋     | 90/194 [02:40<00:58,  1.78it/s]                                                 47%|████▋     | 91/194 [02:41<01:16,  1.34it/s]                                                 47%|████▋     | 91/194 [02:41<01:16,  1.34it/s] 47%|████▋     | 91/194 [02:42<01:16,  1.34it/s] 47%|████▋     | 92/194 [02:42<01:40,  1.02it/s] 48%|████▊     | 93/194 [02:42<02:05,  1.24s/it]                                                 48%|████▊     | 94/194 [02:44<02:17,  1.37s/it] 48%|████▊     | 94/194 [02:44<02:17,  1.37s/it]                                                 49%|████▉     | 96/194 [02:45<02:37,  1.61s/it]                                                launch OpenICLEval[hf_llama-7b/BoolQ] on CPU 
launch OpenICLEval[hf_llama-7b/piqa] on CPU 
launch OpenICLEval[hf_llama-7b/siqa] on CPU 
launch OpenICLEval[hf_llama-7b/hellaswag] on CPU 
launch OpenICLEval[hf_llama-7b/winogrande] on CPU 
launch OpenICLEval[hf_llama-7b/ARC-e] on CPU 
launch OpenICLEval[hf_llama-7b/ARC-c] on CPU 
launch OpenICLEval[hf_llama-7b/openbookqa_fact] on CPU 
launch OpenICLEval[hf_llama-7b/commonsense_qa] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_college_biology] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_college_chemistry] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_college_computer_science] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_college_mathematics] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_college_physics] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_electrical_engineering] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_astronomy] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_anatomy] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_abstract_algebra] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_machine_learning] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_clinical_knowledge] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_global_facts] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_management] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_nutrition] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_marketing] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_professional_accounting] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_high_school_geography] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_international_law] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_moral_scenarios] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_computer_security] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_high_school_microeconomics] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_professional_law] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_medical_genetics] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_professional_psychology] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_jurisprudence] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_world_religions] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_philosophy] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_virology] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_high_school_chemistry] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_public_relations] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_high_school_macroeconomics] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_human_sexuality] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_elementary_mathematics] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_high_school_physics] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_high_school_computer_science] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_high_school_european_history] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_business_ethics] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_moral_disputes] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_high_school_statistics] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_miscellaneous] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_formal_logic] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_high_school_government_and_politics] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_prehistory] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_security_studies] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_high_school_biology] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_logical_fallacies] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_high_school_world_history] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_professional_medicine] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_high_school_mathematics] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_college_medicine] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_high_school_us_history] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_sociology] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_econometrics] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_high_school_psychology] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_human_aging] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_us_foreign_policy] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_conceptual_physics] on CPU 
launch OpenICLEval[hf_llama-7b/openai_humaneval] on CPU 
launch OpenICLEval[hf_llama-7b/mbpp] on CPU 
launch OpenICLEval[hf_llama-7b/triviaqa] on CPU 
launch OpenICLEval[hf_llama-7b/triviaqa_1shot] on CPU 
launch OpenICLEval[hf_llama-7b/triviaqa_5shot] on CPU 
launch OpenICLEval[hf_llama-7b/squad2.0] on CPU 
launch OpenICLEval[hf_llama-7b/gsm8k] on CPU 
launch OpenICLEval[hf_llama-7b/math] on CPU 
launch OpenICLEval[hf_llama-7b/TheoremQA] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-computer_network] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-operating_system] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-computer_architecture] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-college_programming] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-college_physics] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-college_chemistry] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-advanced_mathematics] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-probability_and_statistics] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-discrete_mathematics] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-electrical_engineer] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-metrology_engineer] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-high_school_mathematics] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-high_school_physics] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-high_school_chemistry] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-high_school_biology] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-middle_school_mathematics] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-middle_school_biology] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-middle_school_physics] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-middle_school_chemistry] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-veterinary_medicine] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-college_economics] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-business_administration] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-marxism] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-mao_zedong_thought] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-education_science] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-teacher_qualification] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-high_school_politics] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-high_school_geography] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-middle_school_politics] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-middle_school_geography] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-modern_chinese_history] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-ideological_and_moral_cultivation] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-logic] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-law] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-chinese_language_and_literature] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-art_studies] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-professional_tour_guide] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-legal_professional] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-high_school_chinese] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-high_school_history] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-middle_school_history] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-civil_servant] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-sports_science] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-plant_protection] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-basic_medicine] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-clinical_medicine] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-urban_and_rural_planner] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-accountant] on CPU 
 49%|████▉     | 96/194 [02:46<02:37,  1.61s/it] 50%|█████     | 97/194 [02:47<02:48,  1.74s/it] 50%|█████     | 97/194 [02:47<02:48,  1.74s/it]                                                 50%|█████     | 97/194 [02:47<02:48,  1.74s/it] 50%|█████     | 97/194 [02:47<02:48,  1.74s/it] 50%|█████     | 97/194 [02:48<02:48,  1.74s/it]                                                 50%|█████     | 97/194 [02:48<02:48,  1.74s/it]                                                 50%|█████     | 97/194 [02:49<02:48,  1.74s/it]                                                 50%|█████     | 97/194 [02:50<02:48,  1.74s/it]                                                 50%|█████     | 97/194 [02:50<02:48,  1.74s/it] 51%|█████     | 98/194 [02:51<03:46,  2.36s/it]                                                 51%|█████     | 98/194 [02:52<03:46,  2.36s/it] 51%|█████     | 99/194 [02:52<03:22,  2.13s/it] 52%|█████▏    | 100/194 [02:54<02:27,  1.57s/it]                                                  54%|█████▎    | 104/194 [02:54<01:05,  1.37it/s]                                                  54%|█████▎    | 104/194 [02:55<01:05,  1.37it/s] 54%|█████▎    | 104/194 [02:55<01:05,  1.37it/s] 54%|█████▎    | 104/194 [02:55<01:05,  1.37it/s] 54%|█████▍    | 105/194 [02:56<01:17,  1.15it/s] 54%|█████▍    | 105/194 [02:56<01:17,  1.15it/s]                                                  54%|█████▍    | 105/194 [02:57<01:17,  1.15it/s] 54%|█████▍    | 105/194 [02:57<01:17,  1.15it/s]                                                  54%|█████▍    | 105/194 [02:59<01:17,  1.15it/s]                                                  54%|█████▍    | 105/194 [03:00<01:17,  1.15it/s]                                                  54%|█████▍    | 105/194 [03:00<01:17,  1.15it/s]                                                  55%|█████▌    | 107/194 [03:00<02:32,  1.76s/it] 55%|█████▌    | 107/194 [03:01<02:32,  1.76s/it] 55%|█████▌    | 107/194 [03:01<02:32,  1.76s/it]                                                  55%|█████▌    | 107/194 [03:02<02:32,  1.76s/it]                                                  55%|█████▌    | 107/194 [03:03<02:32,  1.76s/it] 56%|█████▌    | 108/194 [03:25<08:50,  6.16s/it]                                                  56%|█████▌    | 109/194 [03:26<06:58,  4.93s/it] 56%|█████▌    | 109/194 [03:26<06:58,  4.93s/it]                                                  56%|█████▌    | 109/194 [03:27<06:58,  4.93s/it] 57%|█████▋    | 110/194 [03:27<05:49,  4.16s/it]                                                  57%|█████▋    | 110/194 [03:28<05:49,  4.16s/it] 57%|█████▋    | 111/194 [03:32<05:58,  4.32s/it]                                                  57%|█████▋    | 111/194 [03:33<05:58,  4.32s/it] 58%|█████▊    | 112/194 [03:33<04:34,  3.35s/it]                                                  58%|█████▊    | 112/194 [03:33<04:34,  3.35s/it] 58%|█████▊    | 113/194 [03:34<03:45,  2.79s/it]                                                  58%|█████▊    | 113/194 [03:34<03:45,  2.79s/it] 59%|█████▉    | 114/194 [03:38<04:16,  3.20s/it]                                                  60%|█████▉    | 116/194 [03:39<01:52,  1.44s/it] 60%|█████▉    | 116/194 [03:39<01:52,  1.44s/it] 60%|█████▉    | 116/194 [03:40<01:52,  1.44s/it]                                                  60%|█████▉    | 116/194 [03:40<01:52,  1.44s/it]                                                  60%|██████    | 117/194 [03:41<01:49,  1.43s/it] 60%|██████    | 117/194 [03:41<01:49,  1.43s/it]                                                  60%|██████    | 117/194 [03:42<01:49,  1.43s/it] 61%|██████    | 118/194 [03:48<03:42,  2.93s/it] 61%|██████▏   | 119/194 [03:48<04:01,  3.22s/it]                                                  63%|██████▎   | 122/194 [03:49<01:48,  1.51s/it] 63%|██████▎   | 122/194 [03:49<01:48,  1.51s/it]                                                  63%|██████▎   | 122/194 [03:49<01:48,  1.51s/it] 63%|██████▎   | 122/194 [03:49<01:48,  1.51s/it] 63%|██████▎   | 123/194 [03:50<01:40,  1.42s/it]                                                  63%|██████▎   | 123/194 [03:50<01:40,  1.42s/it]                                                  63%|██████▎   | 123/194 [03:50<01:40,  1.42s/it] 63%|██████▎   | 123/194 [03:51<01:40,  1.42s/it]                                                  64%|██████▍   | 124/194 [03:51<01:35,  1.37s/it]                                                  64%|██████▍   | 124/194 [03:52<01:35,  1.37s/it] 64%|██████▍   | 124/194 [03:52<01:35,  1.37s/it]                                                  65%|██████▌   | 127/194 [03:53<00:57,  1.16it/s] 65%|██████▌   | 127/194 [03:53<00:57,  1.16it/s] 65%|██████▌   | 127/194 [03:53<00:57,  1.16it/s] 65%|██████▌   | 127/194 [03:55<00:57,  1.16it/s]                                                  66%|██████▌   | 128/194 [03:55<01:13,  1.12s/it]                                                  66%|██████▌   | 128/194 [03:56<01:13,  1.12s/it]                                                  67%|██████▋   | 130/194 [03:56<01:16,  1.20s/it] 67%|██████▋   | 130/194 [03:57<01:16,  1.20s/it] 68%|██████▊   | 132/194 [03:57<01:00,  1.02it/s] 68%|██████▊   | 132/194 [03:57<01:00,  1.02it/s] 68%|██████▊   | 132/194 [03:57<01:00,  1.02it/s] 68%|██████▊   | 132/194 [03:58<01:00,  1.02it/s]                                                  68%|██████▊   | 132/194 [03:59<01:00,  1.02it/s]                                                  68%|██████▊   | 132/194 [04:00<01:00,  1.02it/s]                                                  68%|██████▊   | 132/194 [04:01<01:00,  1.02it/s]                                                  68%|██████▊   | 132/194 [04:02<01:00,  1.02it/s]                                                  68%|██████▊   | 132/194 [04:02<01:00,  1.02it/s] 69%|██████▊   | 133/194 [04:04<01:41,  1.67s/it]                                                  69%|██████▉   | 134/194 [04:04<01:29,  1.50s/it] 69%|██████▉   | 134/194 [04:04<01:29,  1.50s/it]                                                  69%|██████▉   | 134/194 [04:06<01:29,  1.50s/it] 70%|██████▉   | 135/194 [04:07<01:36,  1.63s/it]                                                  70%|███████   | 136/194 [04:07<01:20,  1.38s/it] 70%|███████   | 136/194 [04:07<01:20,  1.38s/it]                                                  70%|███████   | 136/194 [04:08<01:20,  1.38s/it] 71%|███████   | 137/194 [04:09<01:30,  1.60s/it]                                                  71%|███████   | 138/194 [04:11<01:19,  1.41s/it] 71%|███████   | 138/194 [04:12<01:19,  1.41s/it]                                                  72%|███████▏  | 139/194 [04:13<01:28,  1.60s/it] 72%|███████▏  | 139/194 [04:13<01:28,  1.60s/it]                                                  72%|███████▏  | 139/194 [04:14<01:28,  1.60s/it] 72%|███████▏  | 140/194 [04:28<04:49,  5.35s/it]                                                  72%|███████▏  | 140/194 [04:28<04:49,  5.35s/it] 73%|███████▎  | 141/194 [04:32<04:25,  5.00s/it]                                                  73%|███████▎  | 142/194 [04:33<03:11,  3.67s/it] 73%|███████▎  | 142/194 [04:33<03:11,  3.67s/it]                                                  73%|███████▎  | 142/194 [04:34<03:11,  3.67s/it] 74%|███████▎  | 143/194 [04:38<03:31,  4.14s/it]                                                  74%|███████▎  | 143/194 [04:38<03:31,  4.14s/it] 74%|███████▍  | 144/194 [04:40<02:57,  3.55s/it] 75%|███████▍  | 145/194 [04:40<01:59,  2.44s/it]                                                  75%|███████▍  | 145/194 [04:41<01:59,  2.44s/it]                                                  75%|███████▍  | 145/194 [04:41<01:59,  2.44s/it] 75%|███████▌  | 146/194 [04:44<02:12,  2.77s/it]                                                  76%|███████▌  | 147/194 [04:44<01:42,  2.18s/it] 76%|███████▌  | 147/194 [04:45<01:42,  2.18s/it]                                                  76%|███████▌  | 147/194 [04:45<01:42,  2.18s/it] 76%|███████▋  | 148/194 [04:50<02:22,  3.10s/it]                                                  76%|███████▋  | 148/194 [04:50<02:22,  3.10s/it] 77%|███████▋  | 149/194 [04:51<01:54,  2.53s/it]                                                  77%|███████▋  | 149/194 [04:51<01:54,  2.53s/it] 77%|███████▋  | 150/194 [04:52<01:32,  2.09s/it]                                                  78%|███████▊  | 151/194 [04:52<01:06,  1.55s/it] 78%|███████▊  | 151/194 [04:52<01:06,  1.55s/it]                                                  78%|███████▊  | 151/194 [04:54<01:06,  1.55s/it] 79%|███████▉  | 154/194 [04:55<00:49,  1.24s/it] 80%|███████▉  | 155/194 [04:55<00:45,  1.16s/it] 80%|███████▉  | 155/194 [04:56<00:45,  1.16s/it]                                                  80%|███████▉  | 155/194 [04:56<00:45,  1.16s/it] 80%|███████▉  | 155/194 [04:56<00:45,  1.16s/it]                                                  80%|███████▉  | 155/194 [04:58<00:45,  1.16s/it]                                                  80%|███████▉  | 155/194 [04:58<00:45,  1.16s/it]                                                  80%|███████▉  | 155/194 [04:58<00:45,  1.16s/it] 80%|████████  | 156/194 [04:58<01:01,  1.61s/it] 81%|████████  | 157/194 [04:59<01:01,  1.65s/it]                                                  81%|████████  | 157/194 [04:59<01:01,  1.65s/it]                                                  81%|████████  | 157/194 [05:00<01:01,  1.65s/it] 81%|████████▏ | 158/194 [05:02<01:10,  1.97s/it]                                                  81%|████████▏ | 158/194 [05:02<01:10,  1.97s/it] 82%|████████▏ | 159/194 [05:02<00:55,  1.60s/it]                                                  82%|████████▏ | 159/194 [05:02<00:55,  1.60s/it] 82%|████████▏ | 160/194 [05:03<00:48,  1.42s/it]                                                  84%|████████▎ | 162/194 [05:03<00:21,  1.48it/s] 84%|████████▍ | 163/194 [05:04<00:13,  2.34it/s] 84%|████████▍ | 163/194 [05:04<00:13,  2.34it/s] 84%|████████▍ | 163/194 [05:06<00:13,  2.34it/s]                                                  85%|████████▍ | 164/194 [05:06<00:23,  1.29it/s]                                                  85%|████████▌ | 165/194 [05:07<00:28,  1.01it/s] 85%|████████▌ | 165/194 [05:07<00:28,  1.01it/s] 86%|████████▌ | 166/194 [05:08<00:32,  1.16s/it] 86%|████████▌ | 166/194 [05:08<00:32,  1.16s/it] 86%|████████▌ | 167/194 [05:11<00:43,  1.63s/it] 87%|████████▋ | 168/194 [05:13<00:46,  1.78s/it] 87%|████████▋ | 169/194 [05:17<00:57,  2.29s/it] 88%|████████▊ | 170/194 [05:17<00:43,  1.83s/it] 88%|████████▊ | 171/194 [05:20<00:43,  1.89s/it] 89%|████████▊ | 172/194 [05:27<01:18,  3.56s/it] 89%|████████▉ | 173/194 [05:31<01:16,  3.64s/it] 90%|████████▉ | 174/194 [05:32<00:54,  2.75s/it] 90%|█████████ | 175/194 [05:32<00:38,  2.00s/it] 91%|█████████ | 176/194 [05:37<00:54,  3.03s/it] 91%|█████████ | 177/194 [05:38<00:39,  2.34s/it] 92%|█████████▏| 178/194 [05:40<00:35,  2.21s/it] 92%|█████████▏| 179/194 [05:40<00:24,  1.64s/it] 93%|█████████▎| 180/194 [05:41<00:18,  1.31s/it] 93%|█████████▎| 181/194 [05:43<00:18,  1.43s/it] 94%|█████████▍| 182/194 [05:44<00:16,  1.36s/it] 94%|█████████▍| 183/194 [05:44<00:11,  1.05s/it] 95%|█████████▍| 184/194 [05:44<00:07,  1.26it/s] 96%|█████████▌| 186/194 [05:46<00:06,  1.17it/s] 97%|█████████▋| 188/194 [05:47<00:04,  1.39it/s] 97%|█████████▋| 189/194 [05:48<00:03,  1.26it/s] 98%|█████████▊| 191/194 [05:48<00:01,  1.97it/s] 99%|█████████▉| 193/194 [05:49<00:00,  2.62it/s]100%|██████████| 194/194 [05:49<00:00,  3.00it/s]100%|██████████| 194/194 [05:49<00:00,  1.80s/it]
launch OpenICLEval[hf_llama-7b/ceval-fire_engineer] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-environmental_impact_assessment_engineer] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-tax_accountant] on CPU 
launch OpenICLEval[hf_llama-7b/ceval-physician] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-agronomy] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-anatomy] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-ancient_chinese] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-arts] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-astronomy] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-business_ethics] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-chinese_civil_service_exam] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-chinese_driving_rule] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-chinese_food_culture] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-chinese_foreign_policy] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-chinese_history] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-chinese_literature] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-chinese_teacher_qualification] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-clinical_knowledge] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-college_actuarial_science] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-college_education] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-college_engineering_hydrology] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-college_law] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-college_mathematics] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-college_medical_statistics] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-college_medicine] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-computer_science] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-computer_security] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-conceptual_physics] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-construction_project_management] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-economics] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-education] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-electrical_engineering] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-elementary_chinese] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-elementary_commonsense] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-elementary_information_and_technology] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-elementary_mathematics] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-ethnology] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-food_science] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-genetics] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-global_facts] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-high_school_biology] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-high_school_chemistry] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-high_school_geography] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-high_school_mathematics] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-high_school_physics] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-high_school_politics] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-human_sexuality] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-international_law] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-journalism] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-jurisprudence] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-legal_and_moral_basis] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-logical] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-machine_learning] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-management] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-marketing] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-marxist_theory] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-modern_chinese] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-nutrition] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-philosophy] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-professional_accounting] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-professional_law] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-professional_medicine] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-professional_psychology] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-public_relations] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-security_study] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-sociology] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-sports_science] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-traditional_chinese_medicine] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-virology] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-world_history] on CPU 
launch OpenICLEval[hf_llama-7b/cmmlu-world_religions] on CPU 
dataset                       version    metric         mode    hf_llama-7b
----------------------------  ---------  -------------  ------  -------------
------- MMLU details -------  -          -              -       -
mmlu-humanities               -          -              -       -
mmlu-stem                     -          naive_average  ppl     31.12
mmlu-social-science           -          -              -       -
mmlu-other                    -          -              -       -
mmlu                          -          -              -       -
---- Standard Benchmarks ---  -          -              -       -
BoolQ                         314797     accuracy       ppl     75.50
piqa                          -          -              -       -
siqa                          -          -              -       -
hellaswag                     a6e128     accuracy       ppl     74.29
winogrande                    -          -              -       -
ARC-e                         -          -              -       -
ARC-c                         2ef631     accuracy       ppl     32.20
openbookqa_fact               6aac9e     accuracy       ppl     29.80
commonsense_qa                -          -              -       -
mmlu                          -          -              -       -
------ Code Generation -----  -          -              -       -
openai_humaneval              -          -              -       -
mbpp                          1e1056     score          gen     17.20
------ World Knowledge -----  -          -              -       -
triviaqa                      2121ce     score          gen     44.26
--- Reading Comprehension --  -          -              -       -
squad2.0                      1710bc     score          gen     35.00
---------- Exams -----------  -          -              -       -
math                          265cce     accuracy       gen     2.88
gsm8k                         1d7fe4     accuracy       gen     10.61
TheoremQA                     ef26ca     accuracy       gen     1.25
--------- Chinese ----------  -          -              -       -
ceval                         -          naive_average  ppl     27.38
ceval-stem                    -          naive_average  ppl     26.90
ceval-social-science          -          naive_average  ppl     29.68
ceval-humanities              -          naive_average  ppl     24.18
ceval-other                   -          naive_average  ppl     29.36
ceval-hard                    -          naive_average  ppl     27.68
ceval-test-stem               -          -              -       -
ceval-test-social-science     -          -              -       -
ceval-test-humanities         -          -              -       -
ceval-test-other              -          -              -       -
ceval-test-hard               -          -              -       -
ceval-test                    -          -              -       -
cmmlu                         -          naive_average  ppl     26.77
cmmlu-humanities              -          naive_average  ppl     26.74
cmmlu-stem                    -          naive_average  ppl     25.34
cmmlu-social-science          -          naive_average  ppl     27.31
cmmlu-other                   -          naive_average  ppl     27.62
cmmlu-china-specific          -          naive_average  ppl     25.62
11/13 20:35:46 - OpenCompass - INFO - write summary to /home/hkustadmin/evaluation/opencompass/outputs/default/20231113_164612/summary/summary_20231113_164612.txt
11/13 20:35:46 - OpenCompass - INFO - write csv to /home/hkustadmin/evaluation/opencompass/outputs/default/20231113_164612/summary/summary_20231113_164612.csv
11/15 14:09:19 - OpenCompass - INFO - Reusing experiements from 20231113_205556
11/15 14:09:20 - OpenCompass - WARNING - SlurmRunner is not used, so the partition argument is ignored.
11/15 14:09:20 - OpenCompass - INFO - Partitioned into 1 tasks.
  0%|          | 0/1 [00:00<?, ?it/s]                                       0%|          | 0/1 [00:00<?, ?it/s]launch OpenICLInfer[hf_llama-7b/commonsense_qa,hf_llama-7b/siqa,hf_llama-7b/piqa,hf_llama-7b/lukaemon_mmlu_moral_scenarios,hf_llama-7b/openai_humaneval,hf_llama-7b/lukaemon_mmlu_miscellaneous,hf_llama-7b/winogrande,hf_llama-7b/lukaemon_mmlu_professional_psychology,hf_llama-7b/ARC-e] on GPU 0
11/15 14:09:38 - OpenCompass - WARNING - task OpenICLInfer[hf_llama-7b/commonsense_qa,hf_llama-7b/siqa,hf_llama-7b/piqa,hf_llama-7b/lukaemon_mmlu_moral_scenarios,hf_llama-7b/openai_humaneval,hf_llama-7b/lukaemon_mmlu_miscellaneous,hf_llama-7b/winogrande,hf_llama-7b/lukaemon_mmlu_professional_psychology,hf_llama-7b/ARC-e] fail, see
./outputs/default/20231113_205556/logs/infer/hf_llama-7b/commonsense_qa.out
100%|██████████| 1/1 [00:17<00:00, 17.13s/it]100%|██████████| 1/1 [00:17<00:00, 17.13s/it]
11/15 14:09:38 - OpenCompass - ERROR - /home/hkustadmin/evaluation/opencompass/opencompass/runners/base.py - summarize - 63 - OpenICLInfer[hf_llama-7b/commonsense_qa,hf_llama-7b/siqa,hf_llama-7b/piqa,hf_llama-7b/lukaemon_mmlu_moral_scenarios,hf_llama-7b/openai_humaneval,hf_llama-7b/lukaemon_mmlu_miscellaneous,hf_llama-7b/winogrande,hf_llama-7b/lukaemon_mmlu_professional_psychology,hf_llama-7b/ARC-e] failed with code 1
11/15 14:09:38 - OpenCompass - INFO - Partitioned into 9 tasks.
  0%|          | 0/9 [00:00<?, ?it/s]                                       0%|          | 0/9 [00:00<?, ?it/s]                                       0%|          | 0/9 [00:00<?, ?it/s]                                       0%|          | 0/9 [00:00<?, ?it/s]                                       0%|          | 0/9 [00:00<?, ?it/s]                                       0%|          | 0/9 [00:00<?, ?it/s]                                       0%|          | 0/9 [00:00<?, ?it/s]                                       0%|          | 0/9 [00:00<?, ?it/s]                                       0%|          | 0/9 [00:00<?, ?it/s]                                       0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:07<00:58,  7.28s/it] 33%|███▎      | 3/9 [00:07<00:12,  2.14s/it] 44%|████▍     | 4/9 [00:09<00:09,  1.87s/it] 56%|█████▌    | 5/9 [00:11<00:07,  1.90s/it] 78%|███████▊  | 7/9 [00:11<00:02,  1.13s/it] 89%|████████▉ | 8/9 [00:12<00:00,  1.11it/s]100%|██████████| 9/9 [00:12<00:00,  1.35s/it]
launch OpenICLEval[hf_llama-7b/piqa] on CPU 
launch OpenICLEval[hf_llama-7b/siqa] on CPU 
launch OpenICLEval[hf_llama-7b/winogrande] on CPU 
launch OpenICLEval[hf_llama-7b/ARC-e] on CPU 
launch OpenICLEval[hf_llama-7b/commonsense_qa] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_moral_scenarios] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_professional_psychology] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_miscellaneous] on CPU 
launch OpenICLEval[hf_llama-7b/openai_humaneval] on CPU 
dataset                       version    metric         mode    hf_llama-7b
----------------------------  ---------  -------------  ------  -------------
------- MMLU details -------  -          -              -       -
mmlu-humanities               -          -              -       -
mmlu-stem                     -          naive_average  ppl     31.12
mmlu-social-science           -          -              -       -
mmlu-other                    -          -              -       -
mmlu                          -          -              -       -
---- Standard Benchmarks ---  -          -              -       -
BoolQ                         314797     accuracy       ppl     75.50
piqa                          -          -              -       -
siqa                          -          -              -       -
hellaswag                     a6e128     accuracy       ppl     74.29
winogrande                    -          -              -       -
ARC-e                         -          -              -       -
ARC-c                         2ef631     accuracy       ppl     32.20
openbookqa_fact               6aac9e     accuracy       ppl     29.80
commonsense_qa                -          -              -       -
mmlu                          -          -              -       -
------ Code Generation -----  -          -              -       -
openai_humaneval              -          -              -       -
mbpp                          1e1056     score          gen     17.20
------ World Knowledge -----  -          -              -       -
triviaqa                      2121ce     score          gen     44.26
--- Reading Comprehension --  -          -              -       -
squad2.0                      1710bc     score          gen     35.00
---------- Exams -----------  -          -              -       -
math                          265cce     accuracy       gen     2.88
gsm8k                         1d7fe4     accuracy       gen     10.61
TheoremQA                     ef26ca     accuracy       gen     1.25
--------- Chinese ----------  -          -              -       -
ceval                         -          naive_average  ppl     27.38
ceval-stem                    -          naive_average  ppl     26.90
ceval-social-science          -          naive_average  ppl     29.68
ceval-humanities              -          naive_average  ppl     24.18
ceval-other                   -          naive_average  ppl     29.36
ceval-hard                    -          naive_average  ppl     27.68
ceval-test-stem               -          -              -       -
ceval-test-social-science     -          -              -       -
ceval-test-humanities         -          -              -       -
ceval-test-other              -          -              -       -
ceval-test-hard               -          -              -       -
ceval-test                    -          -              -       -
cmmlu                         -          naive_average  ppl     26.77
cmmlu-humanities              -          naive_average  ppl     26.74
cmmlu-stem                    -          naive_average  ppl     25.34
cmmlu-social-science          -          naive_average  ppl     27.31
cmmlu-other                   -          naive_average  ppl     27.62
cmmlu-china-specific          -          naive_average  ppl     25.62
11/15 14:09:50 - OpenCompass - INFO - write summary to /home/hkustadmin/evaluation/opencompass/outputs/default/20231113_205556/summary/summary_20231115_140919.txt
11/15 14:09:50 - OpenCompass - INFO - write csv to /home/hkustadmin/evaluation/opencompass/outputs/default/20231113_205556/summary/summary_20231115_140919.csv
11/15 14:17:15 - OpenCompass - INFO - Reusing experiements from 20231113_205556
11/15 14:17:15 - OpenCompass - WARNING - SlurmRunner is not used, so the partition argument is ignored.
11/15 14:17:16 - OpenCompass - INFO - Partitioned into 1 tasks.
  0%|          | 0/1 [00:00<?, ?it/s]                                       0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [54:50<00:00, 3290.26s/it]100%|██████████| 1/1 [54:50<00:00, 3290.26s/it]
launch OpenICLInfer[hf_llama-7b/commonsense_qa,hf_llama-7b/siqa,hf_llama-7b/piqa,hf_llama-7b/lukaemon_mmlu_moral_scenarios,hf_llama-7b/openai_humaneval,hf_llama-7b/lukaemon_mmlu_miscellaneous,hf_llama-7b/winogrande,hf_llama-7b/lukaemon_mmlu_professional_psychology,hf_llama-7b/ARC-e] on GPU 0
11/15 15:12:06 - OpenCompass - INFO - Partitioned into 9 tasks.
  0%|          | 0/9 [00:00<?, ?it/s]                                       0%|          | 0/9 [00:00<?, ?it/s]                                       0%|          | 0/9 [00:00<?, ?it/s]                                       0%|          | 0/9 [00:00<?, ?it/s]                                       0%|          | 0/9 [00:00<?, ?it/s]                                       0%|          | 0/9 [00:00<?, ?it/s]                                       0%|          | 0/9 [00:00<?, ?it/s]                                       0%|          | 0/9 [00:00<?, ?it/s]                                       0%|          | 0/9 [00:00<?, ?it/s]                                       0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:06<00:55,  6.98s/it]launch OpenICLEval[hf_llama-7b/piqa] on CPU 
launch OpenICLEval[hf_llama-7b/siqa] on CPU 
launch OpenICLEval[hf_llama-7b/winogrande] on CPU 
launch OpenICLEval[hf_llama-7b/ARC-e] on CPU 
launch OpenICLEval[hf_llama-7b/commonsense_qa] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_moral_scenarios] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_professional_psychology] on CPU 
launch OpenICLEval[hf_llama-7b/lukaemon_mmlu_miscellaneous] on CPU 
launch OpenICLEval[hf_llama-7b/openai_humaneval] on CPU 
11/15 15:12:14 - OpenCompass - WARNING - task OpenICLEval[hf_llama-7b/openai_humaneval] fail, see
./outputs/default/20231113_205556/logs/eval/hf_llama-7b/openai_humaneval.out
 33%|███▎      | 3/9 [00:07<00:12,  2.13s/it] 44%|████▍     | 4/9 [00:09<00:09,  1.99s/it] 56%|█████▌    | 5/9 [00:10<00:05,  1.47s/it] 67%|██████▋   | 6/9 [00:11<00:04,  1.38s/it] 78%|███████▊  | 7/9 [00:11<00:02,  1.09s/it]100%|██████████| 9/9 [00:11<00:00,  1.66it/s]100%|██████████| 9/9 [00:11<00:00,  1.31s/it]
11/15 15:12:18 - OpenCompass - ERROR - /home/hkustadmin/evaluation/opencompass/opencompass/runners/base.py - summarize - 63 - OpenICLEval[hf_llama-7b/openai_humaneval] failed with code 1
dataset                       version    metric         mode    hf_llama-7b
----------------------------  ---------  -------------  ------  -------------
------- MMLU details -------  -          -              -       -
mmlu-humanities               -          naive_average  ppl     38.66
mmlu-stem                     -          naive_average  ppl     31.12
mmlu-social-science           -          naive_average  ppl     37.73
mmlu-other                    -          naive_average  ppl     36.98
mmlu                          -          naive_average  ppl     35.57
---- Standard Benchmarks ---  -          -              -       -
BoolQ                         314797     accuracy       ppl     75.50
piqa                          0cfff2     accuracy       ppl     78.56
siqa                          e8d8c5     accuracy       ppl     40.84
hellaswag                     a6e128     accuracy       ppl     74.29
winogrande                    55a66e     accuracy       ppl     62.04
ARC-e                         2ef631     accuracy       ppl     34.74
ARC-c                         2ef631     accuracy       ppl     32.20
openbookqa_fact               6aac9e     accuracy       ppl     29.80
commonsense_qa                5545e2     accuracy       ppl     64.62
mmlu                          -          naive_average  ppl     35.57
------ Code Generation -----  -          -              -       -
openai_humaneval              -          -              -       -
mbpp                          1e1056     score          gen     17.20
------ World Knowledge -----  -          -              -       -
triviaqa                      2121ce     score          gen     44.26
--- Reading Comprehension --  -          -              -       -
squad2.0                      1710bc     score          gen     35.00
---------- Exams -----------  -          -              -       -
math                          265cce     accuracy       gen     2.88
gsm8k                         1d7fe4     accuracy       gen     10.61
TheoremQA                     ef26ca     accuracy       gen     1.25
--------- Chinese ----------  -          -              -       -
ceval                         -          naive_average  ppl     27.38
ceval-stem                    -          naive_average  ppl     26.90
ceval-social-science          -          naive_average  ppl     29.68
ceval-humanities              -          naive_average  ppl     24.18
ceval-other                   -          naive_average  ppl     29.36
ceval-hard                    -          naive_average  ppl     27.68
ceval-test-stem               -          -              -       -
ceval-test-social-science     -          -              -       -
ceval-test-humanities         -          -              -       -
ceval-test-other              -          -              -       -
ceval-test-hard               -          -              -       -
ceval-test                    -          -              -       -
cmmlu                         -          naive_average  ppl     26.77
cmmlu-humanities              -          naive_average  ppl     26.74
cmmlu-stem                    -          naive_average  ppl     25.34
cmmlu-social-science          -          naive_average  ppl     27.31
cmmlu-other                   -          naive_average  ppl     27.62
cmmlu-china-specific          -          naive_average  ppl     25.62
11/15 15:12:18 - OpenCompass - INFO - write summary to /home/hkustadmin/evaluation/opencompass/outputs/default/20231113_205556/summary/summary_20231115_141715.txt
11/15 15:12:18 - OpenCompass - INFO - write csv to /home/hkustadmin/evaluation/opencompass/outputs/default/20231113_205556/summary/summary_20231115_141715.csv
11/15 15:14:54 - OpenCompass - INFO - Reusing experiements from 20231113_205556
dataset                       version    metric         mode    hf_llama-7b
----------------------------  ---------  -------------  ------  -------------
------- MMLU details -------  -          -              -       -
mmlu-humanities               -          naive_average  ppl     38.66
mmlu-stem                     -          naive_average  ppl     31.12
mmlu-social-science           -          naive_average  ppl     37.73
mmlu-other                    -          naive_average  ppl     36.98
mmlu                          -          naive_average  ppl     35.57
---- Standard Benchmarks ---  -          -              -       -
BoolQ                         314797     accuracy       ppl     75.50
piqa                          0cfff2     accuracy       ppl     78.56
siqa                          e8d8c5     accuracy       ppl     40.84
hellaswag                     a6e128     accuracy       ppl     74.29
winogrande                    55a66e     accuracy       ppl     62.04
ARC-e                         2ef631     accuracy       ppl     34.74
ARC-c                         2ef631     accuracy       ppl     32.20
openbookqa_fact               6aac9e     accuracy       ppl     29.80
commonsense_qa                5545e2     accuracy       ppl     64.62
mmlu                          -          naive_average  ppl     35.57
------ Code Generation -----  -          -              -       -
openai_humaneval              -          -              -       -
mbpp                          1e1056     score          gen     17.20
------ World Knowledge -----  -          -              -       -
triviaqa                      2121ce     score          gen     44.26
--- Reading Comprehension --  -          -              -       -
squad2.0                      1710bc     score          gen     35.00
---------- Exams -----------  -          -              -       -
math                          265cce     accuracy       gen     2.88
gsm8k                         1d7fe4     accuracy       gen     10.61
TheoremQA                     ef26ca     accuracy       gen     1.25
--------- Chinese ----------  -          -              -       -
ceval                         -          naive_average  ppl     27.38
ceval-stem                    -          naive_average  ppl     26.90
ceval-social-science          -          naive_average  ppl     29.68
ceval-humanities              -          naive_average  ppl     24.18
ceval-other                   -          naive_average  ppl     29.36
ceval-hard                    -          naive_average  ppl     27.68
cmmlu                         -          naive_average  ppl     26.77
cmmlu-humanities              -          naive_average  ppl     26.74
cmmlu-stem                    -          naive_average  ppl     25.34
cmmlu-social-science          -          naive_average  ppl     27.31
cmmlu-other                   -          naive_average  ppl     27.62
cmmlu-china-specific          -          naive_average  ppl     25.62
11/15 15:14:55 - OpenCompass - INFO - write summary to /home/hkustadmin/evaluation/opencompass/outputs/default/20231113_205556/summary/summary_20231115_151454.txt
11/15 15:14:55 - OpenCompass - INFO - write csv to /home/hkustadmin/evaluation/opencompass/outputs/default/20231113_205556/summary/summary_20231115_151454.csv
11/15 15:24:13 - OpenCompass - INFO - Reusing experiements from 20231113_205556
11/15 15:24:14 - OpenCompass - WARNING - SlurmRunner is not used, so the partition argument is ignored.
11/15 15:24:14 - OpenCompass - INFO - Partitioned into 0 tasks.
0it [00:00, ?it/s]0it [00:00, ?it/s]
11/15 15:24:14 - OpenCompass - INFO - Partitioned into 1 tasks.
  0%|          | 0/1 [00:00<?, ?it/s]                                       0%|          | 0/1 [00:00<?, ?it/s]launch OpenICLEval[hf_llama-7b/openai_humaneval] on CPU 
11/15 15:24:21 - OpenCompass - WARNING - task OpenICLEval[hf_llama-7b/openai_humaneval] fail, see
./outputs/default/20231113_205556/logs/eval/hf_llama-7b/openai_humaneval.out
100%|██████████| 1/1 [00:06<00:00,  6.51s/it]100%|██████████| 1/1 [00:06<00:00,  6.51s/it]
11/15 15:24:21 - OpenCompass - ERROR - /home/hkustadmin/evaluation/opencompass/opencompass/runners/base.py - summarize - 63 - OpenICLEval[hf_llama-7b/openai_humaneval] failed with code 1
dataset                       version    metric         mode    hf_llama-7b
----------------------------  ---------  -------------  ------  -------------
------- MMLU details -------  -          -              -       -
mmlu-humanities               -          naive_average  ppl     38.66
mmlu-stem                     -          naive_average  ppl     31.12
mmlu-social-science           -          naive_average  ppl     37.73
mmlu-other                    -          naive_average  ppl     36.98
mmlu                          -          naive_average  ppl     35.57
---- Standard Benchmarks ---  -          -              -       -
BoolQ                         314797     accuracy       ppl     75.50
piqa                          0cfff2     accuracy       ppl     78.56
siqa                          e8d8c5     accuracy       ppl     40.84
hellaswag                     a6e128     accuracy       ppl     74.29
winogrande                    55a66e     accuracy       ppl     62.04
ARC-e                         2ef631     accuracy       ppl     34.74
ARC-c                         2ef631     accuracy       ppl     32.20
openbookqa_fact               6aac9e     accuracy       ppl     29.80
commonsense_qa                5545e2     accuracy       ppl     64.62
mmlu                          -          naive_average  ppl     35.57
------ Code Generation -----  -          -              -       -
openai_humaneval              -          -              -       -
mbpp                          1e1056     score          gen     17.20
------ World Knowledge -----  -          -              -       -
triviaqa                      2121ce     score          gen     44.26
--- Reading Comprehension --  -          -              -       -
squad2.0                      1710bc     score          gen     35.00
---------- Exams -----------  -          -              -       -
math                          265cce     accuracy       gen     2.88
gsm8k                         1d7fe4     accuracy       gen     10.61
TheoremQA                     ef26ca     accuracy       gen     1.25
--------- Chinese ----------  -          -              -       -
ceval                         -          naive_average  ppl     27.38
ceval-stem                    -          naive_average  ppl     26.90
ceval-social-science          -          naive_average  ppl     29.68
ceval-humanities              -          naive_average  ppl     24.18
ceval-other                   -          naive_average  ppl     29.36
ceval-hard                    -          naive_average  ppl     27.68
cmmlu                         -          naive_average  ppl     26.77
cmmlu-humanities              -          naive_average  ppl     26.74
cmmlu-stem                    -          naive_average  ppl     25.34
cmmlu-social-science          -          naive_average  ppl     27.31
cmmlu-other                   -          naive_average  ppl     27.62
cmmlu-china-specific          -          naive_average  ppl     25.62
11/15 15:24:21 - OpenCompass - INFO - write summary to /home/hkustadmin/evaluation/opencompass/outputs/default/20231113_205556/summary/summary_20231115_152413.txt
11/15 15:24:21 - OpenCompass - INFO - write csv to /home/hkustadmin/evaluation/opencompass/outputs/default/20231113_205556/summary/summary_20231115_152413.csv
11/15 15:39:17 - OpenCompass - INFO - Reusing experiements from 20231113_205556
11/15 15:39:18 - OpenCompass - WARNING - SlurmRunner is not used, so the partition argument is ignored.
11/15 15:39:18 - OpenCompass - INFO - Partitioned into 0 tasks.
0it [00:00, ?it/s]0it [00:00, ?it/s]
11/15 15:39:18 - OpenCompass - INFO - Partitioned into 1 tasks.
  0%|          | 0/1 [00:00<?, ?it/s]                                       0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:08<00:00,  8.50s/it]100%|██████████| 1/1 [00:08<00:00,  8.50s/it]
launch OpenICLEval[hf_llama-7b/openai_humaneval] on CPU 
dataset                       version    metric            mode    hf_llama-7b
----------------------------  ---------  ----------------  ------  -------------
------- MMLU details -------  -          -                 -       -
mmlu-humanities               -          naive_average     ppl     38.66
mmlu-stem                     -          naive_average     ppl     31.12
mmlu-social-science           -          naive_average     ppl     37.73
mmlu-other                    -          naive_average     ppl     36.98
mmlu                          -          naive_average     ppl     35.57
---- Standard Benchmarks ---  -          -                 -       -
BoolQ                         314797     accuracy          ppl     75.50
piqa                          0cfff2     accuracy          ppl     78.56
siqa                          e8d8c5     accuracy          ppl     40.84
hellaswag                     a6e128     accuracy          ppl     74.29
winogrande                    55a66e     accuracy          ppl     62.04
ARC-e                         2ef631     accuracy          ppl     34.74
ARC-c                         2ef631     accuracy          ppl     32.20
openbookqa_fact               6aac9e     accuracy          ppl     29.80
commonsense_qa                5545e2     accuracy          ppl     64.62
mmlu                          -          naive_average     ppl     35.57
------ Code Generation -----  -          -                 -       -
openai_humaneval              a82cae     humaneval_pass@1  gen     12.80
mbpp                          1e1056     score             gen     17.20
------ World Knowledge -----  -          -                 -       -
triviaqa                      2121ce     score             gen     44.26
--- Reading Comprehension --  -          -                 -       -
squad2.0                      1710bc     score             gen     35.00
---------- Exams -----------  -          -                 -       -
math                          265cce     accuracy          gen     2.88
gsm8k                         1d7fe4     accuracy          gen     10.61
TheoremQA                     ef26ca     accuracy          gen     1.25
--------- Chinese ----------  -          -                 -       -
ceval                         -          naive_average     ppl     27.38
ceval-stem                    -          naive_average     ppl     26.90
ceval-social-science          -          naive_average     ppl     29.68
ceval-humanities              -          naive_average     ppl     24.18
ceval-other                   -          naive_average     ppl     29.36
ceval-hard                    -          naive_average     ppl     27.68
cmmlu                         -          naive_average     ppl     26.77
cmmlu-humanities              -          naive_average     ppl     26.74
cmmlu-stem                    -          naive_average     ppl     25.34
cmmlu-social-science          -          naive_average     ppl     27.31
cmmlu-other                   -          naive_average     ppl     27.62
cmmlu-china-specific          -          naive_average     ppl     25.62
11/15 15:39:27 - OpenCompass - INFO - write summary to /home/hkustadmin/evaluation/opencompass/outputs/default/20231113_205556/summary/summary_20231115_153917.txt
11/15 15:39:27 - OpenCompass - INFO - write csv to /home/hkustadmin/evaluation/opencompass/outputs/default/20231113_205556/summary/summary_20231115_153917.csv
