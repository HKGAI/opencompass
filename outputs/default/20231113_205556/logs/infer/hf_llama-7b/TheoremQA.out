11/15 11:06:07 - OpenCompass - INFO - Task [hf_llama-7b/TheoremQA,hf_llama-7b/mbpp,hf_llama-7b/cmmlu-professional_law]
You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
11/15 11:06:08 - OpenCompass - WARNING - pad_token_id is not set for the tokenizer.
11/15 11:06:08 - OpenCompass - WARNING - Using eos_token_id </s> as pad_token_id.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]
11/15 11:06:15 - OpenCompass - INFO - Start inferencing [hf_llama-7b/TheoremQA]
[2023-11-15 11:06:16,278] [opencompass.openicl.icl_inferencer.icl_gen_inferencer] [INFO] Starting inference process...
  0%|          | 0/50 [00:00<?, ?it/s]  2%|▏         | 1/50 [01:51<1:30:50, 111.24s/it]  4%|▍         | 2/50 [03:41<1:28:32, 110.68s/it]  6%|▌         | 3/50 [05:31<1:26:34, 110.53s/it]  8%|▊         | 4/50 [07:22<1:24:43, 110.51s/it] 10%|█         | 5/50 [09:13<1:22:56, 110.58s/it] 12%|█▏        | 6/50 [11:03<1:21:05, 110.58s/it] 14%|█▍        | 7/50 [12:54<1:19:21, 110.72s/it] 16%|█▌        | 8/50 [14:45<1:17:32, 110.77s/it] 18%|█▊        | 9/50 [16:36<1:15:40, 110.74s/it] 20%|██        | 10/50 [18:27<1:13:50, 110.77s/it] 22%|██▏       | 11/50 [20:18<1:12:02, 110.84s/it] 24%|██▍       | 12/50 [22:08<1:10:09, 110.76s/it] 26%|██▌       | 13/50 [23:58<1:08:13, 110.63s/it] 28%|██▊       | 14/50 [25:49<1:06:19, 110.55s/it] 30%|███       | 15/50 [27:39<1:04:26, 110.47s/it] 32%|███▏      | 16/50 [29:30<1:02:39, 110.57s/it] 34%|███▍      | 17/50 [31:21<1:00:53, 110.71s/it] 36%|███▌      | 18/50 [33:12<59:06, 110.84s/it]   38%|███▊      | 19/50 [35:03<57:21, 111.00s/it] 40%|████      | 20/50 [36:55<55:33, 111.10s/it] 42%|████▏     | 21/50 [38:47<53:49, 111.37s/it] 44%|████▍     | 22/50 [40:38<51:58, 111.36s/it] 46%|████▌     | 23/50 [42:31<50:15, 111.69s/it] 48%|████▊     | 24/50 [44:28<49:04, 113.26s/it] 50%|█████     | 25/50 [46:21<47:09, 113.18s/it] 52%|█████▏    | 26/50 [48:15<45:22, 113.42s/it] 54%|█████▍    | 27/50 [50:07<43:25, 113.29s/it] 56%|█████▌    | 28/50 [52:00<41:29, 113.16s/it] 58%|█████▊    | 29/50 [53:53<39:36, 113.15s/it] 60%|██████    | 30/50 [55:46<37:39, 112.97s/it] 62%|██████▏   | 31/50 [57:38<35:41, 112.70s/it] 64%|██████▍   | 32/50 [59:30<33:43, 112.41s/it] 66%|██████▌   | 33/50 [1:01:22<31:48, 112.25s/it] 68%|██████▊   | 34/50 [1:03:15<29:58, 112.42s/it] 70%|███████   | 35/50 [1:05:07<28:08, 112.57s/it] 72%|███████▏  | 36/50 [1:07:01<26:19, 112.82s/it] 74%|███████▍  | 37/50 [1:08:54<24:28, 112.98s/it] 76%|███████▌  | 38/50 [1:10:47<22:36, 113.04s/it] 78%|███████▊  | 39/50 [1:12:41<20:44, 113.14s/it] 80%|████████  | 40/50 [1:14:34<18:51, 113.16s/it] 82%|████████▏ | 41/50 [1:16:27<16:59, 113.26s/it] 84%|████████▍ | 42/50 [1:18:21<15:06, 113.29s/it] 86%|████████▌ | 43/50 [1:20:14<13:13, 113.32s/it] 88%|████████▊ | 44/50 [1:22:08<11:20, 113.34s/it] 90%|█████████ | 45/50 [1:24:01<09:26, 113.32s/it] 92%|█████████▏| 46/50 [1:25:54<07:33, 113.34s/it] 94%|█████████▍| 47/50 [1:27:48<05:40, 113.42s/it] 96%|█████████▌| 48/50 [1:29:41<03:46, 113.36s/it] 98%|█████████▊| 49/50 [1:31:35<01:53, 113.40s/it]100%|██████████| 50/50 [1:33:28<00:00, 113.39s/it]100%|██████████| 50/50 [1:33:28<00:00, 112.17s/it]
11/15 12:39:46 - OpenCompass - INFO - Start inferencing [hf_llama-7b/mbpp]
Token indices sequence length is longer than the specified maximum sequence length for this model (4427 > 2048). Running this sequence through the model will result in indexing errors
[2023-11-15 12:39:47,417] [opencompass.openicl.icl_inferencer.icl_gen_inferencer] [INFO] Starting inference process...
  0%|          | 0/32 [00:00<?, ?it/s]  3%|▎         | 1/32 [01:54<59:00, 114.22s/it]  6%|▋         | 2/32 [03:47<56:42, 113.41s/it]  9%|▉         | 3/32 [05:40<54:47, 113.35s/it] 12%|█▎        | 4/32 [07:33<52:56, 113.46s/it] 16%|█▌        | 5/32 [09:27<51:04, 113.49s/it] 19%|█▉        | 6/32 [11:20<49:06, 113.34s/it] 22%|██▏       | 7/32 [13:12<47:02, 112.91s/it] 25%|██▌       | 8/32 [15:04<45:04, 112.69s/it] 28%|██▊       | 9/32 [16:57<43:08, 112.54s/it] 31%|███▏      | 10/32 [18:49<41:18, 112.67s/it] 34%|███▍      | 11/32 [20:42<39:22, 112.48s/it] 38%|███▊      | 12/32 [22:33<37:25, 112.27s/it] 41%|████      | 13/32 [24:26<35:33, 112.31s/it] 44%|████▍     | 14/32 [26:18<33:40, 112.27s/it] 47%|████▋     | 15/32 [28:11<31:51, 112.42s/it] 50%|█████     | 16/32 [30:02<29:55, 112.21s/it] 53%|█████▎    | 17/32 [31:54<28:02, 112.16s/it] 56%|█████▋    | 18/32 [33:47<26:10, 112.20s/it] 59%|█████▉    | 19/32 [35:39<24:18, 112.17s/it] 62%|██████▎   | 20/32 [37:31<22:26, 112.25s/it] 66%|██████▌   | 21/32 [39:23<20:33, 112.14s/it] 69%|██████▉   | 22/32 [41:16<18:42, 112.28s/it] 72%|███████▏  | 23/32 [43:09<16:52, 112.50s/it] 75%|███████▌  | 24/32 [45:03<15:03, 112.91s/it] 78%|███████▊  | 25/32 [46:55<13:09, 112.78s/it] 81%|████████▏ | 26/32 [48:48<11:16, 112.81s/it] 84%|████████▍ | 27/32 [50:42<09:25, 113.04s/it] 88%|████████▊ | 28/32 [52:36<07:33, 113.32s/it] 91%|█████████ | 29/32 [54:29<05:40, 113.36s/it] 94%|█████████▍| 30/32 [56:22<03:46, 113.30s/it] 97%|█████████▋| 31/32 [58:16<01:53, 113.41s/it]100%|██████████| 32/32 [58:44<00:00, 87.90s/it] 100%|██████████| 32/32 [58:44<00:00, 110.15s/it]
11/15 13:38:32 - OpenCompass - INFO - Start inferencing [hf_llama-7b/cmmlu-professional_law]
  0%|          | 0/211 [00:00<?, ?it/s]100%|██████████| 211/211 [00:00<00:00, 4194304.00it/s]
[2023-11-15 13:38:32,566] [opencompass.openicl.icl_inferencer.icl_ppl_inferencer] [INFO] Calculating PPL for prompts labeled 'A'
  0%|          | 0/14 [00:00<?, ?it/s]  7%|▋         | 1/14 [00:00<00:11,  1.15it/s] 14%|█▍        | 2/14 [00:01<00:10,  1.16it/s] 21%|██▏       | 3/14 [00:02<00:09,  1.16it/s] 29%|██▊       | 4/14 [00:03<00:08,  1.17it/s] 36%|███▌      | 5/14 [00:04<00:07,  1.17it/s] 43%|████▎     | 6/14 [00:05<00:06,  1.18it/s] 50%|█████     | 7/14 [00:05<00:05,  1.17it/s] 57%|█████▋    | 8/14 [00:06<00:05,  1.18it/s] 64%|██████▍   | 9/14 [00:07<00:04,  1.17it/s] 71%|███████▏  | 10/14 [00:08<00:03,  1.17it/s] 79%|███████▊  | 11/14 [00:09<00:02,  1.14it/s] 86%|████████▌ | 12/14 [00:10<00:01,  1.14it/s] 93%|█████████▎| 13/14 [00:11<00:00,  1.14it/s]100%|██████████| 14/14 [00:11<00:00,  1.51it/s]100%|██████████| 14/14 [00:11<00:00,  1.23it/s]
[2023-11-15 13:38:44,237] [opencompass.openicl.icl_inferencer.icl_ppl_inferencer] [INFO] Calculating PPL for prompts labeled 'B'
  0%|          | 0/14 [00:00<?, ?it/s]  7%|▋         | 1/14 [00:00<00:11,  1.16it/s] 14%|█▍        | 2/14 [00:01<00:10,  1.16it/s] 21%|██▏       | 3/14 [00:02<00:09,  1.16it/s] 29%|██▊       | 4/14 [00:03<00:08,  1.18it/s] 36%|███▌      | 5/14 [00:04<00:07,  1.17it/s] 43%|████▎     | 6/14 [00:05<00:06,  1.18it/s] 50%|█████     | 7/14 [00:05<00:05,  1.17it/s] 57%|█████▋    | 8/14 [00:06<00:05,  1.18it/s] 64%|██████▍   | 9/14 [00:07<00:04,  1.17it/s] 71%|███████▏  | 10/14 [00:08<00:03,  1.17it/s] 79%|███████▊  | 11/14 [00:09<00:02,  1.14it/s] 86%|████████▌ | 12/14 [00:10<00:01,  1.13it/s] 93%|█████████▎| 13/14 [00:11<00:00,  1.14it/s]100%|██████████| 14/14 [00:11<00:00,  1.51it/s]100%|██████████| 14/14 [00:11<00:00,  1.23it/s]
[2023-11-15 13:38:55,909] [opencompass.openicl.icl_inferencer.icl_ppl_inferencer] [INFO] Calculating PPL for prompts labeled 'C'
  0%|          | 0/14 [00:00<?, ?it/s]  7%|▋         | 1/14 [00:00<00:11,  1.15it/s] 14%|█▍        | 2/14 [00:01<00:10,  1.16it/s] 21%|██▏       | 3/14 [00:02<00:09,  1.16it/s] 29%|██▊       | 4/14 [00:03<00:08,  1.18it/s] 36%|███▌      | 5/14 [00:04<00:07,  1.17it/s] 43%|████▎     | 6/14 [00:05<00:06,  1.18it/s] 50%|█████     | 7/14 [00:05<00:05,  1.17it/s] 57%|█████▋    | 8/14 [00:06<00:05,  1.18it/s] 64%|██████▍   | 9/14 [00:07<00:04,  1.17it/s] 71%|███████▏  | 10/14 [00:08<00:03,  1.17it/s] 79%|███████▊  | 11/14 [00:09<00:02,  1.14it/s] 86%|████████▌ | 12/14 [00:10<00:01,  1.13it/s] 93%|█████████▎| 13/14 [00:11<00:00,  1.14it/s]100%|██████████| 14/14 [00:11<00:00,  1.51it/s]100%|██████████| 14/14 [00:11<00:00,  1.23it/s]
[2023-11-15 13:39:07,585] [opencompass.openicl.icl_inferencer.icl_ppl_inferencer] [INFO] Calculating PPL for prompts labeled 'D'
  0%|          | 0/14 [00:00<?, ?it/s]  7%|▋         | 1/14 [00:00<00:11,  1.16it/s] 14%|█▍        | 2/14 [00:01<00:10,  1.16it/s] 21%|██▏       | 3/14 [00:02<00:09,  1.16it/s] 29%|██▊       | 4/14 [00:03<00:08,  1.17it/s] 36%|███▌      | 5/14 [00:04<00:07,  1.17it/s] 43%|████▎     | 6/14 [00:05<00:06,  1.18it/s] 50%|█████     | 7/14 [00:05<00:05,  1.17it/s] 57%|█████▋    | 8/14 [00:06<00:05,  1.18it/s] 64%|██████▍   | 9/14 [00:07<00:04,  1.17it/s] 71%|███████▏  | 10/14 [00:08<00:03,  1.17it/s] 79%|███████▊  | 11/14 [00:09<00:02,  1.14it/s] 86%|████████▌ | 12/14 [00:10<00:01,  1.14it/s] 93%|█████████▎| 13/14 [00:11<00:00,  1.14it/s]100%|██████████| 14/14 [00:11<00:00,  1.51it/s]100%|██████████| 14/14 [00:11<00:00,  1.23it/s]
11/15 13:39:18 - OpenCompass - INFO - time elapsed: 9191.03s
