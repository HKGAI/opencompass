ARC_c_datasets=[
    dict(abbr='ARC-c',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                template=dict(
                    A=dict(
                        round=[
                            dict(prompt='{question}\nA. {textA}\nB. {textB}\nC. {textC}\nD. {textD}',
                                role='HUMAN'),
                            dict(prompt='Answer: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        round=[
                            dict(prompt='{question}\nA. {textA}\nB. {textB}\nC. {textC}\nD. {textD}',
                                role='HUMAN'),
                            dict(prompt='Answer: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        round=[
                            dict(prompt='{question}\nA. {textA}\nB. {textB}\nC. {textC}\nD. {textD}',
                                role='HUMAN'),
                            dict(prompt='Answer: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        round=[
                            dict(prompt='{question}\nA. {textA}\nB. {textB}\nC. {textC}\nD. {textD}',
                                role='HUMAN'),
                            dict(prompt='Answer: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                type='opencompass.openicl.icl_retriever.ZeroRetriever')),
        path='./data/ARC/ARC-c/ARC-Challenge-Dev.jsonl',
        reader_cfg=dict(
            input_columns=[
                'question',
                'textA',
                'textB',
                'textC',
                'textD',
                ],
            output_column='answerKey'),
        type='opencompass.datasets.ARCDataset'),
    ]
ARC_e_datasets=[
    dict(abbr='ARC-e',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                template=dict(
                    A=dict(
                        round=[
                            dict(prompt='{question}\nA. {textA}\nB. {textB}\nC. {textC}\nD. {textD}',
                                role='HUMAN'),
                            dict(prompt='Answer: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        round=[
                            dict(prompt='{question}\nA. {textA}\nB. {textB}\nC. {textC}\nD. {textD}',
                                role='HUMAN'),
                            dict(prompt='Answer: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        round=[
                            dict(prompt='{question}\nA. {textA}\nB. {textB}\nC. {textC}\nD. {textD}',
                                role='HUMAN'),
                            dict(prompt='Answer: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        round=[
                            dict(prompt='{question}\nA. {textA}\nB. {textB}\nC. {textC}\nD. {textD}',
                                role='HUMAN'),
                            dict(prompt='Answer: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                type='opencompass.openicl.icl_retriever.ZeroRetriever')),
        path='./data/ARC/ARC-e/ARC-Easy-Dev.jsonl',
        reader_cfg=dict(
            input_columns=[
                'question',
                'textA',
                'textB',
                'textC',
                'textD',
                ],
            output_column='answerKey'),
        type='opencompass.datasets.ARCDataset'),
    ]
BoolQ_datasets=[
    dict(abbr='BoolQ',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                template=dict(
                    false=dict(
                        round=[
                            dict(prompt='Passage: {passage}\nQuestion: {question}?',
                                role='HUMAN'),
                            dict(prompt='Answer: No',
                                role='BOT'),
                            ]),
                    true=dict(
                        round=[
                            dict(prompt='Passage: {passage}\nQuestion: {question}?',
                                role='HUMAN'),
                            dict(prompt='Answer: Yes',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                type='opencompass.openicl.icl_retriever.ZeroRetriever')),
        path='./data/SuperGLUE/BoolQ/val.jsonl',
        reader_cfg=dict(
            input_columns=[
                'question',
                'passage',
                ],
            output_column='label',
            test_split='train'),
        type='opencompass.datasets.BoolQDataset_V3'),
    ]
TheoremQA_datasets=[
    dict(abbr='TheoremQA',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator'),
            pred_postprocessor=dict(
                type='opencompass.datasets.TheoremQA_postprocess')),
        infer_cfg=dict(
            inferencer=dict(
                max_out_len=512,
                type='opencompass.openicl.icl_inferencer.GenInferencer'),
            prompt_template=dict(
                template=dict(
                    round=[
                        dict(prompt='You are a mathematician, you are supposed to answer the given question. You need to output the answer in your final sentence like "Therefore, the answer is ...". The answer can only be one of the following forms:\n1. a numerical value like 0.1, no symbol and no unit at all.\n2. a list of number like [2, 3, 4].\n3. True/False.\n4. an option like (a), (b), (c), (d)\nQuestion: {Question}\nLet\'s think step by step.',
                            role='HUMAN'),
                        ]),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                type='opencompass.openicl.icl_retriever.ZeroRetriever')),
        path='./data/TheoremQA/test.csv',
        reader_cfg=dict(
            input_columns=[
                'Question',
                'Answer_type',
                ],
            output_column='Answer',
            train_split='test'),
        type='opencompass.datasets.TheoremQADataset'),
    ]
ceval_datasets=[
    dict(abbr='ceval-computer_network',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于计算机网络考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于计算机网络考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于计算机网络考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于计算机网络考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='computer_network',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-operating_system',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于操作系统考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于操作系统考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于操作系统考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于操作系统考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='operating_system',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-computer_architecture',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于计算机组成考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于计算机组成考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于计算机组成考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于计算机组成考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='computer_architecture',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-college_programming',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于大学编程考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于大学编程考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于大学编程考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于大学编程考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='college_programming',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-college_physics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于大学物理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于大学物理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于大学物理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于大学物理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='college_physics',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-college_chemistry',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于大学化学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于大学化学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于大学化学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于大学化学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='college_chemistry',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-advanced_mathematics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高等数学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高等数学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高等数学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高等数学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='advanced_mathematics',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-probability_and_statistics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于概率统计考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于概率统计考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于概率统计考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于概率统计考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='probability_and_statistics',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-discrete_mathematics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于离散数学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于离散数学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于离散数学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于离散数学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='discrete_mathematics',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-electrical_engineer',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于注册电气工程师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于注册电气工程师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于注册电气工程师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于注册电气工程师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='electrical_engineer',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-metrology_engineer',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于注册计量师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于注册计量师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于注册计量师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于注册计量师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='metrology_engineer',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-high_school_mathematics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中数学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中数学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中数学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中数学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_mathematics',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-high_school_physics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中物理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中物理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中物理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中物理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_physics',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-high_school_chemistry',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中化学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中化学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中化学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中化学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_chemistry',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-high_school_biology',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中生物考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中生物考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中生物考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中生物考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_biology',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-middle_school_mathematics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中数学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中数学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中数学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中数学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='middle_school_mathematics',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-middle_school_biology',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中生物考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中生物考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中生物考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中生物考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='middle_school_biology',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-middle_school_physics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中物理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中物理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中物理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中物理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='middle_school_physics',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-middle_school_chemistry',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中化学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中化学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中化学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中化学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='middle_school_chemistry',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-veterinary_medicine',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于兽医学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于兽医学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于兽医学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于兽医学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='veterinary_medicine',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-college_economics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于大学经济学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于大学经济学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于大学经济学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于大学经济学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='college_economics',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-business_administration',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于工商管理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于工商管理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于工商管理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于工商管理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='business_administration',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-marxism',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于马克思主义基本原理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于马克思主义基本原理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于马克思主义基本原理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于马克思主义基本原理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='marxism',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-mao_zedong_thought',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于毛泽东思想和中国特色社会主义理论体系概论考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于毛泽东思想和中国特色社会主义理论体系概论考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于毛泽东思想和中国特色社会主义理论体系概论考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于毛泽东思想和中国特色社会主义理论体系概论考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='mao_zedong_thought',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-education_science',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于教育学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于教育学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于教育学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于教育学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='education_science',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-teacher_qualification',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于教师资格考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于教师资格考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于教师资格考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于教师资格考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='teacher_qualification',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-high_school_politics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中政治考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中政治考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中政治考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中政治考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_politics',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-high_school_geography',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中地理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中地理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中地理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中地理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_geography',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-middle_school_politics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中政治考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中政治考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中政治考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中政治考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='middle_school_politics',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-middle_school_geography',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中地理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中地理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中地理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中地理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='middle_school_geography',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-modern_chinese_history',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于近代史纲要考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于近代史纲要考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于近代史纲要考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于近代史纲要考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='modern_chinese_history',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-ideological_and_moral_cultivation',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于思想道德修养与法律基础考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于思想道德修养与法律基础考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于思想道德修养与法律基础考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于思想道德修养与法律基础考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='ideological_and_moral_cultivation',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-logic',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于逻辑学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于逻辑学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于逻辑学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于逻辑学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='logic',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-law',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于法学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于法学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于法学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于法学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='law',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-chinese_language_and_literature',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于中国语言文学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于中国语言文学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于中国语言文学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于中国语言文学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='chinese_language_and_literature',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-art_studies',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于艺术学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于艺术学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于艺术学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于艺术学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='art_studies',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-professional_tour_guide',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于导游资格考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于导游资格考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于导游资格考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于导游资格考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='professional_tour_guide',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-legal_professional',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于法律职业资格考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于法律职业资格考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于法律职业资格考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于法律职业资格考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='legal_professional',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-high_school_chinese',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中语文考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中语文考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中语文考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中语文考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_chinese',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-high_school_history',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中历史考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中历史考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中历史考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中历史考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_history',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-middle_school_history',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中历史考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中历史考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中历史考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中历史考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='middle_school_history',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-civil_servant',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于公务员考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于公务员考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于公务员考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于公务员考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='civil_servant',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-sports_science',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于体育学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于体育学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于体育学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于体育学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='sports_science',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-plant_protection',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于植物保护考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于植物保护考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于植物保护考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于植物保护考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='plant_protection',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-basic_medicine',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于基础医学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于基础医学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于基础医学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于基础医学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='basic_medicine',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-clinical_medicine',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于临床医学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于临床医学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于临床医学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于临床医学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='clinical_medicine',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-urban_and_rural_planner',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于注册城乡规划师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于注册城乡规划师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于注册城乡规划师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于注册城乡规划师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='urban_and_rural_planner',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-accountant',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于注册会计师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于注册会计师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于注册会计师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于注册会计师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='accountant',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-fire_engineer',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于注册消防工程师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于注册消防工程师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于注册消防工程师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于注册消防工程师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='fire_engineer',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-environmental_impact_assessment_engineer',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于环境影响评价工程师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于环境影响评价工程师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于环境影响评价工程师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于环境影响评价工程师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='environmental_impact_assessment_engineer',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-tax_accountant',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于税务师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于税务师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于税务师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于税务师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='tax_accountant',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-physician',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于医师资格考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于医师资格考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于医师资格考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于医师资格考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='physician',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    ]
cmmlu_datasets=[
    dict(abbr='cmmlu-agronomy',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于农学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于农学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于农学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于农学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='agronomy',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-anatomy',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于解剖学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于解剖学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于解剖学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于解剖学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='anatomy',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-ancient_chinese',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于古汉语的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于古汉语的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于古汉语的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于古汉语的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='ancient_chinese',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-arts',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于艺术学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于艺术学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于艺术学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于艺术学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='arts',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-astronomy',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于天文学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于天文学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于天文学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于天文学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='astronomy',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-business_ethics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于商业伦理的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于商业伦理的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于商业伦理的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于商业伦理的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='business_ethics',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-chinese_civil_service_exam',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国公务员考试的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国公务员考试的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国公务员考试的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国公务员考试的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='chinese_civil_service_exam',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-chinese_driving_rule',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国驾驶规则的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国驾驶规则的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国驾驶规则的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国驾驶规则的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='chinese_driving_rule',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-chinese_food_culture',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国饮食文化的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国饮食文化的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国饮食文化的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国饮食文化的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='chinese_food_culture',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-chinese_foreign_policy',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国外交政策的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国外交政策的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国外交政策的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国外交政策的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='chinese_foreign_policy',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-chinese_history',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国历史的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国历史的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国历史的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国历史的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='chinese_history',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-chinese_literature',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国文学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国文学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国文学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国文学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='chinese_literature',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-chinese_teacher_qualification',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国教师资格的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国教师资格的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国教师资格的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国教师资格的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='chinese_teacher_qualification',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-clinical_knowledge',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于临床知识的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于临床知识的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于临床知识的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于临床知识的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='clinical_knowledge',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-college_actuarial_science',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学精算学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学精算学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学精算学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学精算学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='college_actuarial_science',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-college_education',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学教育学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学教育学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学教育学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学教育学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='college_education',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-college_engineering_hydrology',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学工程水文学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学工程水文学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学工程水文学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学工程水文学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='college_engineering_hydrology',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-college_law',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学法律的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学法律的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学法律的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学法律的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='college_law',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-college_mathematics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学数学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学数学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学数学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学数学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='college_mathematics',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-college_medical_statistics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学医学统计的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学医学统计的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学医学统计的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学医学统计的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='college_medical_statistics',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-college_medicine',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学医学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学医学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学医学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学医学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='college_medicine',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-computer_science',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于计算机科学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于计算机科学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于计算机科学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于计算机科学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='computer_science',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-computer_security',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于计算机安全的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于计算机安全的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于计算机安全的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于计算机安全的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='computer_security',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-conceptual_physics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于概念物理学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于概念物理学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于概念物理学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于概念物理学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='conceptual_physics',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-construction_project_management',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于建设工程管理的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于建设工程管理的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于建设工程管理的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于建设工程管理的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='construction_project_management',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-economics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于经济学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于经济学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于经济学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于经济学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='economics',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-education',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于教育学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于教育学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于教育学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于教育学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='education',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-electrical_engineering',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于电气工程的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于电气工程的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于电气工程的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于电气工程的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='electrical_engineering',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-elementary_chinese',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于小学语文的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于小学语文的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于小学语文的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于小学语文的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='elementary_chinese',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-elementary_commonsense',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于小学常识的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于小学常识的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于小学常识的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于小学常识的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='elementary_commonsense',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-elementary_information_and_technology',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于小学信息技术的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于小学信息技术的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于小学信息技术的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于小学信息技术的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='elementary_information_and_technology',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-elementary_mathematics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于初等数学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于初等数学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于初等数学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于初等数学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='elementary_mathematics',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-ethnology',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于民族学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于民族学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于民族学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于民族学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='ethnology',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-food_science',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于食品科学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于食品科学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于食品科学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于食品科学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='food_science',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-genetics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于遗传学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于遗传学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于遗传学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于遗传学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='genetics',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-global_facts',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于全球事实的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于全球事实的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于全球事实的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于全球事实的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='global_facts',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-high_school_biology',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于高中生物的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于高中生物的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于高中生物的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于高中生物的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_biology',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-high_school_chemistry',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于高中化学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于高中化学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于高中化学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于高中化学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_chemistry',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-high_school_geography',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于高中地理的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于高中地理的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于高中地理的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于高中地理的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_geography',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-high_school_mathematics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于高中数学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于高中数学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于高中数学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于高中数学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_mathematics',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-high_school_physics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于高中物理学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于高中物理学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于高中物理学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于高中物理学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_physics',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-high_school_politics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于高中政治的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于高中政治的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于高中政治的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于高中政治的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_politics',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-human_sexuality',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于人类性行为的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于人类性行为的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于人类性行为的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于人类性行为的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='human_sexuality',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-international_law',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于国际法学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于国际法学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于国际法学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于国际法学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='international_law',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-journalism',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于新闻学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于新闻学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于新闻学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于新闻学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='journalism',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-jurisprudence',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于法理学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于法理学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于法理学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于法理学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='jurisprudence',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-legal_and_moral_basis',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于法律与道德基础的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于法律与道德基础的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于法律与道德基础的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于法律与道德基础的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='legal_and_moral_basis',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-logical',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于逻辑学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于逻辑学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于逻辑学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于逻辑学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='logical',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-machine_learning',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于机器学习的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于机器学习的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于机器学习的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于机器学习的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='machine_learning',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-management',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于管理学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于管理学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于管理学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于管理学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='management',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-marketing',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于市场营销的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于市场营销的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于市场营销的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于市场营销的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='marketing',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-marxist_theory',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于马克思主义理论的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于马克思主义理论的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于马克思主义理论的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于马克思主义理论的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='marxist_theory',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-modern_chinese',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于现代汉语的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于现代汉语的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于现代汉语的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于现代汉语的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='modern_chinese',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-nutrition',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于营养学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于营养学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于营养学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于营养学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='nutrition',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-philosophy',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于哲学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于哲学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于哲学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于哲学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='philosophy',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-professional_accounting',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于专业会计的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于专业会计的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于专业会计的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于专业会计的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='professional_accounting',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-professional_law',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于专业法学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于专业法学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于专业法学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于专业法学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='professional_law',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-professional_medicine',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于专业医学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于专业医学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于专业医学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于专业医学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='professional_medicine',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-professional_psychology',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于专业心理学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于专业心理学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于专业心理学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于专业心理学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='professional_psychology',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-public_relations',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于公共关系的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于公共关系的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于公共关系的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于公共关系的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='public_relations',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-security_study',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于安全研究的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于安全研究的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于安全研究的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于安全研究的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='security_study',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-sociology',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于社会学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于社会学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于社会学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于社会学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='sociology',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-sports_science',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于体育学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于体育学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于体育学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于体育学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='sports_science',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-traditional_chinese_medicine',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中医中药的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中医中药的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中医中药的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中医中药的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='traditional_chinese_medicine',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-virology',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于病毒学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于病毒学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于病毒学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于病毒学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='virology',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-world_history',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于世界历史的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于世界历史的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于世界历史的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于世界历史的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='world_history',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-world_religions',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于世界宗教的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于世界宗教的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于世界宗教的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于世界宗教的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='world_religions',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    ]
commonsenseqa_datasets=[
    dict(eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='Question: {question}\nAnswer: ',
                                role='HUMAN'),
                            dict(prompt='{A}',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='Question: {question}\nAnswer: ',
                                role='HUMAN'),
                            dict(prompt='{B}',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='Question: {question}\nAnswer: ',
                                role='HUMAN'),
                            dict(prompt='{C}',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='Question: {question}\nAnswer: ',
                                role='HUMAN'),
                            dict(prompt='{D}',
                                role='BOT'),
                            ]),
                    E=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='Question: {question}\nAnswer: ',
                                role='HUMAN'),
                            dict(prompt='{E}',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                batch_size=12,
                candidate_num=30,
                ice_num=8,
                ice_template=dict(
                    ice_token='</E>',
                    template=dict(
                        A=dict(
                            begin='</E>',
                            round=[
                                dict(prompt='Question: {question}\nAnswer: ',
                                    role='HUMAN'),
                                dict(prompt='{A}',
                                    role='BOT'),
                                ]),
                        B=dict(
                            begin='</E>',
                            round=[
                                dict(prompt='Question: {question}\nAnswer: ',
                                    role='HUMAN'),
                                dict(prompt='{B}',
                                    role='BOT'),
                                ]),
                        C=dict(
                            begin='</E>',
                            round=[
                                dict(prompt='Question: {question}\nAnswer: ',
                                    role='HUMAN'),
                                dict(prompt='{C}',
                                    role='BOT'),
                                ]),
                        D=dict(
                            begin='</E>',
                            round=[
                                dict(prompt='Question: {question}\nAnswer: ',
                                    role='HUMAN'),
                                dict(prompt='{D}',
                                    role='BOT'),
                                ]),
                        E=dict(
                            begin='</E>',
                            round=[
                                dict(prompt='Question: {question}\nAnswer: ',
                                    role='HUMAN'),
                                dict(prompt='{E}',
                                    role='BOT'),
                                ])),
                    type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
                seed=1,
                select_time=10,
                type='opencompass.openicl.icl_retriever.MDLRetriever')),
        path='commonsense_qa',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                'E',
                ],
            output_column='answerKey',
            test_split='validation'),
        type='opencompass.datasets.commonsenseqaDataset'),
    ]
dataset_abbrs=[
    '------- MMLU details -------',
    'mmlu-humanities',
    'mmlu-stem',
    'mmlu-social-science',
    'mmlu-other',
    'mmlu',
    '---- Standard Benchmarks ---',
    'BoolQ',
    'piqa',
    'siqa',
    'hellaswag',
    'winogrande',
    'ARC-e',
    'ARC-c',
    'openbookqa_fact',
    'commonsense_qa',
    'mmlu',
    '------ Code Generation -----',
    'openai_humaneval',
    'mbpp',
    '------ World Knowledge -----',
    'natural_questiontriviaqa',
    '--- Reading Comprehension --',
    'squad2.0',
    '---------- Exams -----------',
    'math',
    'gsm8k',
    'TheoremQA',
    '--------- Chinese ----------',
    'ceval',
    'ceval-stem',
    'ceval-social-science',
    'ceval-humanities',
    'ceval-other',
    'ceval-hard',
    'cmmlu',
    'cmmlu-humanities',
    'cmmlu-stem',
    'cmmlu-social-science',
    'cmmlu-other',
    'cmmlu-china-specific',
    ]
datasets=[
    dict(abbr='BoolQ',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                template=dict(
                    false=dict(
                        round=[
                            dict(prompt='Passage: {passage}\nQuestion: {question}?',
                                role='HUMAN'),
                            dict(prompt='Answer: No',
                                role='BOT'),
                            ]),
                    true=dict(
                        round=[
                            dict(prompt='Passage: {passage}\nQuestion: {question}?',
                                role='HUMAN'),
                            dict(prompt='Answer: Yes',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                type='opencompass.openicl.icl_retriever.ZeroRetriever')),
        path='./data/SuperGLUE/BoolQ/val.jsonl',
        reader_cfg=dict(
            input_columns=[
                'question',
                'passage',
                ],
            output_column='label',
            test_split='train'),
        type='opencompass.datasets.BoolQDataset_V3'),
    dict(abbr='piqa',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                template=dict(
                    {'0': dict(
                        round=[
                            dict(prompt='{goal} {sol1}',
                                role='HUMAN'),
                            ]),
                    '1': dict(
                        round=[
                            dict(prompt='{goal} {sol2}',
                                role='HUMAN'),
                            ])}),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                type='opencompass.openicl.icl_retriever.ZeroRetriever')),
        path='piqa',
        reader_cfg=dict(
            input_columns=[
                'goal',
                'sol1',
                'sol2',
                ],
            output_column='label',
            test_split='validation'),
        type='opencompass.datasets.piqaDataset_V3'),
    dict(abbr='siqa',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                template=dict(
                    {'1': dict(
                        round=[
                            dict(prompt='{context}\nQuestion: {question}\nA. {answerA}\nB. {answerB}\nC. {answerC}',
                                role='HUMAN'),
                            dict(prompt='Answer: A',
                                role='BOT'),
                            ]),
                    '2': dict(
                        round=[
                            dict(prompt='{context}\nQuestion: {question}\nA. {answerA}\nB. {answerB}\nC. {answerC}',
                                role='HUMAN'),
                            dict(prompt='Answer: B',
                                role='BOT'),
                            ]),
                    '3': dict(
                        round=[
                            dict(prompt='{context}\nQuestion: {question}\nA. {answerA}\nB. {answerB}\nC. {answerC}',
                                role='HUMAN'),
                            dict(prompt='Answer: C',
                                role='BOT'),
                            ])}),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                type='opencompass.openicl.icl_retriever.ZeroRetriever')),
        path='social_i_qa',
        reader_cfg=dict(
            input_columns=[
                'context',
                'question',
                'answerA',
                'answerB',
                'answerC',
                ],
            output_column='label',
            test_split='validation'),
        type='opencompass.datasets.HFDataset'),
    dict(abbr='hellaswag',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                template=dict(
                    {'0': dict(
                        round=[
                            dict(prompt='{query} {A}',
                                role='HUMAN'),
                            ]),
                    '1': dict(
                        round=[
                            dict(prompt='{query} {B}',
                                role='HUMAN'),
                            ]),
                    '2': dict(
                        round=[
                            dict(prompt='{query} {C}',
                                role='HUMAN'),
                            ]),
                    '3': dict(
                        round=[
                            dict(prompt='{query} {D}',
                                role='HUMAN'),
                            ])}),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                type='opencompass.openicl.icl_retriever.ZeroRetriever')),
        path='./data/hellaswag/hellaswag.jsonl',
        reader_cfg=dict(
            input_columns=[
                'query',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='gold'),
        type='opencompass.datasets.hellaswagDataset_V3'),
    dict(abbr='winogrande',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                template=dict(
                    {1: dict(
                        round=[
                            dict(prompt='Good sentence: {opt1}',
                                role='HUMAN'),
                            ]),
                    2: dict(
                        round=[
                            dict(prompt='Good sentence: {opt2}',
                                role='HUMAN'),
                            ])}),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                type='opencompass.openicl.icl_retriever.ZeroRetriever')),
        name='winogrande_xs',
        path='winogrande',
        reader_cfg=dict(
            input_columns=[
                'opt1',
                'opt2',
                ],
            output_column='answer',
            test_split='validation',
            train_split='validation'),
        type='opencompass.datasets.winograndeDataset'),
    dict(abbr='ARC-e',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                template=dict(
                    A=dict(
                        round=[
                            dict(prompt='{question}\nA. {textA}\nB. {textB}\nC. {textC}\nD. {textD}',
                                role='HUMAN'),
                            dict(prompt='Answer: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        round=[
                            dict(prompt='{question}\nA. {textA}\nB. {textB}\nC. {textC}\nD. {textD}',
                                role='HUMAN'),
                            dict(prompt='Answer: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        round=[
                            dict(prompt='{question}\nA. {textA}\nB. {textB}\nC. {textC}\nD. {textD}',
                                role='HUMAN'),
                            dict(prompt='Answer: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        round=[
                            dict(prompt='{question}\nA. {textA}\nB. {textB}\nC. {textC}\nD. {textD}',
                                role='HUMAN'),
                            dict(prompt='Answer: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                type='opencompass.openicl.icl_retriever.ZeroRetriever')),
        path='./data/ARC/ARC-e/ARC-Easy-Dev.jsonl',
        reader_cfg=dict(
            input_columns=[
                'question',
                'textA',
                'textB',
                'textC',
                'textD',
                ],
            output_column='answerKey'),
        type='opencompass.datasets.ARCDataset'),
    dict(abbr='ARC-c',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                template=dict(
                    A=dict(
                        round=[
                            dict(prompt='{question}\nA. {textA}\nB. {textB}\nC. {textC}\nD. {textD}',
                                role='HUMAN'),
                            dict(prompt='Answer: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        round=[
                            dict(prompt='{question}\nA. {textA}\nB. {textB}\nC. {textC}\nD. {textD}',
                                role='HUMAN'),
                            dict(prompt='Answer: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        round=[
                            dict(prompt='{question}\nA. {textA}\nB. {textB}\nC. {textC}\nD. {textD}',
                                role='HUMAN'),
                            dict(prompt='Answer: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        round=[
                            dict(prompt='{question}\nA. {textA}\nB. {textB}\nC. {textC}\nD. {textD}',
                                role='HUMAN'),
                            dict(prompt='Answer: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                type='opencompass.openicl.icl_retriever.ZeroRetriever')),
        path='./data/ARC/ARC-c/ARC-Challenge-Dev.jsonl',
        reader_cfg=dict(
            input_columns=[
                'question',
                'textA',
                'textB',
                'textC',
                'textD',
                ],
            output_column='answerKey'),
        type='opencompass.datasets.ARCDataset'),
    dict(abbr='openbookqa_fact',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                template=dict(
                    A=dict(
                        round=[
                            dict(prompt='We know the fact that {fact1}.\nQuestion: {question_stem}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n',
                                role='HUMAN'),
                            dict(prompt='Answer: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        round=[
                            dict(prompt='We know the fact that {fact1}.\nQuestion: {question_stem}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n',
                                role='HUMAN'),
                            dict(prompt='Answer: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        round=[
                            dict(prompt='We know the fact that {fact1}.\nQuestion: {question_stem}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n',
                                role='HUMAN'),
                            dict(prompt='Answer: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        round=[
                            dict(prompt='We know the fact that {fact1}.\nQuestion: {question_stem}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n',
                                role='HUMAN'),
                            dict(prompt='Answer: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                type='opencompass.openicl.icl_retriever.ZeroRetriever')),
        name='additional',
        path='openbookqa',
        reader_cfg=dict(
            input_columns=[
                'question_stem',
                'A',
                'B',
                'C',
                'D',
                'fact1',
                ],
            output_column='answerKey'),
        split='test',
        type='opencompass.datasets.OBQADataset_V2'),
    dict(eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='Question: {question}\nAnswer: ',
                                role='HUMAN'),
                            dict(prompt='{A}',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='Question: {question}\nAnswer: ',
                                role='HUMAN'),
                            dict(prompt='{B}',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='Question: {question}\nAnswer: ',
                                role='HUMAN'),
                            dict(prompt='{C}',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='Question: {question}\nAnswer: ',
                                role='HUMAN'),
                            dict(prompt='{D}',
                                role='BOT'),
                            ]),
                    E=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='Question: {question}\nAnswer: ',
                                role='HUMAN'),
                            dict(prompt='{E}',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                batch_size=12,
                candidate_num=30,
                ice_num=8,
                ice_template=dict(
                    ice_token='</E>',
                    template=dict(
                        A=dict(
                            begin='</E>',
                            round=[
                                dict(prompt='Question: {question}\nAnswer: ',
                                    role='HUMAN'),
                                dict(prompt='{A}',
                                    role='BOT'),
                                ]),
                        B=dict(
                            begin='</E>',
                            round=[
                                dict(prompt='Question: {question}\nAnswer: ',
                                    role='HUMAN'),
                                dict(prompt='{B}',
                                    role='BOT'),
                                ]),
                        C=dict(
                            begin='</E>',
                            round=[
                                dict(prompt='Question: {question}\nAnswer: ',
                                    role='HUMAN'),
                                dict(prompt='{C}',
                                    role='BOT'),
                                ]),
                        D=dict(
                            begin='</E>',
                            round=[
                                dict(prompt='Question: {question}\nAnswer: ',
                                    role='HUMAN'),
                                dict(prompt='{D}',
                                    role='BOT'),
                                ]),
                        E=dict(
                            begin='</E>',
                            round=[
                                dict(prompt='Question: {question}\nAnswer: ',
                                    role='HUMAN'),
                                dict(prompt='{E}',
                                    role='BOT'),
                                ])),
                    type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
                seed=1,
                select_time=10,
                type='opencompass.openicl.icl_retriever.MDLRetriever')),
        path='commonsense_qa',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                'E',
                ],
            output_column='answerKey',
            test_split='validation'),
        type='opencompass.datasets.commonsenseqaDataset'),
    dict(abbr='lukaemon_mmlu_college_biology',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  college biology.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  college biology.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  college biology.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  college biology.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='college_biology',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_college_chemistry',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  college chemistry.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  college chemistry.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  college chemistry.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  college chemistry.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='college_chemistry',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_college_computer_science',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  college computer science.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  college computer science.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  college computer science.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  college computer science.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='college_computer_science',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_college_mathematics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  college mathematics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  college mathematics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  college mathematics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  college mathematics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='college_mathematics',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_college_physics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  college physics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  college physics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  college physics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  college physics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='college_physics',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_electrical_engineering',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  electrical engineering.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  electrical engineering.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  electrical engineering.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  electrical engineering.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='electrical_engineering',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_astronomy',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  astronomy.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  astronomy.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  astronomy.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  astronomy.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='astronomy',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_anatomy',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  anatomy.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  anatomy.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  anatomy.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  anatomy.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='anatomy',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_abstract_algebra',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  abstract algebra.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  abstract algebra.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  abstract algebra.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  abstract algebra.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='abstract_algebra',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_machine_learning',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  machine learning.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  machine learning.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  machine learning.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  machine learning.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='machine_learning',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_clinical_knowledge',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  clinical knowledge.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  clinical knowledge.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  clinical knowledge.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  clinical knowledge.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='clinical_knowledge',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_global_facts',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  global facts.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  global facts.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  global facts.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  global facts.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='global_facts',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_management',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  management.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  management.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  management.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  management.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='management',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_nutrition',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  nutrition.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  nutrition.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  nutrition.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  nutrition.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='nutrition',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_marketing',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  marketing.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  marketing.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  marketing.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  marketing.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='marketing',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_professional_accounting',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  professional accounting.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  professional accounting.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  professional accounting.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  professional accounting.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='professional_accounting',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_high_school_geography',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  high school geography.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  high school geography.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  high school geography.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  high school geography.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_geography',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_international_law',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  international law.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  international law.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  international law.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  international law.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='international_law',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_moral_scenarios',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  moral scenarios.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  moral scenarios.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  moral scenarios.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  moral scenarios.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='moral_scenarios',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_computer_security',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  computer security.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  computer security.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  computer security.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  computer security.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='computer_security',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_high_school_microeconomics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  high school microeconomics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  high school microeconomics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  high school microeconomics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  high school microeconomics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_microeconomics',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_professional_law',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  professional law.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  professional law.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  professional law.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  professional law.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='professional_law',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_medical_genetics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  medical genetics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  medical genetics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  medical genetics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  medical genetics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='medical_genetics',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_professional_psychology',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  professional psychology.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  professional psychology.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  professional psychology.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  professional psychology.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='professional_psychology',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_jurisprudence',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  jurisprudence.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  jurisprudence.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  jurisprudence.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  jurisprudence.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='jurisprudence',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_world_religions',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  world religions.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  world religions.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  world religions.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  world religions.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='world_religions',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_philosophy',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  philosophy.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  philosophy.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  philosophy.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  philosophy.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='philosophy',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_virology',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  virology.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  virology.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  virology.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  virology.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='virology',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_high_school_chemistry',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  high school chemistry.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  high school chemistry.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  high school chemistry.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  high school chemistry.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_chemistry',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_public_relations',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  public relations.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  public relations.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  public relations.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  public relations.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='public_relations',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_high_school_macroeconomics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  high school macroeconomics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  high school macroeconomics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  high school macroeconomics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  high school macroeconomics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_macroeconomics',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_human_sexuality',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  human sexuality.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  human sexuality.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  human sexuality.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  human sexuality.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='human_sexuality',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_elementary_mathematics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  elementary mathematics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  elementary mathematics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  elementary mathematics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  elementary mathematics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='elementary_mathematics',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_high_school_physics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  high school physics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  high school physics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  high school physics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  high school physics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_physics',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_high_school_computer_science',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  high school computer science.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  high school computer science.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  high school computer science.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  high school computer science.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_computer_science',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_high_school_european_history',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  high school european history.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  high school european history.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  high school european history.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  high school european history.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_european_history',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_business_ethics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  business ethics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  business ethics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  business ethics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  business ethics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='business_ethics',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_moral_disputes',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  moral disputes.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  moral disputes.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  moral disputes.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  moral disputes.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='moral_disputes',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_high_school_statistics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  high school statistics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  high school statistics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  high school statistics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  high school statistics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_statistics',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_miscellaneous',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  miscellaneous.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  miscellaneous.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  miscellaneous.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  miscellaneous.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='miscellaneous',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_formal_logic',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  formal logic.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  formal logic.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  formal logic.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  formal logic.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='formal_logic',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_high_school_government_and_politics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  high school government and politics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  high school government and politics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  high school government and politics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  high school government and politics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_government_and_politics',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_prehistory',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  prehistory.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  prehistory.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  prehistory.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  prehistory.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='prehistory',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_security_studies',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  security studies.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  security studies.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  security studies.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  security studies.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='security_studies',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_high_school_biology',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  high school biology.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  high school biology.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  high school biology.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  high school biology.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_biology',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_logical_fallacies',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  logical fallacies.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  logical fallacies.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  logical fallacies.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  logical fallacies.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='logical_fallacies',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_high_school_world_history',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  high school world history.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  high school world history.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  high school world history.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  high school world history.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_world_history',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_professional_medicine',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  professional medicine.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  professional medicine.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  professional medicine.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  professional medicine.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='professional_medicine',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_high_school_mathematics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  high school mathematics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  high school mathematics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  high school mathematics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  high school mathematics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_mathematics',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_college_medicine',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  college medicine.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  college medicine.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  college medicine.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  college medicine.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='college_medicine',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_high_school_us_history',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  high school us history.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  high school us history.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  high school us history.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  high school us history.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_us_history',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_sociology',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  sociology.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  sociology.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  sociology.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  sociology.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='sociology',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_econometrics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  econometrics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  econometrics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  econometrics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  econometrics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='econometrics',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_high_school_psychology',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  high school psychology.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  high school psychology.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  high school psychology.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  high school psychology.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_psychology',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_human_aging',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  human aging.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  human aging.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  human aging.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  human aging.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='human_aging',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_us_foreign_policy',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  us foreign policy.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  us foreign policy.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  us foreign policy.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  us foreign policy.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='us_foreign_policy',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_conceptual_physics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  conceptual physics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  conceptual physics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  conceptual physics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  conceptual physics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='conceptual_physics',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(eval_cfg=dict(
            evaluator=dict(
                type='opencompass.datasets.HumanEvaluator'),
            k=[
                1,
                10,
                100,
                ],
            pred_postprocessor=dict(
                type='opencompass.datasets.humaneval_postprocess'),
            pred_role='BOT'),
        infer_cfg=dict(
            inferencer=dict(
                max_out_len=512,
                type='opencompass.openicl.icl_inferencer.GenInferencer'),
            prompt_template=dict(
                template=dict(
                    round=[
                        dict(prompt='{prompt}',
                            role='HUMAN'),
                        ]),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                type='opencompass.openicl.icl_retriever.ZeroRetriever')),
        path='openai_humaneval',
        reader_cfg=dict(
            input_columns=[
                'prompt',
                ],
            output_column='task_id',
            train_split='test'),
        type='opencompass.datasets.HFDataset'),
    dict(abbr='mbpp',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.datasets.MBPPEvaluator'),
            pred_role='BOT'),
        infer_cfg=dict(
            inferencer=dict(
                max_out_len=512,
                type='opencompass.openicl.icl_inferencer.GenInferencer'),
            prompt_template=dict(
                template=dict(
                    round=[
                        dict(prompt='You are an expert Python programmer, and here is your task: Write a function to find the similar elements from the given two tuple lists. Your code should pass these tests:\n\n assert similar_elements((3, 4, 5, 6),(5, 7, 4, 10)) == (4, 5)\n assert similar_elements((1, 2, 3, 4),(5, 4, 3, 7)) == (3, 4) \n assert similar_elements((11, 12, 14, 13),(17, 15, 14, 13)) == (13, 14) \n',
                            role='HUMAN'),
                        dict(prompt="[BEGIN]\n 'def similar_elements(test_tup1, test_tup2):\r\n  res = tuple(set(test_tup1) & set(test_tup2))\r\n  return (res)' \n[DONE] \n\n ",
                            role='BOT'),
                        dict(prompt='You are an expert Python programmer, and here is your task: Write a python function to identify non-prime numbers. Your code should pass these tests:\n\n assert is_not_prime(2) == False \n assert is_not_prime(10) == True \n assert is_not_prime(35) == True \n',
                            role='HUMAN'),
                        dict(prompt="[BEGIN]\n 'import math\r\ndef is_not_prime(n):\r\n    result = False\r\n    for i in range(2,int(math.sqrt(n)) + 1):\r\n        if n % i == 0:\r\n            result = True\r\n    return result' \n[DONE] \n\n ",
                            role='BOT'),
                        dict(prompt='You are an expert Python programmer, and here is your task: Write a function to find the largest integers from a given list of numbers using heap queue algorithm. Your code should pass these tests:\n\n assert heap_queue_largest( [25, 35, 22, 85, 14, 65, 75, 22, 58],3)==[85, 75, 65] \n assert heap_queue_largest( [25, 35, 22, 85, 14, 65, 75, 22, 58],2)==[85, 75] \n assert heap_queue_largest( [25, 35, 22, 85, 14, 65, 75, 22, 58],5)==[85, 75, 65, 58, 35] \n',
                            role='HUMAN'),
                        dict(prompt="[BEGIN]\n 'import heapq as hq\r\ndef heap_queue_largest(nums,n):\r\n  largest_nums = hq.nlargest(n, nums)\r\n  return largest_nums' \n[DONE] \n\n ",
                            role='BOT'),
                        dict(prompt='You are an expert Python programmer, and here is your task: {text} Your code should pass these tests:\n\n {test_list}  \n',
                            role='HUMAN'),
                        dict(prompt='[BEGIN]\n',
                            role='BOT'),
                        ]),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                type='opencompass.openicl.icl_retriever.ZeroRetriever')),
        path='./data/mbpp/mbpp.jsonl',
        reader_cfg=dict(
            input_columns=[
                'text',
                'test_list',
                ],
            output_column='test_list_2'),
        type='opencompass.datasets.MBPPDataset'),
    dict(abbr='nq',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.datasets.NQEvaluator'),
            pred_role='BOT'),
        infer_cfg=dict(
            inferencer=dict(
                max_out_len=50,
                type='opencompass.openicl.icl_inferencer.GenInferencer'),
            prompt_template=dict(
                template=dict(
                    round=[
                        dict(prompt="Answer these questions, your answer should be as simple as possible, start your answer with the prompt 'The answer is '.\nQ: {question}?",
                            role='HUMAN'),
                        dict(prompt='A:',
                            role='BOT'),
                        ]),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                type='opencompass.openicl.icl_retriever.ZeroRetriever')),
        path='./data/nq/',
        reader_cfg=dict(
            input_columns=[
                'question',
                ],
            output_column='answer',
            train_split='dev'),
        type='opencompass.datasets.NaturalQuestionDataset'),
    dict(abbr='nq_1shot',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.datasets.NQEvaluator'),
            pred_role='BOT'),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    round=[
                        dict(prompt="Answer the question, your answer should be as simple as possible, start your answer with the prompt 'The answer is '.\nQ: {question}?",
                            role='HUMAN'),
                        dict(prompt='A: The answer is {answer}.\n',
                            role='BOT'),
                        ]),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                max_out_len=50,
                type='opencompass.openicl.icl_inferencer.GenInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    begin='</E>',
                    round=[
                        dict(prompt="Answer the question, your answer should be as simple as possible, start your answer with the prompt 'The answer is '.\nQ: {question}?",
                            role='HUMAN'),
                        dict(prompt='A:',
                            role='BOT'),
                        ]),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        path='./data/nq/',
        reader_cfg=dict(
            input_columns=[
                'question',
                ],
            output_column='answer',
            train_split='dev'),
        type='opencompass.datasets.NaturalQuestionDataset'),
    dict(abbr='nq_5shot',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.datasets.NQEvaluator'),
            pred_role='BOT'),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    round=[
                        dict(prompt="Answer the question, your answer should be as simple as possible, start your answer with the prompt 'The answer is '.\nQ: {question}?",
                            role='HUMAN'),
                        dict(prompt='A: The answer is {answer}.\n',
                            role='BOT'),
                        ]),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                max_out_len=50,
                type='opencompass.openicl.icl_inferencer.GenInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    begin='</E>',
                    round=[
                        dict(prompt="Answer the question, your answer should be as simple as possible, start your answer with the prompt 'The answer is '.\nQ: {question}?",
                            role='HUMAN'),
                        dict(prompt='A:',
                            role='BOT'),
                        ]),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        path='./data/nq/',
        reader_cfg=dict(
            input_columns=[
                'question',
                ],
            output_column='answer',
            train_split='dev'),
        type='opencompass.datasets.NaturalQuestionDataset'),
    dict(abbr='triviaqa',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.datasets.TriviaQAEvaluator'),
            pred_role='BOT'),
        infer_cfg=dict(
            inferencer=dict(
                max_out_len=50,
                type='opencompass.openicl.icl_inferencer.GenInferencer'),
            prompt_template=dict(
                template=dict(
                    round=[
                        dict(prompt="Answer these questions, your answer should be as simple as possible, start your answer with the prompt 'The answer is '.\nQ: {question}?",
                            role='HUMAN'),
                        dict(prompt='A:',
                            role='BOT'),
                        ]),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                type='opencompass.openicl.icl_retriever.ZeroRetriever')),
        path='./data/triviaqa/',
        reader_cfg=dict(
            input_columns=[
                'question',
                ],
            output_column='answer',
            test_split='dev',
            train_split='test'),
        type='opencompass.datasets.TriviaQADataset'),
    dict(abbr='triviaqa_1shot',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.datasets.TriviaQAEvaluator'),
            pred_role='BOT'),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    round=[
                        dict(prompt="Answer the question, your answer should be as simple as possible, start your answer with the prompt 'The answer is '.\nQ: {question}?",
                            role='HUMAN'),
                        dict(prompt='A: The answer is {answer}.\n',
                            role='BOT'),
                        ]),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                max_out_len=50,
                type='opencompass.openicl.icl_inferencer.GenInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    begin='</E>',
                    round=[
                        dict(prompt="Answer the question, your answer should be as simple as possible, start your answer with the prompt 'The answer is '.\nQ: {question}?",
                            role='HUMAN'),
                        dict(prompt='A:',
                            role='BOT'),
                        ]),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        path='./data/triviaqa/',
        reader_cfg=dict(
            input_columns=[
                'question',
                ],
            output_column='answer',
            test_split='dev',
            train_split='test'),
        type='opencompass.datasets.TriviaQADataset'),
    dict(abbr='triviaqa_5shot',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.datasets.TriviaQAEvaluator'),
            pred_role='BOT'),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    round=[
                        dict(prompt="Answer the question, your answer should be as simple as possible, start your answer with the prompt 'The answer is '.\nQ: {question}?",
                            role='HUMAN'),
                        dict(prompt='A: The answer is {answer}.\n',
                            role='BOT'),
                        ]),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                max_out_len=50,
                type='opencompass.openicl.icl_inferencer.GenInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    begin='</E>',
                    round=[
                        dict(prompt="Answer the question, your answer should be as simple as possible, start your answer with the prompt 'The answer is '.\nQ: {question}?",
                            role='HUMAN'),
                        dict(prompt='A:',
                            role='BOT'),
                        ]),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        path='./data/triviaqa/',
        reader_cfg=dict(
            input_columns=[
                'question',
                ],
            output_column='answer',
            test_split='dev',
            train_split='test'),
        type='opencompass.datasets.TriviaQADataset'),
    dict(abbr='squad2.0',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.datasets.SQuAD20Evaluator'),
            pred_role='BOT'),
        infer_cfg=dict(
            inferencer=dict(
                max_out_len=50,
                type='opencompass.openicl.icl_inferencer.GenInferencer'),
            prompt_template=dict(
                template=dict(
                    round=[
                        dict(prompt='{context}\nAccording to the above passage, answer the following question. If it is impossible to answer according to the passage, answer `impossible to answer`:\nQuestion: {question}',
                            role='HUMAN'),
                        dict(prompt='Answer:',
                            role='BOT'),
                        ]),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                type='opencompass.openicl.icl_retriever.ZeroRetriever')),
        path='./data/SQuAD2.0/dev-v2.0.json',
        reader_cfg=dict(
            input_columns=[
                'context',
                'question',
                ],
            output_column='answers'),
        type='opencompass.datasets.SQuAD20Dataset'),
    dict(abbr='gsm8k',
        eval_cfg=dict(
            dataset_postprocessor=dict(
                type='opencompass.datasets.gsm8k_dataset_postprocess'),
            evaluator=dict(
                type='opencompass.datasets.Gsm8kEvaluator'),
            pred_postprocessor=dict(
                type='opencompass.datasets.gsm8k_postprocess')),
        infer_cfg=dict(
            inferencer=dict(
                max_out_len=512,
                type='opencompass.openicl.icl_inferencer.GenInferencer'),
            prompt_template=dict(
                template=dict(
                    round=[
                        dict(prompt="Question: Angelo and Melanie want to plan how many hours over the next week they should study together for their test next week. They have 2 chapters of their textbook to study and 4 worksheets to memorize. They figure out that they should dedicate 3 hours to each chapter of their textbook and 1.5 hours for each worksheet. If they plan to study no more than 4 hours each day, how many days should they plan to study total over the next week if they take a 10-minute break every hour, include 3 10-minute snack breaks each day, and 30 minutes for lunch each day?\nLet's think step by step\nAnswer:",
                            role='HUMAN'),
                        dict(prompt='Angelo and Melanie think they should dedicate 3 hours to each of the 2 chapters, 3 hours x 2 chapters = 6 hours total.\nFor the worksheets they plan to dedicate 1.5 hours for each worksheet, 1.5 hours x 4 worksheets = 6 hours total.\nAngelo and Melanie need to start with planning 12 hours to study, at 4 hours a day, 12 / 4 = 3 days.\nHowever, they need to include time for breaks and lunch. Every hour they want to include a 10-minute break, so 12 total hours x 10 minutes = 120 extra minutes for breaks.\nThey also want to include 3 10-minute snack breaks, 3 x 10 minutes = 30 minutes.\nAnd they want to include 30 minutes for lunch each day, so 120 minutes for breaks + 30 minutes for snack breaks + 30 minutes for lunch = 180 minutes, or 180 / 60 minutes per hour = 3 extra hours.\nSo Angelo and Melanie want to plan 12 hours to study + 3 hours of breaks = 15 hours total.\nThey want to study no more than 4 hours each day, 15 hours / 4 hours each day = 3.75\nThey will need to plan to study 4 days to allow for all the time they need.\nThe answer is 4\n',
                            role='BOT'),
                        dict(prompt="Question: Mark's basketball team scores 25 2 pointers, 8 3 pointers and 10 free throws.  Their opponents score double the 2 pointers but half the 3 pointers and free throws.  What's the total number of points scored by both teams added together?\nLet's think step by step\nAnswer:",
                            role='HUMAN'),
                        dict(prompt="Mark's team scores 25 2 pointers, meaning they scored 25*2= 50 points in 2 pointers.\nHis team also scores 6 3 pointers, meaning they scored 8*3= 24 points in 3 pointers\nThey scored 10 free throws, and free throws count as one point so they scored 10*1=10 points in free throws.\nAll together his team scored 50+24+10= 84 points\nMark's opponents scored double his team's number of 2 pointers, meaning they scored 50*2=100 points in 2 pointers.\nHis opponents scored half his team's number of 3 pointers, meaning they scored 24/2= 12 points in 3 pointers.\nThey also scored half Mark's team's points in free throws, meaning they scored 10/2=5 points in free throws.\nAll together Mark's opponents scored 100+12+5=117 points\nThe total score for the game is both team's scores added together, so it is 84+117=201 points\nThe answer is 201\n",
                            role='BOT'),
                        dict(prompt="Question: Bella has two times as many marbles as frisbees. She also has 20 more frisbees than deck cards. If she buys 2/5 times more of each item, what would be the total number of the items she will have if she currently has 60 marbles?\nLet's think step by step\nAnswer:",
                            role='HUMAN'),
                        dict(prompt="When Bella buys 2/5 times more marbles, she'll have increased the number of marbles by 2/5*60 = 24\nThe total number of marbles she'll have is 60+24 = 84\nIf Bella currently has 60 marbles, and she has two times as many marbles as frisbees, she has 60/2 = 30 frisbees.\nIf Bella buys 2/5 times more frisbees, she'll have 2/5*30 = 12 more frisbees.\nThe total number of frisbees she'll have will increase to 30+12 = 42\nBella also has 20 more frisbees than deck cards, meaning she has 30-20 = 10 deck cards\nIf she buys 2/5 times more deck cards, she'll have 2/5*10 = 4 more deck cards.\nThe total number of deck cards she'll have is 10+4 = 14\nTogether, Bella will have a total of 14+42+84 = 140 items\nThe answer is 140\n",
                            role='BOT'),
                        dict(prompt="Question: A group of 4 fruit baskets contains 9 apples, 15 oranges, and 14 bananas in the first three baskets and 2 less of each fruit in the fourth basket. How many fruits are there?\nLet's think step by step\nAnswer:",
                            role='HUMAN'),
                        dict(prompt='For the first three baskets, the number of apples and oranges in one basket is 9+15=24\nIn total, together with bananas, the number of fruits in one basket is 24+14=38 for the first three baskets.\nSince there are three baskets each having 38 fruits, there are 3*38=114 fruits in the first three baskets.\nThe number of apples in the fourth basket is 9-2=7\nThere are also 15-2=13 oranges in the fourth basket\nThe combined number of oranges and apples in the fourth basket is 13+7=20\nThe fourth basket also contains 14-2=12 bananas.\nIn total, the fourth basket has 20+12=32 fruits.\nThe four baskets together have 32+114=146 fruits.\nThe answer is 146\n',
                            role='BOT'),
                        dict(prompt="Question: {question}\nLet's think step by step\nAnswer:",
                            role='HUMAN'),
                        ]),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                type='opencompass.openicl.icl_retriever.ZeroRetriever')),
        name='main',
        path='gsm8k',
        reader_cfg=dict(
            input_columns=[
                'question',
                ],
            output_column='answer'),
        type='opencompass.datasets.HFDataset'),
    dict(abbr='math',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.datasets.MATHEvaluator'),
            pred_postprocessor=dict(
                type='opencompass.datasets.math_postprocess')),
        infer_cfg=dict(
            inferencer=dict(
                max_out_len=512,
                type='opencompass.openicl.icl_inferencer.GenInferencer'),
            prompt_template=dict(
                template=dict(
                    round=[
                        dict(prompt='Problem:\nFind the domain of the expression $\\frac{{\\sqrt{{x-2}}}}{{\\sqrt{{5-x}}}}$.}}\nSolution:',
                            role='HUMAN'),
                        dict(prompt='The expressions inside each square root must be non-negative. Therefore, $x-2 \\ge 0$, so $x\\ge2$, and $5 - x \\ge 0$, so $x \\le 5$. Also, the denominator cannot be equal to zero, so $5-x>0$, which gives $x<5$. Therefore, the domain of the expression is $\\boxed{{[2,5)}}$.\nFinal Answer: The final answer is $[2,5)$. I hope it is correct.\n',
                            role='BOT'),
                        dict(prompt='Problem:\nIf $\\det \\mathbf{{A}} = 2$ and $\\det \\mathbf{{B}} = 12,$ then find $\\det (\\mathbf{{A}} \\mathbf{{B}}).$\nSolution:',
                            role='HUMAN'),
                        dict(prompt='We have that $\\det (\\mathbf{{A}} \\mathbf{{B}}) = (\\det \\mathbf{{A}})(\\det \\mathbf{{B}}) = (2)(12) = \\boxed{{24}}.$\nFinal Answer: The final answer is $24$. I hope it is correct.\n',
                            role='BOT'),
                        dict(prompt='Problem:\nTerrell usually lifts two 20-pound weights 12 times. If he uses two 15-pound weights instead, how many times must Terrell lift them in order to lift the same total weight?\nSolution:',
                            role='HUMAN'),
                        dict(prompt='If Terrell lifts two 20-pound weights 12 times, he lifts a total of $2\\cdot 12\\cdot20=480$ pounds of weight. If he lifts two 15-pound weights instead for $n$ times, he will lift a total of $2\\cdot15\\cdot n=30n$ pounds of weight. Equating this to 480 pounds, we can solve for $n$: \\begin{{align*}} 30n&=480\\\\ \\Rightarrow\\qquad n&=480/30=\\boxed{{16}} \\end{{align*}}\nFinal Answer: The final answer is $16$. I hope it is correct.\n',
                            role='BOT'),
                        dict(prompt='Problem:\nIf the system of equations: \\begin{{align*}} 6x-4y&=a,\\\\ 6y-9x &=b. \\end{{align*}}has a solution $(x, y)$ where $x$ and $y$ are both nonzero, find $\\frac{{a}}{{b}},$ assuming $b$ is nonzero.\nSolution:',
                            role='HUMAN'),
                        dict(prompt='If we multiply the first equation by $-\\frac{{3}}{{2}}$, we obtain $$6y-9x=-\\frac{{3}}{{2}}a.$$Since we also know that $6y-9x=b$, we have $$-\\frac{{3}}{{2}}a=b\\Rightarrow\\frac{{a}}{{b}}=\\boxed{{-\\frac{{2}}{{3}}}}.$$\nFinal Answer: The final answer is $-\\frac{{2}}{{3}}$. I hope it is correct.\n',
                            role='BOT'),
                        dict(prompt='Problem:\n{problem}\nSolution:\n',
                            role='HUMAN'),
                        ]),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                type='opencompass.openicl.icl_retriever.ZeroRetriever')),
        path='./data/math/math.json',
        reader_cfg=dict(
            input_columns=[
                'problem',
                ],
            output_column='solution'),
        type='opencompass.datasets.MATHDataset'),
    dict(abbr='TheoremQA',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator'),
            pred_postprocessor=dict(
                type='opencompass.datasets.TheoremQA_postprocess')),
        infer_cfg=dict(
            inferencer=dict(
                max_out_len=512,
                type='opencompass.openicl.icl_inferencer.GenInferencer'),
            prompt_template=dict(
                template=dict(
                    round=[
                        dict(prompt='You are a mathematician, you are supposed to answer the given question. You need to output the answer in your final sentence like "Therefore, the answer is ...". The answer can only be one of the following forms:\n1. a numerical value like 0.1, no symbol and no unit at all.\n2. a list of number like [2, 3, 4].\n3. True/False.\n4. an option like (a), (b), (c), (d)\nQuestion: {Question}\nLet\'s think step by step.',
                            role='HUMAN'),
                        ]),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                type='opencompass.openicl.icl_retriever.ZeroRetriever')),
        path='./data/TheoremQA/test.csv',
        reader_cfg=dict(
            input_columns=[
                'Question',
                'Answer_type',
                ],
            output_column='Answer',
            train_split='test'),
        type='opencompass.datasets.TheoremQADataset'),
    dict(abbr='ceval-computer_network',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于计算机网络考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于计算机网络考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于计算机网络考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于计算机网络考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='computer_network',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-operating_system',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于操作系统考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于操作系统考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于操作系统考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于操作系统考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='operating_system',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-computer_architecture',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于计算机组成考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于计算机组成考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于计算机组成考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于计算机组成考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='computer_architecture',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-college_programming',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于大学编程考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于大学编程考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于大学编程考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于大学编程考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='college_programming',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-college_physics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于大学物理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于大学物理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于大学物理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于大学物理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='college_physics',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-college_chemistry',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于大学化学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于大学化学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于大学化学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于大学化学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='college_chemistry',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-advanced_mathematics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高等数学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高等数学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高等数学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高等数学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='advanced_mathematics',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-probability_and_statistics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于概率统计考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于概率统计考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于概率统计考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于概率统计考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='probability_and_statistics',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-discrete_mathematics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于离散数学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于离散数学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于离散数学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于离散数学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='discrete_mathematics',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-electrical_engineer',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于注册电气工程师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于注册电气工程师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于注册电气工程师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于注册电气工程师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='electrical_engineer',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-metrology_engineer',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于注册计量师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于注册计量师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于注册计量师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于注册计量师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='metrology_engineer',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-high_school_mathematics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中数学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中数学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中数学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中数学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_mathematics',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-high_school_physics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中物理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中物理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中物理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中物理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_physics',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-high_school_chemistry',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中化学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中化学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中化学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中化学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_chemistry',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-high_school_biology',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中生物考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中生物考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中生物考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中生物考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_biology',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-middle_school_mathematics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中数学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中数学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中数学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中数学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='middle_school_mathematics',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-middle_school_biology',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中生物考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中生物考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中生物考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中生物考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='middle_school_biology',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-middle_school_physics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中物理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中物理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中物理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中物理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='middle_school_physics',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-middle_school_chemistry',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中化学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中化学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中化学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中化学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='middle_school_chemistry',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-veterinary_medicine',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于兽医学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于兽医学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于兽医学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于兽医学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='veterinary_medicine',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-college_economics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于大学经济学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于大学经济学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于大学经济学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于大学经济学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='college_economics',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-business_administration',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于工商管理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于工商管理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于工商管理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于工商管理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='business_administration',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-marxism',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于马克思主义基本原理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于马克思主义基本原理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于马克思主义基本原理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于马克思主义基本原理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='marxism',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-mao_zedong_thought',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于毛泽东思想和中国特色社会主义理论体系概论考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于毛泽东思想和中国特色社会主义理论体系概论考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于毛泽东思想和中国特色社会主义理论体系概论考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于毛泽东思想和中国特色社会主义理论体系概论考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='mao_zedong_thought',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-education_science',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于教育学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于教育学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于教育学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于教育学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='education_science',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-teacher_qualification',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于教师资格考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于教师资格考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于教师资格考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于教师资格考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='teacher_qualification',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-high_school_politics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中政治考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中政治考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中政治考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中政治考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_politics',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-high_school_geography',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中地理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中地理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中地理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中地理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_geography',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-middle_school_politics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中政治考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中政治考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中政治考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中政治考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='middle_school_politics',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-middle_school_geography',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中地理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中地理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中地理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中地理考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='middle_school_geography',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-modern_chinese_history',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于近代史纲要考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于近代史纲要考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于近代史纲要考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于近代史纲要考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='modern_chinese_history',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-ideological_and_moral_cultivation',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于思想道德修养与法律基础考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于思想道德修养与法律基础考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于思想道德修养与法律基础考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于思想道德修养与法律基础考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='ideological_and_moral_cultivation',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-logic',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于逻辑学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于逻辑学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于逻辑学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于逻辑学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='logic',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-law',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于法学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于法学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于法学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于法学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='law',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-chinese_language_and_literature',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于中国语言文学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于中国语言文学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于中国语言文学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于中国语言文学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='chinese_language_and_literature',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-art_studies',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于艺术学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于艺术学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于艺术学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于艺术学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='art_studies',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-professional_tour_guide',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于导游资格考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于导游资格考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于导游资格考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于导游资格考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='professional_tour_guide',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-legal_professional',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于法律职业资格考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于法律职业资格考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于法律职业资格考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于法律职业资格考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='legal_professional',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-high_school_chinese',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中语文考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中语文考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中语文考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中语文考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_chinese',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-high_school_history',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中历史考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中历史考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中历史考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于高中历史考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_history',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-middle_school_history',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中历史考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中历史考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中历史考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于初中历史考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='middle_school_history',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-civil_servant',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于公务员考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于公务员考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于公务员考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于公务员考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='civil_servant',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-sports_science',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于体育学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于体育学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于体育学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于体育学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='sports_science',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-plant_protection',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于植物保护考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于植物保护考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于植物保护考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于植物保护考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='plant_protection',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-basic_medicine',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于基础医学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于基础医学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于基础医学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于基础医学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='basic_medicine',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-clinical_medicine',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于临床医学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于临床医学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于临床医学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于临床医学考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='clinical_medicine',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-urban_and_rural_planner',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于注册城乡规划师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于注册城乡规划师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于注册城乡规划师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于注册城乡规划师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='urban_and_rural_planner',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-accountant',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于注册会计师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于注册会计师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于注册会计师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于注册会计师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='accountant',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-fire_engineer',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于注册消防工程师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于注册消防工程师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于注册消防工程师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于注册消防工程师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='fire_engineer',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-environmental_impact_assessment_engineer',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于环境影响评价工程师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于环境影响评价工程师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于环境影响评价工程师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于环境影响评价工程师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='environmental_impact_assessment_engineer',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-tax_accountant',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于税务师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于税务师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于税务师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于税务师考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='tax_accountant',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='ceval-physician',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于医师资格考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于医师资格考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于医师资格考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是中国关于医师资格考试的单项选择题，请选出其中的正确答案。\n{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n答案: ',
                                role='HUMAN'),
                            dict(prompt='D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='physician',
        path='./data/ceval/formal_ceval',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='val',
            train_split='dev'),
        type='opencompass.datasets.CEvalDataset'),
    dict(abbr='cmmlu-agronomy',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于农学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于农学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于农学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于农学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='agronomy',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-anatomy',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于解剖学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于解剖学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于解剖学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于解剖学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='anatomy',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-ancient_chinese',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于古汉语的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于古汉语的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于古汉语的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于古汉语的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='ancient_chinese',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-arts',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于艺术学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于艺术学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于艺术学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于艺术学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='arts',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-astronomy',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于天文学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于天文学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于天文学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于天文学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='astronomy',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-business_ethics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于商业伦理的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于商业伦理的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于商业伦理的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于商业伦理的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='business_ethics',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-chinese_civil_service_exam',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国公务员考试的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国公务员考试的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国公务员考试的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国公务员考试的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='chinese_civil_service_exam',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-chinese_driving_rule',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国驾驶规则的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国驾驶规则的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国驾驶规则的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国驾驶规则的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='chinese_driving_rule',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-chinese_food_culture',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国饮食文化的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国饮食文化的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国饮食文化的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国饮食文化的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='chinese_food_culture',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-chinese_foreign_policy',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国外交政策的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国外交政策的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国外交政策的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国外交政策的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='chinese_foreign_policy',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-chinese_history',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国历史的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国历史的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国历史的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国历史的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='chinese_history',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-chinese_literature',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国文学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国文学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国文学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国文学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='chinese_literature',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-chinese_teacher_qualification',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国教师资格的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国教师资格的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国教师资格的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中国教师资格的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='chinese_teacher_qualification',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-clinical_knowledge',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于临床知识的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于临床知识的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于临床知识的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于临床知识的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='clinical_knowledge',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-college_actuarial_science',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学精算学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学精算学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学精算学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学精算学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='college_actuarial_science',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-college_education',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学教育学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学教育学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学教育学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学教育学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='college_education',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-college_engineering_hydrology',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学工程水文学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学工程水文学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学工程水文学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学工程水文学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='college_engineering_hydrology',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-college_law',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学法律的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学法律的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学法律的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学法律的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='college_law',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-college_mathematics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学数学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学数学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学数学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学数学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='college_mathematics',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-college_medical_statistics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学医学统计的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学医学统计的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学医学统计的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学医学统计的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='college_medical_statistics',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-college_medicine',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学医学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学医学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学医学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于大学医学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='college_medicine',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-computer_science',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于计算机科学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于计算机科学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于计算机科学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于计算机科学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='computer_science',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-computer_security',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于计算机安全的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于计算机安全的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于计算机安全的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于计算机安全的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='computer_security',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-conceptual_physics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于概念物理学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于概念物理学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于概念物理学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于概念物理学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='conceptual_physics',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-construction_project_management',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于建设工程管理的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于建设工程管理的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于建设工程管理的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于建设工程管理的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='construction_project_management',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-economics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于经济学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于经济学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于经济学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于经济学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='economics',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-education',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于教育学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于教育学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于教育学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于教育学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='education',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-electrical_engineering',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于电气工程的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于电气工程的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于电气工程的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于电气工程的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='electrical_engineering',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-elementary_chinese',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于小学语文的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于小学语文的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于小学语文的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于小学语文的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='elementary_chinese',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-elementary_commonsense',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于小学常识的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于小学常识的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于小学常识的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于小学常识的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='elementary_commonsense',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-elementary_information_and_technology',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于小学信息技术的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于小学信息技术的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于小学信息技术的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于小学信息技术的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='elementary_information_and_technology',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-elementary_mathematics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于初等数学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于初等数学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于初等数学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于初等数学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='elementary_mathematics',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-ethnology',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于民族学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于民族学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于民族学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于民族学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='ethnology',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-food_science',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于食品科学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于食品科学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于食品科学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于食品科学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='food_science',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-genetics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于遗传学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于遗传学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于遗传学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于遗传学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='genetics',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-global_facts',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于全球事实的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于全球事实的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于全球事实的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于全球事实的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='global_facts',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-high_school_biology',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于高中生物的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于高中生物的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于高中生物的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于高中生物的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_biology',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-high_school_chemistry',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于高中化学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于高中化学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于高中化学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于高中化学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_chemistry',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-high_school_geography',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于高中地理的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于高中地理的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于高中地理的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于高中地理的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_geography',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-high_school_mathematics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于高中数学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于高中数学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于高中数学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于高中数学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_mathematics',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-high_school_physics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于高中物理学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于高中物理学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于高中物理学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于高中物理学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_physics',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-high_school_politics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于高中政治的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于高中政治的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于高中政治的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于高中政治的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_politics',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-human_sexuality',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于人类性行为的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于人类性行为的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于人类性行为的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于人类性行为的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='human_sexuality',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-international_law',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于国际法学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于国际法学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于国际法学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于国际法学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='international_law',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-journalism',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于新闻学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于新闻学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于新闻学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于新闻学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='journalism',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-jurisprudence',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于法理学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于法理学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于法理学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于法理学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='jurisprudence',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-legal_and_moral_basis',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于法律与道德基础的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于法律与道德基础的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于法律与道德基础的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于法律与道德基础的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='legal_and_moral_basis',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-logical',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于逻辑学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于逻辑学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于逻辑学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于逻辑学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='logical',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-machine_learning',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于机器学习的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于机器学习的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于机器学习的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于机器学习的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='machine_learning',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-management',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于管理学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于管理学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于管理学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于管理学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='management',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-marketing',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于市场营销的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于市场营销的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于市场营销的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于市场营销的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='marketing',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-marxist_theory',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于马克思主义理论的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于马克思主义理论的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于马克思主义理论的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于马克思主义理论的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='marxist_theory',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-modern_chinese',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于现代汉语的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于现代汉语的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于现代汉语的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于现代汉语的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='modern_chinese',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-nutrition',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于营养学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于营养学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于营养学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于营养学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='nutrition',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-philosophy',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于哲学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于哲学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于哲学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于哲学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='philosophy',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-professional_accounting',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于专业会计的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于专业会计的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于专业会计的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于专业会计的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='professional_accounting',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-professional_law',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于专业法学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于专业法学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于专业法学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于专业法学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='professional_law',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-professional_medicine',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于专业医学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于专业医学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于专业医学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于专业医学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='professional_medicine',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-professional_psychology',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于专业心理学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于专业心理学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于专业心理学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于专业心理学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='professional_psychology',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-public_relations',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于公共关系的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于公共关系的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于公共关系的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于公共关系的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='public_relations',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-security_study',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于安全研究的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于安全研究的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于安全研究的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于安全研究的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='security_study',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-sociology',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于社会学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于社会学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于社会学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于社会学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='sociology',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-sports_science',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于体育学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于体育学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于体育学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于体育学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='sports_science',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-traditional_chinese_medicine',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中医中药的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中医中药的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中医中药的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于中医中药的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='traditional_chinese_medicine',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-virology',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于病毒学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于病毒学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于病毒学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于病毒学的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='virology',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-world_history',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于世界历史的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于世界历史的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于世界历史的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于世界历史的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='world_history',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    dict(abbr='cmmlu-world_religions',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                ice_token='</E>',
                template=dict(
                    A=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于世界宗教的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于世界宗教的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于世界宗教的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        begin='</E>',
                        round=[
                            dict(prompt='以下是关于世界宗教的单项选择题，请直接给出正确答案的选项。\n题目：{question}\nA. {A}\nB. {B}\nC. {C}\nD. {D}',
                                role='HUMAN'),
                            dict(prompt='答案是: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='world_religions',
        path='./data/cmmlu/',
        reader_cfg=dict(
            input_columns=[
                'question',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answer',
            test_split='test',
            train_split='dev'),
        type='opencompass.datasets.CMMLUDataset'),
    ]
gsm8k_datasets=[
    dict(abbr='gsm8k',
        eval_cfg=dict(
            dataset_postprocessor=dict(
                type='opencompass.datasets.gsm8k_dataset_postprocess'),
            evaluator=dict(
                type='opencompass.datasets.Gsm8kEvaluator'),
            pred_postprocessor=dict(
                type='opencompass.datasets.gsm8k_postprocess')),
        infer_cfg=dict(
            inferencer=dict(
                max_out_len=512,
                type='opencompass.openicl.icl_inferencer.GenInferencer'),
            prompt_template=dict(
                template=dict(
                    round=[
                        dict(prompt="Question: Angelo and Melanie want to plan how many hours over the next week they should study together for their test next week. They have 2 chapters of their textbook to study and 4 worksheets to memorize. They figure out that they should dedicate 3 hours to each chapter of their textbook and 1.5 hours for each worksheet. If they plan to study no more than 4 hours each day, how many days should they plan to study total over the next week if they take a 10-minute break every hour, include 3 10-minute snack breaks each day, and 30 minutes for lunch each day?\nLet's think step by step\nAnswer:",
                            role='HUMAN'),
                        dict(prompt='Angelo and Melanie think they should dedicate 3 hours to each of the 2 chapters, 3 hours x 2 chapters = 6 hours total.\nFor the worksheets they plan to dedicate 1.5 hours for each worksheet, 1.5 hours x 4 worksheets = 6 hours total.\nAngelo and Melanie need to start with planning 12 hours to study, at 4 hours a day, 12 / 4 = 3 days.\nHowever, they need to include time for breaks and lunch. Every hour they want to include a 10-minute break, so 12 total hours x 10 minutes = 120 extra minutes for breaks.\nThey also want to include 3 10-minute snack breaks, 3 x 10 minutes = 30 minutes.\nAnd they want to include 30 minutes for lunch each day, so 120 minutes for breaks + 30 minutes for snack breaks + 30 minutes for lunch = 180 minutes, or 180 / 60 minutes per hour = 3 extra hours.\nSo Angelo and Melanie want to plan 12 hours to study + 3 hours of breaks = 15 hours total.\nThey want to study no more than 4 hours each day, 15 hours / 4 hours each day = 3.75\nThey will need to plan to study 4 days to allow for all the time they need.\nThe answer is 4\n',
                            role='BOT'),
                        dict(prompt="Question: Mark's basketball team scores 25 2 pointers, 8 3 pointers and 10 free throws.  Their opponents score double the 2 pointers but half the 3 pointers and free throws.  What's the total number of points scored by both teams added together?\nLet's think step by step\nAnswer:",
                            role='HUMAN'),
                        dict(prompt="Mark's team scores 25 2 pointers, meaning they scored 25*2= 50 points in 2 pointers.\nHis team also scores 6 3 pointers, meaning they scored 8*3= 24 points in 3 pointers\nThey scored 10 free throws, and free throws count as one point so they scored 10*1=10 points in free throws.\nAll together his team scored 50+24+10= 84 points\nMark's opponents scored double his team's number of 2 pointers, meaning they scored 50*2=100 points in 2 pointers.\nHis opponents scored half his team's number of 3 pointers, meaning they scored 24/2= 12 points in 3 pointers.\nThey also scored half Mark's team's points in free throws, meaning they scored 10/2=5 points in free throws.\nAll together Mark's opponents scored 100+12+5=117 points\nThe total score for the game is both team's scores added together, so it is 84+117=201 points\nThe answer is 201\n",
                            role='BOT'),
                        dict(prompt="Question: Bella has two times as many marbles as frisbees. She also has 20 more frisbees than deck cards. If she buys 2/5 times more of each item, what would be the total number of the items she will have if she currently has 60 marbles?\nLet's think step by step\nAnswer:",
                            role='HUMAN'),
                        dict(prompt="When Bella buys 2/5 times more marbles, she'll have increased the number of marbles by 2/5*60 = 24\nThe total number of marbles she'll have is 60+24 = 84\nIf Bella currently has 60 marbles, and she has two times as many marbles as frisbees, she has 60/2 = 30 frisbees.\nIf Bella buys 2/5 times more frisbees, she'll have 2/5*30 = 12 more frisbees.\nThe total number of frisbees she'll have will increase to 30+12 = 42\nBella also has 20 more frisbees than deck cards, meaning she has 30-20 = 10 deck cards\nIf she buys 2/5 times more deck cards, she'll have 2/5*10 = 4 more deck cards.\nThe total number of deck cards she'll have is 10+4 = 14\nTogether, Bella will have a total of 14+42+84 = 140 items\nThe answer is 140\n",
                            role='BOT'),
                        dict(prompt="Question: A group of 4 fruit baskets contains 9 apples, 15 oranges, and 14 bananas in the first three baskets and 2 less of each fruit in the fourth basket. How many fruits are there?\nLet's think step by step\nAnswer:",
                            role='HUMAN'),
                        dict(prompt='For the first three baskets, the number of apples and oranges in one basket is 9+15=24\nIn total, together with bananas, the number of fruits in one basket is 24+14=38 for the first three baskets.\nSince there are three baskets each having 38 fruits, there are 3*38=114 fruits in the first three baskets.\nThe number of apples in the fourth basket is 9-2=7\nThere are also 15-2=13 oranges in the fourth basket\nThe combined number of oranges and apples in the fourth basket is 13+7=20\nThe fourth basket also contains 14-2=12 bananas.\nIn total, the fourth basket has 20+12=32 fruits.\nThe four baskets together have 32+114=146 fruits.\nThe answer is 146\n',
                            role='BOT'),
                        dict(prompt="Question: {question}\nLet's think step by step\nAnswer:",
                            role='HUMAN'),
                        ]),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                type='opencompass.openicl.icl_retriever.ZeroRetriever')),
        name='main',
        path='gsm8k',
        reader_cfg=dict(
            input_columns=[
                'question',
                ],
            output_column='answer'),
        type='opencompass.datasets.HFDataset'),
    ]
hellaswag_datasets=[
    dict(abbr='hellaswag',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                template=dict(
                    {'0': dict(
                        round=[
                            dict(prompt='{query} {A}',
                                role='HUMAN'),
                            ]),
                    '1': dict(
                        round=[
                            dict(prompt='{query} {B}',
                                role='HUMAN'),
                            ]),
                    '2': dict(
                        round=[
                            dict(prompt='{query} {C}',
                                role='HUMAN'),
                            ]),
                    '3': dict(
                        round=[
                            dict(prompt='{query} {D}',
                                role='HUMAN'),
                            ])}),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                type='opencompass.openicl.icl_retriever.ZeroRetriever')),
        path='./data/hellaswag/hellaswag.jsonl',
        reader_cfg=dict(
            input_columns=[
                'query',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='gold'),
        type='opencompass.datasets.hellaswagDataset_V3'),
    ]
humaneval_datasets=[
    dict(eval_cfg=dict(
            evaluator=dict(
                type='opencompass.datasets.HumanEvaluator'),
            k=[
                1,
                10,
                100,
                ],
            pred_postprocessor=dict(
                type='opencompass.datasets.humaneval_postprocess'),
            pred_role='BOT'),
        infer_cfg=dict(
            inferencer=dict(
                max_out_len=512,
                type='opencompass.openicl.icl_inferencer.GenInferencer'),
            prompt_template=dict(
                template=dict(
                    round=[
                        dict(prompt='{prompt}',
                            role='HUMAN'),
                        ]),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                type='opencompass.openicl.icl_retriever.ZeroRetriever')),
        path='openai_humaneval',
        reader_cfg=dict(
            input_columns=[
                'prompt',
                ],
            output_column='task_id',
            train_split='test'),
        type='opencompass.datasets.HFDataset'),
    ]
math_datasets=[
    dict(abbr='math',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.datasets.MATHEvaluator'),
            pred_postprocessor=dict(
                type='opencompass.datasets.math_postprocess')),
        infer_cfg=dict(
            inferencer=dict(
                max_out_len=512,
                type='opencompass.openicl.icl_inferencer.GenInferencer'),
            prompt_template=dict(
                template=dict(
                    round=[
                        dict(prompt='Problem:\nFind the domain of the expression $\\frac{{\\sqrt{{x-2}}}}{{\\sqrt{{5-x}}}}$.}}\nSolution:',
                            role='HUMAN'),
                        dict(prompt='The expressions inside each square root must be non-negative. Therefore, $x-2 \\ge 0$, so $x\\ge2$, and $5 - x \\ge 0$, so $x \\le 5$. Also, the denominator cannot be equal to zero, so $5-x>0$, which gives $x<5$. Therefore, the domain of the expression is $\\boxed{{[2,5)}}$.\nFinal Answer: The final answer is $[2,5)$. I hope it is correct.\n',
                            role='BOT'),
                        dict(prompt='Problem:\nIf $\\det \\mathbf{{A}} = 2$ and $\\det \\mathbf{{B}} = 12,$ then find $\\det (\\mathbf{{A}} \\mathbf{{B}}).$\nSolution:',
                            role='HUMAN'),
                        dict(prompt='We have that $\\det (\\mathbf{{A}} \\mathbf{{B}}) = (\\det \\mathbf{{A}})(\\det \\mathbf{{B}}) = (2)(12) = \\boxed{{24}}.$\nFinal Answer: The final answer is $24$. I hope it is correct.\n',
                            role='BOT'),
                        dict(prompt='Problem:\nTerrell usually lifts two 20-pound weights 12 times. If he uses two 15-pound weights instead, how many times must Terrell lift them in order to lift the same total weight?\nSolution:',
                            role='HUMAN'),
                        dict(prompt='If Terrell lifts two 20-pound weights 12 times, he lifts a total of $2\\cdot 12\\cdot20=480$ pounds of weight. If he lifts two 15-pound weights instead for $n$ times, he will lift a total of $2\\cdot15\\cdot n=30n$ pounds of weight. Equating this to 480 pounds, we can solve for $n$: \\begin{{align*}} 30n&=480\\\\ \\Rightarrow\\qquad n&=480/30=\\boxed{{16}} \\end{{align*}}\nFinal Answer: The final answer is $16$. I hope it is correct.\n',
                            role='BOT'),
                        dict(prompt='Problem:\nIf the system of equations: \\begin{{align*}} 6x-4y&=a,\\\\ 6y-9x &=b. \\end{{align*}}has a solution $(x, y)$ where $x$ and $y$ are both nonzero, find $\\frac{{a}}{{b}},$ assuming $b$ is nonzero.\nSolution:',
                            role='HUMAN'),
                        dict(prompt='If we multiply the first equation by $-\\frac{{3}}{{2}}$, we obtain $$6y-9x=-\\frac{{3}}{{2}}a.$$Since we also know that $6y-9x=b$, we have $$-\\frac{{3}}{{2}}a=b\\Rightarrow\\frac{{a}}{{b}}=\\boxed{{-\\frac{{2}}{{3}}}}.$$\nFinal Answer: The final answer is $-\\frac{{2}}{{3}}$. I hope it is correct.\n',
                            role='BOT'),
                        dict(prompt='Problem:\n{problem}\nSolution:\n',
                            role='HUMAN'),
                        ]),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                type='opencompass.openicl.icl_retriever.ZeroRetriever')),
        path='./data/math/math.json',
        reader_cfg=dict(
            input_columns=[
                'problem',
                ],
            output_column='solution'),
        type='opencompass.datasets.MATHDataset'),
    ]
mbpp_datasets=[
    dict(abbr='mbpp',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.datasets.MBPPEvaluator'),
            pred_role='BOT'),
        infer_cfg=dict(
            inferencer=dict(
                max_out_len=512,
                type='opencompass.openicl.icl_inferencer.GenInferencer'),
            prompt_template=dict(
                template=dict(
                    round=[
                        dict(prompt='You are an expert Python programmer, and here is your task: Write a function to find the similar elements from the given two tuple lists. Your code should pass these tests:\n\n assert similar_elements((3, 4, 5, 6),(5, 7, 4, 10)) == (4, 5)\n assert similar_elements((1, 2, 3, 4),(5, 4, 3, 7)) == (3, 4) \n assert similar_elements((11, 12, 14, 13),(17, 15, 14, 13)) == (13, 14) \n',
                            role='HUMAN'),
                        dict(prompt="[BEGIN]\n 'def similar_elements(test_tup1, test_tup2):\r\n  res = tuple(set(test_tup1) & set(test_tup2))\r\n  return (res)' \n[DONE] \n\n ",
                            role='BOT'),
                        dict(prompt='You are an expert Python programmer, and here is your task: Write a python function to identify non-prime numbers. Your code should pass these tests:\n\n assert is_not_prime(2) == False \n assert is_not_prime(10) == True \n assert is_not_prime(35) == True \n',
                            role='HUMAN'),
                        dict(prompt="[BEGIN]\n 'import math\r\ndef is_not_prime(n):\r\n    result = False\r\n    for i in range(2,int(math.sqrt(n)) + 1):\r\n        if n % i == 0:\r\n            result = True\r\n    return result' \n[DONE] \n\n ",
                            role='BOT'),
                        dict(prompt='You are an expert Python programmer, and here is your task: Write a function to find the largest integers from a given list of numbers using heap queue algorithm. Your code should pass these tests:\n\n assert heap_queue_largest( [25, 35, 22, 85, 14, 65, 75, 22, 58],3)==[85, 75, 65] \n assert heap_queue_largest( [25, 35, 22, 85, 14, 65, 75, 22, 58],2)==[85, 75] \n assert heap_queue_largest( [25, 35, 22, 85, 14, 65, 75, 22, 58],5)==[85, 75, 65, 58, 35] \n',
                            role='HUMAN'),
                        dict(prompt="[BEGIN]\n 'import heapq as hq\r\ndef heap_queue_largest(nums,n):\r\n  largest_nums = hq.nlargest(n, nums)\r\n  return largest_nums' \n[DONE] \n\n ",
                            role='BOT'),
                        dict(prompt='You are an expert Python programmer, and here is your task: {text} Your code should pass these tests:\n\n {test_list}  \n',
                            role='HUMAN'),
                        dict(prompt='[BEGIN]\n',
                            role='BOT'),
                        ]),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                type='opencompass.openicl.icl_retriever.ZeroRetriever')),
        path='./data/mbpp/mbpp.jsonl',
        reader_cfg=dict(
            input_columns=[
                'text',
                'test_list',
                ],
            output_column='test_list_2'),
        type='opencompass.datasets.MBPPDataset'),
    ]
mmlu_datasets=[
    dict(abbr='lukaemon_mmlu_college_biology',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  college biology.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  college biology.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  college biology.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  college biology.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='college_biology',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_college_chemistry',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  college chemistry.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  college chemistry.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  college chemistry.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  college chemistry.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='college_chemistry',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_college_computer_science',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  college computer science.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  college computer science.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  college computer science.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  college computer science.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='college_computer_science',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_college_mathematics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  college mathematics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  college mathematics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  college mathematics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  college mathematics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='college_mathematics',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_college_physics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  college physics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  college physics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  college physics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  college physics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='college_physics',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_electrical_engineering',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  electrical engineering.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  electrical engineering.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  electrical engineering.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  electrical engineering.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='electrical_engineering',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_astronomy',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  astronomy.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  astronomy.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  astronomy.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  astronomy.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='astronomy',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_anatomy',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  anatomy.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  anatomy.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  anatomy.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  anatomy.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='anatomy',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_abstract_algebra',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  abstract algebra.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  abstract algebra.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  abstract algebra.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  abstract algebra.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='abstract_algebra',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_machine_learning',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  machine learning.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  machine learning.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  machine learning.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  machine learning.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='machine_learning',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_clinical_knowledge',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  clinical knowledge.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  clinical knowledge.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  clinical knowledge.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  clinical knowledge.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='clinical_knowledge',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_global_facts',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  global facts.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  global facts.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  global facts.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  global facts.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='global_facts',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_management',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  management.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  management.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  management.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  management.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='management',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_nutrition',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  nutrition.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  nutrition.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  nutrition.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  nutrition.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='nutrition',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_marketing',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  marketing.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  marketing.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  marketing.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  marketing.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='marketing',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_professional_accounting',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  professional accounting.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  professional accounting.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  professional accounting.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  professional accounting.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='professional_accounting',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_high_school_geography',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  high school geography.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  high school geography.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  high school geography.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  high school geography.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_geography',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_international_law',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  international law.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  international law.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  international law.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  international law.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='international_law',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_moral_scenarios',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  moral scenarios.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  moral scenarios.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  moral scenarios.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  moral scenarios.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='moral_scenarios',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_computer_security',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  computer security.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  computer security.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  computer security.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  computer security.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='computer_security',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_high_school_microeconomics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  high school microeconomics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  high school microeconomics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  high school microeconomics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  high school microeconomics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_microeconomics',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_professional_law',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  professional law.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  professional law.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  professional law.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  professional law.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='professional_law',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_medical_genetics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  medical genetics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  medical genetics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  medical genetics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  medical genetics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='medical_genetics',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_professional_psychology',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  professional psychology.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  professional psychology.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  professional psychology.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  professional psychology.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='professional_psychology',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_jurisprudence',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  jurisprudence.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  jurisprudence.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  jurisprudence.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  jurisprudence.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='jurisprudence',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_world_religions',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  world religions.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  world religions.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  world religions.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  world religions.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='world_religions',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_philosophy',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  philosophy.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  philosophy.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  philosophy.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  philosophy.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='philosophy',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_virology',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  virology.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  virology.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  virology.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  virology.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='virology',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_high_school_chemistry',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  high school chemistry.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  high school chemistry.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  high school chemistry.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  high school chemistry.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_chemistry',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_public_relations',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  public relations.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  public relations.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  public relations.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  public relations.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='public_relations',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_high_school_macroeconomics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  high school macroeconomics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  high school macroeconomics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  high school macroeconomics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  high school macroeconomics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_macroeconomics',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_human_sexuality',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  human sexuality.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  human sexuality.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  human sexuality.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  human sexuality.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='human_sexuality',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_elementary_mathematics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  elementary mathematics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  elementary mathematics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  elementary mathematics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  elementary mathematics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='elementary_mathematics',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_high_school_physics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  high school physics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  high school physics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  high school physics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  high school physics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_physics',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_high_school_computer_science',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  high school computer science.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  high school computer science.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  high school computer science.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  high school computer science.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_computer_science',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_high_school_european_history',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  high school european history.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  high school european history.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  high school european history.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  high school european history.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_european_history',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_business_ethics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  business ethics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  business ethics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  business ethics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  business ethics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='business_ethics',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_moral_disputes',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  moral disputes.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  moral disputes.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  moral disputes.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  moral disputes.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='moral_disputes',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_high_school_statistics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  high school statistics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  high school statistics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  high school statistics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  high school statistics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_statistics',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_miscellaneous',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  miscellaneous.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  miscellaneous.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  miscellaneous.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  miscellaneous.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='miscellaneous',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_formal_logic',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  formal logic.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  formal logic.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  formal logic.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  formal logic.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='formal_logic',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_high_school_government_and_politics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  high school government and politics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  high school government and politics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  high school government and politics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  high school government and politics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_government_and_politics',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_prehistory',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  prehistory.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  prehistory.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  prehistory.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  prehistory.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='prehistory',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_security_studies',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  security studies.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  security studies.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  security studies.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  security studies.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='security_studies',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_high_school_biology',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  high school biology.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  high school biology.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  high school biology.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  high school biology.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_biology',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_logical_fallacies',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  logical fallacies.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  logical fallacies.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  logical fallacies.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  logical fallacies.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='logical_fallacies',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_high_school_world_history',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  high school world history.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  high school world history.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  high school world history.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  high school world history.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_world_history',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_professional_medicine',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  professional medicine.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  professional medicine.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  professional medicine.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  professional medicine.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='professional_medicine',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_high_school_mathematics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  high school mathematics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  high school mathematics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  high school mathematics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  high school mathematics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_mathematics',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_college_medicine',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  college medicine.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  college medicine.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  college medicine.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  college medicine.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='college_medicine',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_high_school_us_history',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  high school us history.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  high school us history.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  high school us history.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  high school us history.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_us_history',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_sociology',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  sociology.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  sociology.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  sociology.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  sociology.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='sociology',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_econometrics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  econometrics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  econometrics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  econometrics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  econometrics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='econometrics',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_high_school_psychology',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  high school psychology.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  high school psychology.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  high school psychology.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  high school psychology.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='high_school_psychology',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_human_aging',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  human aging.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  human aging.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  human aging.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  human aging.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='human_aging',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_us_foreign_policy',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  us foreign policy.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  us foreign policy.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  us foreign policy.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  us foreign policy.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='us_foreign_policy',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    dict(abbr='lukaemon_mmlu_conceptual_physics',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    A='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A\n',
                    B='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B\n',
                    C='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C\n',
                    D='{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D\n'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    A='The following are multiple choice questions (with answers) about  conceptual physics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: A',
                    B='The following are multiple choice questions (with answers) about  conceptual physics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: B',
                    C='The following are multiple choice questions (with answers) about  conceptual physics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: C',
                    D='The following are multiple choice questions (with answers) about  conceptual physics.\n\n</E>{input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: D'),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        name='conceptual_physics',
        path='./data/mmlu/',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target',
            train_split='dev'),
        type='opencompass.datasets.MMLUDataset'),
    ]
models=[
    dict(abbr='hf_llama-7b',
        batch_padding=False,
        batch_size=16,
        max_out_len=100,
        max_seq_len=2048,
        model_kwargs=dict(
            device_map='auto',
            trust_remote_code=True),
        path='huggyllama/llama-7b',
        run_cfg=dict(
            num_gpus=1,
            num_procs=1),
        tokenizer_kwargs=dict(
            padding_side='left',
            truncation_side='left',
            trust_remote_code=True,
            use_fast=False),
        tokenizer_path='huggyllama/llama-7b',
        type='opencompass.models.HuggingFaceCausalLM'),
    ]
nq_datasets=[
    dict(abbr='nq',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.datasets.NQEvaluator'),
            pred_role='BOT'),
        infer_cfg=dict(
            inferencer=dict(
                max_out_len=50,
                type='opencompass.openicl.icl_inferencer.GenInferencer'),
            prompt_template=dict(
                template=dict(
                    round=[
                        dict(prompt="Answer these questions, your answer should be as simple as possible, start your answer with the prompt 'The answer is '.\nQ: {question}?",
                            role='HUMAN'),
                        dict(prompt='A:',
                            role='BOT'),
                        ]),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                type='opencompass.openicl.icl_retriever.ZeroRetriever')),
        path='./data/nq/',
        reader_cfg=dict(
            input_columns=[
                'question',
                ],
            output_column='answer',
            train_split='dev'),
        type='opencompass.datasets.NaturalQuestionDataset'),
    dict(abbr='nq_1shot',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.datasets.NQEvaluator'),
            pred_role='BOT'),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    round=[
                        dict(prompt="Answer the question, your answer should be as simple as possible, start your answer with the prompt 'The answer is '.\nQ: {question}?",
                            role='HUMAN'),
                        dict(prompt='A: The answer is {answer}.\n',
                            role='BOT'),
                        ]),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                max_out_len=50,
                type='opencompass.openicl.icl_inferencer.GenInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    begin='</E>',
                    round=[
                        dict(prompt="Answer the question, your answer should be as simple as possible, start your answer with the prompt 'The answer is '.\nQ: {question}?",
                            role='HUMAN'),
                        dict(prompt='A:',
                            role='BOT'),
                        ]),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        path='./data/nq/',
        reader_cfg=dict(
            input_columns=[
                'question',
                ],
            output_column='answer',
            train_split='dev'),
        type='opencompass.datasets.NaturalQuestionDataset'),
    dict(abbr='nq_5shot',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.datasets.NQEvaluator'),
            pred_role='BOT'),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    round=[
                        dict(prompt="Answer the question, your answer should be as simple as possible, start your answer with the prompt 'The answer is '.\nQ: {question}?",
                            role='HUMAN'),
                        dict(prompt='A: The answer is {answer}.\n',
                            role='BOT'),
                        ]),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                max_out_len=50,
                type='opencompass.openicl.icl_inferencer.GenInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    begin='</E>',
                    round=[
                        dict(prompt="Answer the question, your answer should be as simple as possible, start your answer with the prompt 'The answer is '.\nQ: {question}?",
                            role='HUMAN'),
                        dict(prompt='A:',
                            role='BOT'),
                        ]),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        path='./data/nq/',
        reader_cfg=dict(
            input_columns=[
                'question',
                ],
            output_column='answer',
            train_split='dev'),
        type='opencompass.datasets.NaturalQuestionDataset'),
    ]
obqa_datasets=[
    dict(abbr='openbookqa_fact',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                template=dict(
                    A=dict(
                        round=[
                            dict(prompt='We know the fact that {fact1}.\nQuestion: {question_stem}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n',
                                role='HUMAN'),
                            dict(prompt='Answer: A',
                                role='BOT'),
                            ]),
                    B=dict(
                        round=[
                            dict(prompt='We know the fact that {fact1}.\nQuestion: {question_stem}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n',
                                role='HUMAN'),
                            dict(prompt='Answer: B',
                                role='BOT'),
                            ]),
                    C=dict(
                        round=[
                            dict(prompt='We know the fact that {fact1}.\nQuestion: {question_stem}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n',
                                role='HUMAN'),
                            dict(prompt='Answer: C',
                                role='BOT'),
                            ]),
                    D=dict(
                        round=[
                            dict(prompt='We know the fact that {fact1}.\nQuestion: {question_stem}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\n',
                                role='HUMAN'),
                            dict(prompt='Answer: D',
                                role='BOT'),
                            ])),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                type='opencompass.openicl.icl_retriever.ZeroRetriever')),
        name='additional',
        path='openbookqa',
        reader_cfg=dict(
            input_columns=[
                'question_stem',
                'A',
                'B',
                'C',
                'D',
                'fact1',
                ],
            output_column='answerKey'),
        split='test',
        type='opencompass.datasets.OBQADataset_V2'),
    ]
piqa_datasets=[
    dict(abbr='piqa',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                template=dict(
                    {'0': dict(
                        round=[
                            dict(prompt='{goal} {sol1}',
                                role='HUMAN'),
                            ]),
                    '1': dict(
                        round=[
                            dict(prompt='{goal} {sol2}',
                                role='HUMAN'),
                            ])}),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                type='opencompass.openicl.icl_retriever.ZeroRetriever')),
        path='piqa',
        reader_cfg=dict(
            input_columns=[
                'goal',
                'sol1',
                'sol2',
                ],
            output_column='label',
            test_split='validation'),
        type='opencompass.datasets.piqaDataset_V3'),
    ]
siqa_datasets=[
    dict(abbr='siqa',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                template=dict(
                    {'1': dict(
                        round=[
                            dict(prompt='{context}\nQuestion: {question}\nA. {answerA}\nB. {answerB}\nC. {answerC}',
                                role='HUMAN'),
                            dict(prompt='Answer: A',
                                role='BOT'),
                            ]),
                    '2': dict(
                        round=[
                            dict(prompt='{context}\nQuestion: {question}\nA. {answerA}\nB. {answerB}\nC. {answerC}',
                                role='HUMAN'),
                            dict(prompt='Answer: B',
                                role='BOT'),
                            ]),
                    '3': dict(
                        round=[
                            dict(prompt='{context}\nQuestion: {question}\nA. {answerA}\nB. {answerB}\nC. {answerC}',
                                role='HUMAN'),
                            dict(prompt='Answer: C',
                                role='BOT'),
                            ])}),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                type='opencompass.openicl.icl_retriever.ZeroRetriever')),
        path='social_i_qa',
        reader_cfg=dict(
            input_columns=[
                'context',
                'question',
                'answerA',
                'answerB',
                'answerC',
                ],
            output_column='label',
            test_split='validation'),
        type='opencompass.datasets.HFDataset'),
    ]
squad20_datasets=[
    dict(abbr='squad2.0',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.datasets.SQuAD20Evaluator'),
            pred_role='BOT'),
        infer_cfg=dict(
            inferencer=dict(
                max_out_len=50,
                type='opencompass.openicl.icl_inferencer.GenInferencer'),
            prompt_template=dict(
                template=dict(
                    round=[
                        dict(prompt='{context}\nAccording to the above passage, answer the following question. If it is impossible to answer according to the passage, answer `impossible to answer`:\nQuestion: {question}',
                            role='HUMAN'),
                        dict(prompt='Answer:',
                            role='BOT'),
                        ]),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                type='opencompass.openicl.icl_retriever.ZeroRetriever')),
        path='./data/SQuAD2.0/dev-v2.0.json',
        reader_cfg=dict(
            input_columns=[
                'context',
                'question',
                ],
            output_column='answers'),
        type='opencompass.datasets.SQuAD20Dataset'),
    ]
summarizer=dict(
    dataset_abbrs=[
        '------- MMLU details -------',
        'mmlu-humanities',
        'mmlu-stem',
        'mmlu-social-science',
        'mmlu-other',
        'mmlu',
        '---- Standard Benchmarks ---',
        'BoolQ',
        'piqa',
        'siqa',
        'hellaswag',
        'winogrande',
        'ARC-e',
        'ARC-c',
        'openbookqa_fact',
        'commonsense_qa',
        'mmlu',
        '------ Code Generation -----',
        'openai_humaneval',
        'mbpp',
        '------ World Knowledge -----',
        'natural_questiontriviaqa',
        '--- Reading Comprehension --',
        'squad2.0',
        '---------- Exams -----------',
        'math',
        'gsm8k',
        'TheoremQA',
        '--------- Chinese ----------',
        'ceval',
        'ceval-stem',
        'ceval-social-science',
        'ceval-humanities',
        'ceval-other',
        'ceval-hard',
        'cmmlu',
        'cmmlu-humanities',
        'cmmlu-stem',
        'cmmlu-social-science',
        'cmmlu-other',
        'cmmlu-china-specific',
        ],
    summary_groups=[
        dict(name='mmlu-humanities',
            subsets=[
                'lukaemon_mmlu_formal_logic',
                'lukaemon_mmlu_high_school_european_history',
                'lukaemon_mmlu_high_school_us_history',
                'lukaemon_mmlu_high_school_world_history',
                'lukaemon_mmlu_international_law',
                'lukaemon_mmlu_jurisprudence',
                'lukaemon_mmlu_logical_fallacies',
                'lukaemon_mmlu_moral_disputes',
                'lukaemon_mmlu_moral_scenarios',
                'lukaemon_mmlu_philosophy',
                'lukaemon_mmlu_prehistory',
                'lukaemon_mmlu_professional_law',
                'lukaemon_mmlu_world_religions',
                ]),
        dict(name='mmlu-stem',
            subsets=[
                'lukaemon_mmlu_abstract_algebra',
                'lukaemon_mmlu_anatomy',
                'lukaemon_mmlu_astronomy',
                'lukaemon_mmlu_college_biology',
                'lukaemon_mmlu_college_chemistry',
                'lukaemon_mmlu_college_computer_science',
                'lukaemon_mmlu_college_mathematics',
                'lukaemon_mmlu_college_physics',
                'lukaemon_mmlu_computer_security',
                'lukaemon_mmlu_conceptual_physics',
                'lukaemon_mmlu_electrical_engineering',
                'lukaemon_mmlu_elementary_mathematics',
                'lukaemon_mmlu_high_school_biology',
                'lukaemon_mmlu_high_school_chemistry',
                'lukaemon_mmlu_high_school_computer_science',
                'lukaemon_mmlu_high_school_mathematics',
                'lukaemon_mmlu_high_school_physics',
                'lukaemon_mmlu_high_school_statistics',
                'lukaemon_mmlu_machine_learning',
                ]),
        dict(name='mmlu-social-science',
            subsets=[
                'lukaemon_mmlu_econometrics',
                'lukaemon_mmlu_high_school_geography',
                'lukaemon_mmlu_high_school_government_and_politics',
                'lukaemon_mmlu_high_school_macroeconomics',
                'lukaemon_mmlu_high_school_microeconomics',
                'lukaemon_mmlu_high_school_psychology',
                'lukaemon_mmlu_human_sexuality',
                'lukaemon_mmlu_professional_psychology',
                'lukaemon_mmlu_public_relations',
                'lukaemon_mmlu_security_studies',
                'lukaemon_mmlu_sociology',
                'lukaemon_mmlu_us_foreign_policy',
                ]),
        dict(name='mmlu-other',
            subsets=[
                'lukaemon_mmlu_business_ethics',
                'lukaemon_mmlu_clinical_knowledge',
                'lukaemon_mmlu_college_medicine',
                'lukaemon_mmlu_global_facts',
                'lukaemon_mmlu_human_aging',
                'lukaemon_mmlu_management',
                'lukaemon_mmlu_marketing',
                'lukaemon_mmlu_medical_genetics',
                'lukaemon_mmlu_miscellaneous',
                'lukaemon_mmlu_nutrition',
                'lukaemon_mmlu_professional_accounting',
                'lukaemon_mmlu_professional_medicine',
                'lukaemon_mmlu_virology',
                ]),
        dict(name='mmlu',
            subsets=[
                'lukaemon_mmlu_formal_logic',
                'lukaemon_mmlu_high_school_european_history',
                'lukaemon_mmlu_high_school_us_history',
                'lukaemon_mmlu_high_school_world_history',
                'lukaemon_mmlu_international_law',
                'lukaemon_mmlu_jurisprudence',
                'lukaemon_mmlu_logical_fallacies',
                'lukaemon_mmlu_moral_disputes',
                'lukaemon_mmlu_moral_scenarios',
                'lukaemon_mmlu_philosophy',
                'lukaemon_mmlu_prehistory',
                'lukaemon_mmlu_professional_law',
                'lukaemon_mmlu_world_religions',
                'lukaemon_mmlu_abstract_algebra',
                'lukaemon_mmlu_anatomy',
                'lukaemon_mmlu_astronomy',
                'lukaemon_mmlu_college_biology',
                'lukaemon_mmlu_college_chemistry',
                'lukaemon_mmlu_college_computer_science',
                'lukaemon_mmlu_college_mathematics',
                'lukaemon_mmlu_college_physics',
                'lukaemon_mmlu_computer_security',
                'lukaemon_mmlu_conceptual_physics',
                'lukaemon_mmlu_electrical_engineering',
                'lukaemon_mmlu_elementary_mathematics',
                'lukaemon_mmlu_high_school_biology',
                'lukaemon_mmlu_high_school_chemistry',
                'lukaemon_mmlu_high_school_computer_science',
                'lukaemon_mmlu_high_school_mathematics',
                'lukaemon_mmlu_high_school_physics',
                'lukaemon_mmlu_high_school_statistics',
                'lukaemon_mmlu_machine_learning',
                'lukaemon_mmlu_econometrics',
                'lukaemon_mmlu_high_school_geography',
                'lukaemon_mmlu_high_school_government_and_politics',
                'lukaemon_mmlu_high_school_macroeconomics',
                'lukaemon_mmlu_high_school_microeconomics',
                'lukaemon_mmlu_high_school_psychology',
                'lukaemon_mmlu_human_sexuality',
                'lukaemon_mmlu_professional_psychology',
                'lukaemon_mmlu_public_relations',
                'lukaemon_mmlu_security_studies',
                'lukaemon_mmlu_sociology',
                'lukaemon_mmlu_us_foreign_policy',
                'lukaemon_mmlu_business_ethics',
                'lukaemon_mmlu_clinical_knowledge',
                'lukaemon_mmlu_college_medicine',
                'lukaemon_mmlu_global_facts',
                'lukaemon_mmlu_human_aging',
                'lukaemon_mmlu_management',
                'lukaemon_mmlu_marketing',
                'lukaemon_mmlu_medical_genetics',
                'lukaemon_mmlu_miscellaneous',
                'lukaemon_mmlu_nutrition',
                'lukaemon_mmlu_professional_accounting',
                'lukaemon_mmlu_professional_medicine',
                'lukaemon_mmlu_virology',
                ]),
        dict(name='mmlu-weighted',
            subsets=[
                'lukaemon_mmlu_formal_logic',
                'lukaemon_mmlu_high_school_european_history',
                'lukaemon_mmlu_high_school_us_history',
                'lukaemon_mmlu_high_school_world_history',
                'lukaemon_mmlu_international_law',
                'lukaemon_mmlu_jurisprudence',
                'lukaemon_mmlu_logical_fallacies',
                'lukaemon_mmlu_moral_disputes',
                'lukaemon_mmlu_moral_scenarios',
                'lukaemon_mmlu_philosophy',
                'lukaemon_mmlu_prehistory',
                'lukaemon_mmlu_professional_law',
                'lukaemon_mmlu_world_religions',
                'lukaemon_mmlu_abstract_algebra',
                'lukaemon_mmlu_anatomy',
                'lukaemon_mmlu_astronomy',
                'lukaemon_mmlu_college_biology',
                'lukaemon_mmlu_college_chemistry',
                'lukaemon_mmlu_college_computer_science',
                'lukaemon_mmlu_college_mathematics',
                'lukaemon_mmlu_college_physics',
                'lukaemon_mmlu_computer_security',
                'lukaemon_mmlu_conceptual_physics',
                'lukaemon_mmlu_electrical_engineering',
                'lukaemon_mmlu_elementary_mathematics',
                'lukaemon_mmlu_high_school_biology',
                'lukaemon_mmlu_high_school_chemistry',
                'lukaemon_mmlu_high_school_computer_science',
                'lukaemon_mmlu_high_school_mathematics',
                'lukaemon_mmlu_high_school_physics',
                'lukaemon_mmlu_high_school_statistics',
                'lukaemon_mmlu_machine_learning',
                'lukaemon_mmlu_econometrics',
                'lukaemon_mmlu_high_school_geography',
                'lukaemon_mmlu_high_school_government_and_politics',
                'lukaemon_mmlu_high_school_macroeconomics',
                'lukaemon_mmlu_high_school_microeconomics',
                'lukaemon_mmlu_high_school_psychology',
                'lukaemon_mmlu_human_sexuality',
                'lukaemon_mmlu_professional_psychology',
                'lukaemon_mmlu_public_relations',
                'lukaemon_mmlu_security_studies',
                'lukaemon_mmlu_sociology',
                'lukaemon_mmlu_us_foreign_policy',
                'lukaemon_mmlu_business_ethics',
                'lukaemon_mmlu_clinical_knowledge',
                'lukaemon_mmlu_college_medicine',
                'lukaemon_mmlu_global_facts',
                'lukaemon_mmlu_human_aging',
                'lukaemon_mmlu_management',
                'lukaemon_mmlu_marketing',
                'lukaemon_mmlu_medical_genetics',
                'lukaemon_mmlu_miscellaneous',
                'lukaemon_mmlu_nutrition',
                'lukaemon_mmlu_professional_accounting',
                'lukaemon_mmlu_professional_medicine',
                'lukaemon_mmlu_virology',
                ],
            weights=dict(
                lukaemon_mmlu_abstract_algebra=100,
                lukaemon_mmlu_anatomy=135,
                lukaemon_mmlu_astronomy=152,
                lukaemon_mmlu_business_ethics=100,
                lukaemon_mmlu_clinical_knowledge=265,
                lukaemon_mmlu_college_biology=144,
                lukaemon_mmlu_college_chemistry=100,
                lukaemon_mmlu_college_computer_science=100,
                lukaemon_mmlu_college_mathematics=100,
                lukaemon_mmlu_college_medicine=173,
                lukaemon_mmlu_college_physics=102,
                lukaemon_mmlu_computer_security=100,
                lukaemon_mmlu_conceptual_physics=235,
                lukaemon_mmlu_econometrics=114,
                lukaemon_mmlu_electrical_engineering=145,
                lukaemon_mmlu_elementary_mathematics=378,
                lukaemon_mmlu_formal_logic=126,
                lukaemon_mmlu_global_facts=100,
                lukaemon_mmlu_high_school_biology=310,
                lukaemon_mmlu_high_school_chemistry=203,
                lukaemon_mmlu_high_school_computer_science=100,
                lukaemon_mmlu_high_school_european_history=165,
                lukaemon_mmlu_high_school_geography=198,
                lukaemon_mmlu_high_school_government_and_politics=193,
                lukaemon_mmlu_high_school_macroeconomics=390,
                lukaemon_mmlu_high_school_mathematics=270,
                lukaemon_mmlu_high_school_microeconomics=238,
                lukaemon_mmlu_high_school_physics=151,
                lukaemon_mmlu_high_school_psychology=545,
                lukaemon_mmlu_high_school_statistics=216,
                lukaemon_mmlu_high_school_us_history=204,
                lukaemon_mmlu_high_school_world_history=237,
                lukaemon_mmlu_human_aging=223,
                lukaemon_mmlu_human_sexuality=131,
                lukaemon_mmlu_international_law=121,
                lukaemon_mmlu_jurisprudence=108,
                lukaemon_mmlu_logical_fallacies=163,
                lukaemon_mmlu_machine_learning=112,
                lukaemon_mmlu_management=103,
                lukaemon_mmlu_marketing=234,
                lukaemon_mmlu_medical_genetics=100,
                lukaemon_mmlu_miscellaneous=783,
                lukaemon_mmlu_moral_disputes=346,
                lukaemon_mmlu_moral_scenarios=895,
                lukaemon_mmlu_nutrition=306,
                lukaemon_mmlu_philosophy=311,
                lukaemon_mmlu_prehistory=324,
                lukaemon_mmlu_professional_accounting=282,
                lukaemon_mmlu_professional_law=1534,
                lukaemon_mmlu_professional_medicine=272,
                lukaemon_mmlu_professional_psychology=612,
                lukaemon_mmlu_public_relations=110,
                lukaemon_mmlu_security_studies=245,
                lukaemon_mmlu_sociology=201,
                lukaemon_mmlu_us_foreign_policy=100,
                lukaemon_mmlu_virology=166,
                lukaemon_mmlu_world_religions=171)),
        dict(name='cmmlu-humanities',
            subsets=[
                'cmmlu-arts',
                'cmmlu-chinese_history',
                'cmmlu-chinese_literature',
                'cmmlu-college_law',
                'cmmlu-global_facts',
                'cmmlu-international_law',
                'cmmlu-jurisprudence',
                'cmmlu-logical',
                'cmmlu-marxist_theory',
                'cmmlu-philosophy',
                'cmmlu-professional_law',
                'cmmlu-world_history',
                'cmmlu-world_religions',
                ]),
        dict(name='cmmlu-stem',
            subsets=[
                'cmmlu-anatomy',
                'cmmlu-astronomy',
                'cmmlu-college_actuarial_science',
                'cmmlu-college_engineering_hydrology',
                'cmmlu-college_mathematics',
                'cmmlu-college_medical_statistics',
                'cmmlu-computer_science',
                'cmmlu-conceptual_physics',
                'cmmlu-electrical_engineering',
                'cmmlu-elementary_mathematics',
                'cmmlu-genetics',
                'cmmlu-high_school_biology',
                'cmmlu-high_school_chemistry',
                'cmmlu-high_school_mathematics',
                'cmmlu-high_school_physics',
                'cmmlu-machine_learning',
                'cmmlu-virology',
                ]),
        dict(name='cmmlu-social-science',
            subsets=[
                'cmmlu-ancient_chinese',
                'cmmlu-business_ethics',
                'cmmlu-chinese_civil_service_exam',
                'cmmlu-chinese_food_culture',
                'cmmlu-chinese_foreign_policy',
                'cmmlu-chinese_teacher_qualification',
                'cmmlu-college_education',
                'cmmlu-economics',
                'cmmlu-education',
                'cmmlu-elementary_chinese',
                'cmmlu-ethnology',
                'cmmlu-high_school_geography',
                'cmmlu-high_school_politics',
                'cmmlu-journalism',
                'cmmlu-management',
                'cmmlu-marketing',
                'cmmlu-modern_chinese',
                'cmmlu-professional_accounting',
                'cmmlu-professional_psychology',
                'cmmlu-public_relations',
                'cmmlu-security_study',
                'cmmlu-sociology',
                ]),
        dict(name='cmmlu-other',
            subsets=[
                'cmmlu-agronomy',
                'cmmlu-chinese_driving_rule',
                'cmmlu-clinical_knowledge',
                'cmmlu-college_medicine',
                'cmmlu-computer_security',
                'cmmlu-construction_project_management',
                'cmmlu-elementary_commonsense',
                'cmmlu-elementary_information_and_technology',
                'cmmlu-food_science',
                'cmmlu-human_sexuality',
                'cmmlu-legal_and_moral_basis',
                'cmmlu-nutrition',
                'cmmlu-professional_medicine',
                'cmmlu-sports_science',
                'cmmlu-traditional_chinese_medicine',
                ]),
        dict(name='cmmlu-china-specific',
            subsets=[
                'cmmlu-ancient_chinese',
                'cmmlu-chinese_civil_service_exam',
                'cmmlu-chinese_driving_rule',
                'cmmlu-chinese_food_culture',
                'cmmlu-chinese_foreign_policy',
                'cmmlu-chinese_history',
                'cmmlu-chinese_literature',
                'cmmlu-chinese_teacher_qualification',
                'cmmlu-construction_project_management',
                'cmmlu-elementary_chinese',
                'cmmlu-elementary_commonsense',
                'cmmlu-ethnology',
                'cmmlu-high_school_politics',
                'cmmlu-modern_chinese',
                'cmmlu-traditional_chinese_medicine',
                ]),
        dict(name='cmmlu',
            subsets=[
                'cmmlu-agronomy',
                'cmmlu-anatomy',
                'cmmlu-ancient_chinese',
                'cmmlu-arts',
                'cmmlu-astronomy',
                'cmmlu-business_ethics',
                'cmmlu-chinese_civil_service_exam',
                'cmmlu-chinese_driving_rule',
                'cmmlu-chinese_food_culture',
                'cmmlu-chinese_foreign_policy',
                'cmmlu-chinese_history',
                'cmmlu-chinese_literature',
                'cmmlu-chinese_teacher_qualification',
                'cmmlu-college_actuarial_science',
                'cmmlu-college_education',
                'cmmlu-college_engineering_hydrology',
                'cmmlu-college_law',
                'cmmlu-college_mathematics',
                'cmmlu-college_medical_statistics',
                'cmmlu-clinical_knowledge',
                'cmmlu-college_medicine',
                'cmmlu-computer_science',
                'cmmlu-computer_security',
                'cmmlu-conceptual_physics',
                'cmmlu-construction_project_management',
                'cmmlu-economics',
                'cmmlu-education',
                'cmmlu-elementary_chinese',
                'cmmlu-elementary_commonsense',
                'cmmlu-elementary_information_and_technology',
                'cmmlu-electrical_engineering',
                'cmmlu-elementary_mathematics',
                'cmmlu-ethnology',
                'cmmlu-food_science',
                'cmmlu-genetics',
                'cmmlu-global_facts',
                'cmmlu-high_school_biology',
                'cmmlu-high_school_chemistry',
                'cmmlu-high_school_geography',
                'cmmlu-high_school_mathematics',
                'cmmlu-high_school_physics',
                'cmmlu-high_school_politics',
                'cmmlu-human_sexuality',
                'cmmlu-international_law',
                'cmmlu-journalism',
                'cmmlu-jurisprudence',
                'cmmlu-legal_and_moral_basis',
                'cmmlu-logical',
                'cmmlu-machine_learning',
                'cmmlu-management',
                'cmmlu-marketing',
                'cmmlu-marxist_theory',
                'cmmlu-modern_chinese',
                'cmmlu-nutrition',
                'cmmlu-philosophy',
                'cmmlu-professional_accounting',
                'cmmlu-professional_law',
                'cmmlu-professional_medicine',
                'cmmlu-professional_psychology',
                'cmmlu-public_relations',
                'cmmlu-security_study',
                'cmmlu-sociology',
                'cmmlu-sports_science',
                'cmmlu-traditional_chinese_medicine',
                'cmmlu-virology',
                'cmmlu-world_history',
                'cmmlu-world_religions',
                ]),
        dict(name='ceval-stem',
            subsets=[
                'ceval-computer_network',
                'ceval-operating_system',
                'ceval-computer_architecture',
                'ceval-college_programming',
                'ceval-college_physics',
                'ceval-college_chemistry',
                'ceval-advanced_mathematics',
                'ceval-probability_and_statistics',
                'ceval-discrete_mathematics',
                'ceval-electrical_engineer',
                'ceval-metrology_engineer',
                'ceval-high_school_mathematics',
                'ceval-high_school_physics',
                'ceval-high_school_chemistry',
                'ceval-high_school_biology',
                'ceval-middle_school_mathematics',
                'ceval-middle_school_biology',
                'ceval-middle_school_physics',
                'ceval-middle_school_chemistry',
                'ceval-veterinary_medicine',
                ]),
        dict(name='ceval-social-science',
            subsets=[
                'ceval-college_economics',
                'ceval-business_administration',
                'ceval-marxism',
                'ceval-mao_zedong_thought',
                'ceval-education_science',
                'ceval-teacher_qualification',
                'ceval-high_school_politics',
                'ceval-high_school_geography',
                'ceval-middle_school_politics',
                'ceval-middle_school_geography',
                ]),
        dict(name='ceval-humanities',
            subsets=[
                'ceval-modern_chinese_history',
                'ceval-ideological_and_moral_cultivation',
                'ceval-logic',
                'ceval-law',
                'ceval-chinese_language_and_literature',
                'ceval-art_studies',
                'ceval-professional_tour_guide',
                'ceval-legal_professional',
                'ceval-high_school_chinese',
                'ceval-high_school_history',
                'ceval-middle_school_history',
                ]),
        dict(name='ceval-other',
            subsets=[
                'ceval-civil_servant',
                'ceval-sports_science',
                'ceval-plant_protection',
                'ceval-basic_medicine',
                'ceval-clinical_medicine',
                'ceval-urban_and_rural_planner',
                'ceval-accountant',
                'ceval-fire_engineer',
                'ceval-environmental_impact_assessment_engineer',
                'ceval-tax_accountant',
                'ceval-physician',
                ]),
        dict(name='ceval-hard',
            subsets=[
                'ceval-advanced_mathematics',
                'ceval-discrete_mathematics',
                'ceval-probability_and_statistics',
                'ceval-college_chemistry',
                'ceval-college_physics',
                'ceval-high_school_mathematics',
                'ceval-high_school_chemistry',
                'ceval-high_school_physics',
                ]),
        dict(name='ceval',
            subsets=[
                'ceval-computer_network',
                'ceval-operating_system',
                'ceval-computer_architecture',
                'ceval-college_programming',
                'ceval-college_physics',
                'ceval-college_chemistry',
                'ceval-advanced_mathematics',
                'ceval-probability_and_statistics',
                'ceval-discrete_mathematics',
                'ceval-electrical_engineer',
                'ceval-metrology_engineer',
                'ceval-high_school_mathematics',
                'ceval-high_school_physics',
                'ceval-high_school_chemistry',
                'ceval-high_school_biology',
                'ceval-middle_school_mathematics',
                'ceval-middle_school_biology',
                'ceval-middle_school_physics',
                'ceval-middle_school_chemistry',
                'ceval-veterinary_medicine',
                'ceval-college_economics',
                'ceval-business_administration',
                'ceval-marxism',
                'ceval-mao_zedong_thought',
                'ceval-education_science',
                'ceval-teacher_qualification',
                'ceval-high_school_politics',
                'ceval-high_school_geography',
                'ceval-middle_school_politics',
                'ceval-middle_school_geography',
                'ceval-modern_chinese_history',
                'ceval-ideological_and_moral_cultivation',
                'ceval-logic',
                'ceval-law',
                'ceval-chinese_language_and_literature',
                'ceval-art_studies',
                'ceval-professional_tour_guide',
                'ceval-legal_professional',
                'ceval-high_school_chinese',
                'ceval-high_school_history',
                'ceval-middle_school_history',
                'ceval-civil_servant',
                'ceval-sports_science',
                'ceval-plant_protection',
                'ceval-basic_medicine',
                'ceval-clinical_medicine',
                'ceval-urban_and_rural_planner',
                'ceval-accountant',
                'ceval-fire_engineer',
                'ceval-environmental_impact_assessment_engineer',
                'ceval-tax_accountant',
                'ceval-physician',
                ]),
        dict(name='ceval-test-stem',
            subsets=[
                'ceval-test-computer_network',
                'ceval-test-operating_system',
                'ceval-test-computer_architecture',
                'ceval-test-college_programming',
                'ceval-test-college_physics',
                'ceval-test-college_chemistry',
                'ceval-test-advanced_mathematics',
                'ceval-test-probability_and_statistics',
                'ceval-test-discrete_mathematics',
                'ceval-test-electrical_engineer',
                'ceval-test-metrology_engineer',
                'ceval-test-high_school_mathematics',
                'ceval-test-high_school_physics',
                'ceval-test-high_school_chemistry',
                'ceval-test-high_school_biology',
                'ceval-test-middle_school_mathematics',
                'ceval-test-middle_school_biology',
                'ceval-test-middle_school_physics',
                'ceval-test-middle_school_chemistry',
                'ceval-test-veterinary_medicine',
                ]),
        dict(name='ceval-test-social-science',
            subsets=[
                'ceval-test-college_economics',
                'ceval-test-business_administration',
                'ceval-test-marxism',
                'ceval-test-mao_zedong_thought',
                'ceval-test-education_science',
                'ceval-test-teacher_qualification',
                'ceval-test-high_school_politics',
                'ceval-test-high_school_geography',
                'ceval-test-middle_school_politics',
                'ceval-test-middle_school_geography',
                ]),
        dict(name='ceval-test-humanities',
            subsets=[
                'ceval-test-modern_chinese_history',
                'ceval-test-ideological_and_moral_cultivation',
                'ceval-test-logic',
                'ceval-test-law',
                'ceval-test-chinese_language_and_literature',
                'ceval-test-art_studies',
                'ceval-test-professional_tour_guide',
                'ceval-test-legal_professional',
                'ceval-test-high_school_chinese',
                'ceval-test-high_school_history',
                'ceval-test-middle_school_history',
                ]),
        dict(name='ceval-test-other',
            subsets=[
                'ceval-test-civil_servant',
                'ceval-test-sports_science',
                'ceval-test-plant_protection',
                'ceval-test-basic_medicine',
                'ceval-test-clinical_medicine',
                'ceval-test-urban_and_rural_planner',
                'ceval-test-accountant',
                'ceval-test-fire_engineer',
                'ceval-test-environmental_impact_assessment_engineer',
                'ceval-test-tax_accountant',
                'ceval-test-physician',
                ]),
        dict(name='ceval-test-hard',
            subsets=[
                'ceval-test-advanced_mathematics',
                'ceval-test-discrete_mathematics',
                'ceval-test-probability_and_statistics',
                'ceval-test-college_chemistry',
                'ceval-test-college_physics',
                'ceval-test-high_school_mathematics',
                'ceval-test-high_school_chemistry',
                'ceval-test-high_school_physics',
                ]),
        dict(name='ceval-test',
            subsets=[
                'ceval-test-computer_network',
                'ceval-test-operating_system',
                'ceval-test-computer_architecture',
                'ceval-test-college_programming',
                'ceval-test-college_physics',
                'ceval-test-college_chemistry',
                'ceval-test-advanced_mathematics',
                'ceval-test-probability_and_statistics',
                'ceval-test-discrete_mathematics',
                'ceval-test-electrical_engineer',
                'ceval-test-metrology_engineer',
                'ceval-test-high_school_mathematics',
                'ceval-test-high_school_physics',
                'ceval-test-high_school_chemistry',
                'ceval-test-high_school_biology',
                'ceval-test-middle_school_mathematics',
                'ceval-test-middle_school_biology',
                'ceval-test-middle_school_physics',
                'ceval-test-middle_school_chemistry',
                'ceval-test-veterinary_medicine',
                'ceval-test-college_economics',
                'ceval-test-business_administration',
                'ceval-test-marxism',
                'ceval-test-mao_zedong_thought',
                'ceval-test-education_science',
                'ceval-test-teacher_qualification',
                'ceval-test-high_school_politics',
                'ceval-test-high_school_geography',
                'ceval-test-middle_school_politics',
                'ceval-test-middle_school_geography',
                'ceval-test-modern_chinese_history',
                'ceval-test-ideological_and_moral_cultivation',
                'ceval-test-logic',
                'ceval-test-law',
                'ceval-test-chinese_language_and_literature',
                'ceval-test-art_studies',
                'ceval-test-professional_tour_guide',
                'ceval-test-legal_professional',
                'ceval-test-high_school_chinese',
                'ceval-test-high_school_history',
                'ceval-test-middle_school_history',
                'ceval-test-civil_servant',
                'ceval-test-sports_science',
                'ceval-test-plant_protection',
                'ceval-test-basic_medicine',
                'ceval-test-clinical_medicine',
                'ceval-test-urban_and_rural_planner',
                'ceval-test-accountant',
                'ceval-test-fire_engineer',
                'ceval-test-environmental_impact_assessment_engineer',
                'ceval-test-tax_accountant',
                'ceval-test-physician',
                ]),
        ])
summary_groups=[
    dict(name='mmlu-humanities',
        subsets=[
            'lukaemon_mmlu_formal_logic',
            'lukaemon_mmlu_high_school_european_history',
            'lukaemon_mmlu_high_school_us_history',
            'lukaemon_mmlu_high_school_world_history',
            'lukaemon_mmlu_international_law',
            'lukaemon_mmlu_jurisprudence',
            'lukaemon_mmlu_logical_fallacies',
            'lukaemon_mmlu_moral_disputes',
            'lukaemon_mmlu_moral_scenarios',
            'lukaemon_mmlu_philosophy',
            'lukaemon_mmlu_prehistory',
            'lukaemon_mmlu_professional_law',
            'lukaemon_mmlu_world_religions',
            ]),
    dict(name='mmlu-stem',
        subsets=[
            'lukaemon_mmlu_abstract_algebra',
            'lukaemon_mmlu_anatomy',
            'lukaemon_mmlu_astronomy',
            'lukaemon_mmlu_college_biology',
            'lukaemon_mmlu_college_chemistry',
            'lukaemon_mmlu_college_computer_science',
            'lukaemon_mmlu_college_mathematics',
            'lukaemon_mmlu_college_physics',
            'lukaemon_mmlu_computer_security',
            'lukaemon_mmlu_conceptual_physics',
            'lukaemon_mmlu_electrical_engineering',
            'lukaemon_mmlu_elementary_mathematics',
            'lukaemon_mmlu_high_school_biology',
            'lukaemon_mmlu_high_school_chemistry',
            'lukaemon_mmlu_high_school_computer_science',
            'lukaemon_mmlu_high_school_mathematics',
            'lukaemon_mmlu_high_school_physics',
            'lukaemon_mmlu_high_school_statistics',
            'lukaemon_mmlu_machine_learning',
            ]),
    dict(name='mmlu-social-science',
        subsets=[
            'lukaemon_mmlu_econometrics',
            'lukaemon_mmlu_high_school_geography',
            'lukaemon_mmlu_high_school_government_and_politics',
            'lukaemon_mmlu_high_school_macroeconomics',
            'lukaemon_mmlu_high_school_microeconomics',
            'lukaemon_mmlu_high_school_psychology',
            'lukaemon_mmlu_human_sexuality',
            'lukaemon_mmlu_professional_psychology',
            'lukaemon_mmlu_public_relations',
            'lukaemon_mmlu_security_studies',
            'lukaemon_mmlu_sociology',
            'lukaemon_mmlu_us_foreign_policy',
            ]),
    dict(name='mmlu-other',
        subsets=[
            'lukaemon_mmlu_business_ethics',
            'lukaemon_mmlu_clinical_knowledge',
            'lukaemon_mmlu_college_medicine',
            'lukaemon_mmlu_global_facts',
            'lukaemon_mmlu_human_aging',
            'lukaemon_mmlu_management',
            'lukaemon_mmlu_marketing',
            'lukaemon_mmlu_medical_genetics',
            'lukaemon_mmlu_miscellaneous',
            'lukaemon_mmlu_nutrition',
            'lukaemon_mmlu_professional_accounting',
            'lukaemon_mmlu_professional_medicine',
            'lukaemon_mmlu_virology',
            ]),
    dict(name='mmlu',
        subsets=[
            'lukaemon_mmlu_formal_logic',
            'lukaemon_mmlu_high_school_european_history',
            'lukaemon_mmlu_high_school_us_history',
            'lukaemon_mmlu_high_school_world_history',
            'lukaemon_mmlu_international_law',
            'lukaemon_mmlu_jurisprudence',
            'lukaemon_mmlu_logical_fallacies',
            'lukaemon_mmlu_moral_disputes',
            'lukaemon_mmlu_moral_scenarios',
            'lukaemon_mmlu_philosophy',
            'lukaemon_mmlu_prehistory',
            'lukaemon_mmlu_professional_law',
            'lukaemon_mmlu_world_religions',
            'lukaemon_mmlu_abstract_algebra',
            'lukaemon_mmlu_anatomy',
            'lukaemon_mmlu_astronomy',
            'lukaemon_mmlu_college_biology',
            'lukaemon_mmlu_college_chemistry',
            'lukaemon_mmlu_college_computer_science',
            'lukaemon_mmlu_college_mathematics',
            'lukaemon_mmlu_college_physics',
            'lukaemon_mmlu_computer_security',
            'lukaemon_mmlu_conceptual_physics',
            'lukaemon_mmlu_electrical_engineering',
            'lukaemon_mmlu_elementary_mathematics',
            'lukaemon_mmlu_high_school_biology',
            'lukaemon_mmlu_high_school_chemistry',
            'lukaemon_mmlu_high_school_computer_science',
            'lukaemon_mmlu_high_school_mathematics',
            'lukaemon_mmlu_high_school_physics',
            'lukaemon_mmlu_high_school_statistics',
            'lukaemon_mmlu_machine_learning',
            'lukaemon_mmlu_econometrics',
            'lukaemon_mmlu_high_school_geography',
            'lukaemon_mmlu_high_school_government_and_politics',
            'lukaemon_mmlu_high_school_macroeconomics',
            'lukaemon_mmlu_high_school_microeconomics',
            'lukaemon_mmlu_high_school_psychology',
            'lukaemon_mmlu_human_sexuality',
            'lukaemon_mmlu_professional_psychology',
            'lukaemon_mmlu_public_relations',
            'lukaemon_mmlu_security_studies',
            'lukaemon_mmlu_sociology',
            'lukaemon_mmlu_us_foreign_policy',
            'lukaemon_mmlu_business_ethics',
            'lukaemon_mmlu_clinical_knowledge',
            'lukaemon_mmlu_college_medicine',
            'lukaemon_mmlu_global_facts',
            'lukaemon_mmlu_human_aging',
            'lukaemon_mmlu_management',
            'lukaemon_mmlu_marketing',
            'lukaemon_mmlu_medical_genetics',
            'lukaemon_mmlu_miscellaneous',
            'lukaemon_mmlu_nutrition',
            'lukaemon_mmlu_professional_accounting',
            'lukaemon_mmlu_professional_medicine',
            'lukaemon_mmlu_virology',
            ]),
    dict(name='mmlu-weighted',
        subsets=[
            'lukaemon_mmlu_formal_logic',
            'lukaemon_mmlu_high_school_european_history',
            'lukaemon_mmlu_high_school_us_history',
            'lukaemon_mmlu_high_school_world_history',
            'lukaemon_mmlu_international_law',
            'lukaemon_mmlu_jurisprudence',
            'lukaemon_mmlu_logical_fallacies',
            'lukaemon_mmlu_moral_disputes',
            'lukaemon_mmlu_moral_scenarios',
            'lukaemon_mmlu_philosophy',
            'lukaemon_mmlu_prehistory',
            'lukaemon_mmlu_professional_law',
            'lukaemon_mmlu_world_religions',
            'lukaemon_mmlu_abstract_algebra',
            'lukaemon_mmlu_anatomy',
            'lukaemon_mmlu_astronomy',
            'lukaemon_mmlu_college_biology',
            'lukaemon_mmlu_college_chemistry',
            'lukaemon_mmlu_college_computer_science',
            'lukaemon_mmlu_college_mathematics',
            'lukaemon_mmlu_college_physics',
            'lukaemon_mmlu_computer_security',
            'lukaemon_mmlu_conceptual_physics',
            'lukaemon_mmlu_electrical_engineering',
            'lukaemon_mmlu_elementary_mathematics',
            'lukaemon_mmlu_high_school_biology',
            'lukaemon_mmlu_high_school_chemistry',
            'lukaemon_mmlu_high_school_computer_science',
            'lukaemon_mmlu_high_school_mathematics',
            'lukaemon_mmlu_high_school_physics',
            'lukaemon_mmlu_high_school_statistics',
            'lukaemon_mmlu_machine_learning',
            'lukaemon_mmlu_econometrics',
            'lukaemon_mmlu_high_school_geography',
            'lukaemon_mmlu_high_school_government_and_politics',
            'lukaemon_mmlu_high_school_macroeconomics',
            'lukaemon_mmlu_high_school_microeconomics',
            'lukaemon_mmlu_high_school_psychology',
            'lukaemon_mmlu_human_sexuality',
            'lukaemon_mmlu_professional_psychology',
            'lukaemon_mmlu_public_relations',
            'lukaemon_mmlu_security_studies',
            'lukaemon_mmlu_sociology',
            'lukaemon_mmlu_us_foreign_policy',
            'lukaemon_mmlu_business_ethics',
            'lukaemon_mmlu_clinical_knowledge',
            'lukaemon_mmlu_college_medicine',
            'lukaemon_mmlu_global_facts',
            'lukaemon_mmlu_human_aging',
            'lukaemon_mmlu_management',
            'lukaemon_mmlu_marketing',
            'lukaemon_mmlu_medical_genetics',
            'lukaemon_mmlu_miscellaneous',
            'lukaemon_mmlu_nutrition',
            'lukaemon_mmlu_professional_accounting',
            'lukaemon_mmlu_professional_medicine',
            'lukaemon_mmlu_virology',
            ],
        weights=dict(
            lukaemon_mmlu_abstract_algebra=100,
            lukaemon_mmlu_anatomy=135,
            lukaemon_mmlu_astronomy=152,
            lukaemon_mmlu_business_ethics=100,
            lukaemon_mmlu_clinical_knowledge=265,
            lukaemon_mmlu_college_biology=144,
            lukaemon_mmlu_college_chemistry=100,
            lukaemon_mmlu_college_computer_science=100,
            lukaemon_mmlu_college_mathematics=100,
            lukaemon_mmlu_college_medicine=173,
            lukaemon_mmlu_college_physics=102,
            lukaemon_mmlu_computer_security=100,
            lukaemon_mmlu_conceptual_physics=235,
            lukaemon_mmlu_econometrics=114,
            lukaemon_mmlu_electrical_engineering=145,
            lukaemon_mmlu_elementary_mathematics=378,
            lukaemon_mmlu_formal_logic=126,
            lukaemon_mmlu_global_facts=100,
            lukaemon_mmlu_high_school_biology=310,
            lukaemon_mmlu_high_school_chemistry=203,
            lukaemon_mmlu_high_school_computer_science=100,
            lukaemon_mmlu_high_school_european_history=165,
            lukaemon_mmlu_high_school_geography=198,
            lukaemon_mmlu_high_school_government_and_politics=193,
            lukaemon_mmlu_high_school_macroeconomics=390,
            lukaemon_mmlu_high_school_mathematics=270,
            lukaemon_mmlu_high_school_microeconomics=238,
            lukaemon_mmlu_high_school_physics=151,
            lukaemon_mmlu_high_school_psychology=545,
            lukaemon_mmlu_high_school_statistics=216,
            lukaemon_mmlu_high_school_us_history=204,
            lukaemon_mmlu_high_school_world_history=237,
            lukaemon_mmlu_human_aging=223,
            lukaemon_mmlu_human_sexuality=131,
            lukaemon_mmlu_international_law=121,
            lukaemon_mmlu_jurisprudence=108,
            lukaemon_mmlu_logical_fallacies=163,
            lukaemon_mmlu_machine_learning=112,
            lukaemon_mmlu_management=103,
            lukaemon_mmlu_marketing=234,
            lukaemon_mmlu_medical_genetics=100,
            lukaemon_mmlu_miscellaneous=783,
            lukaemon_mmlu_moral_disputes=346,
            lukaemon_mmlu_moral_scenarios=895,
            lukaemon_mmlu_nutrition=306,
            lukaemon_mmlu_philosophy=311,
            lukaemon_mmlu_prehistory=324,
            lukaemon_mmlu_professional_accounting=282,
            lukaemon_mmlu_professional_law=1534,
            lukaemon_mmlu_professional_medicine=272,
            lukaemon_mmlu_professional_psychology=612,
            lukaemon_mmlu_public_relations=110,
            lukaemon_mmlu_security_studies=245,
            lukaemon_mmlu_sociology=201,
            lukaemon_mmlu_us_foreign_policy=100,
            lukaemon_mmlu_virology=166,
            lukaemon_mmlu_world_religions=171)),
    dict(name='cmmlu-humanities',
        subsets=[
            'cmmlu-arts',
            'cmmlu-chinese_history',
            'cmmlu-chinese_literature',
            'cmmlu-college_law',
            'cmmlu-global_facts',
            'cmmlu-international_law',
            'cmmlu-jurisprudence',
            'cmmlu-logical',
            'cmmlu-marxist_theory',
            'cmmlu-philosophy',
            'cmmlu-professional_law',
            'cmmlu-world_history',
            'cmmlu-world_religions',
            ]),
    dict(name='cmmlu-stem',
        subsets=[
            'cmmlu-anatomy',
            'cmmlu-astronomy',
            'cmmlu-college_actuarial_science',
            'cmmlu-college_engineering_hydrology',
            'cmmlu-college_mathematics',
            'cmmlu-college_medical_statistics',
            'cmmlu-computer_science',
            'cmmlu-conceptual_physics',
            'cmmlu-electrical_engineering',
            'cmmlu-elementary_mathematics',
            'cmmlu-genetics',
            'cmmlu-high_school_biology',
            'cmmlu-high_school_chemistry',
            'cmmlu-high_school_mathematics',
            'cmmlu-high_school_physics',
            'cmmlu-machine_learning',
            'cmmlu-virology',
            ]),
    dict(name='cmmlu-social-science',
        subsets=[
            'cmmlu-ancient_chinese',
            'cmmlu-business_ethics',
            'cmmlu-chinese_civil_service_exam',
            'cmmlu-chinese_food_culture',
            'cmmlu-chinese_foreign_policy',
            'cmmlu-chinese_teacher_qualification',
            'cmmlu-college_education',
            'cmmlu-economics',
            'cmmlu-education',
            'cmmlu-elementary_chinese',
            'cmmlu-ethnology',
            'cmmlu-high_school_geography',
            'cmmlu-high_school_politics',
            'cmmlu-journalism',
            'cmmlu-management',
            'cmmlu-marketing',
            'cmmlu-modern_chinese',
            'cmmlu-professional_accounting',
            'cmmlu-professional_psychology',
            'cmmlu-public_relations',
            'cmmlu-security_study',
            'cmmlu-sociology',
            ]),
    dict(name='cmmlu-other',
        subsets=[
            'cmmlu-agronomy',
            'cmmlu-chinese_driving_rule',
            'cmmlu-clinical_knowledge',
            'cmmlu-college_medicine',
            'cmmlu-computer_security',
            'cmmlu-construction_project_management',
            'cmmlu-elementary_commonsense',
            'cmmlu-elementary_information_and_technology',
            'cmmlu-food_science',
            'cmmlu-human_sexuality',
            'cmmlu-legal_and_moral_basis',
            'cmmlu-nutrition',
            'cmmlu-professional_medicine',
            'cmmlu-sports_science',
            'cmmlu-traditional_chinese_medicine',
            ]),
    dict(name='cmmlu-china-specific',
        subsets=[
            'cmmlu-ancient_chinese',
            'cmmlu-chinese_civil_service_exam',
            'cmmlu-chinese_driving_rule',
            'cmmlu-chinese_food_culture',
            'cmmlu-chinese_foreign_policy',
            'cmmlu-chinese_history',
            'cmmlu-chinese_literature',
            'cmmlu-chinese_teacher_qualification',
            'cmmlu-construction_project_management',
            'cmmlu-elementary_chinese',
            'cmmlu-elementary_commonsense',
            'cmmlu-ethnology',
            'cmmlu-high_school_politics',
            'cmmlu-modern_chinese',
            'cmmlu-traditional_chinese_medicine',
            ]),
    dict(name='cmmlu',
        subsets=[
            'cmmlu-agronomy',
            'cmmlu-anatomy',
            'cmmlu-ancient_chinese',
            'cmmlu-arts',
            'cmmlu-astronomy',
            'cmmlu-business_ethics',
            'cmmlu-chinese_civil_service_exam',
            'cmmlu-chinese_driving_rule',
            'cmmlu-chinese_food_culture',
            'cmmlu-chinese_foreign_policy',
            'cmmlu-chinese_history',
            'cmmlu-chinese_literature',
            'cmmlu-chinese_teacher_qualification',
            'cmmlu-college_actuarial_science',
            'cmmlu-college_education',
            'cmmlu-college_engineering_hydrology',
            'cmmlu-college_law',
            'cmmlu-college_mathematics',
            'cmmlu-college_medical_statistics',
            'cmmlu-clinical_knowledge',
            'cmmlu-college_medicine',
            'cmmlu-computer_science',
            'cmmlu-computer_security',
            'cmmlu-conceptual_physics',
            'cmmlu-construction_project_management',
            'cmmlu-economics',
            'cmmlu-education',
            'cmmlu-elementary_chinese',
            'cmmlu-elementary_commonsense',
            'cmmlu-elementary_information_and_technology',
            'cmmlu-electrical_engineering',
            'cmmlu-elementary_mathematics',
            'cmmlu-ethnology',
            'cmmlu-food_science',
            'cmmlu-genetics',
            'cmmlu-global_facts',
            'cmmlu-high_school_biology',
            'cmmlu-high_school_chemistry',
            'cmmlu-high_school_geography',
            'cmmlu-high_school_mathematics',
            'cmmlu-high_school_physics',
            'cmmlu-high_school_politics',
            'cmmlu-human_sexuality',
            'cmmlu-international_law',
            'cmmlu-journalism',
            'cmmlu-jurisprudence',
            'cmmlu-legal_and_moral_basis',
            'cmmlu-logical',
            'cmmlu-machine_learning',
            'cmmlu-management',
            'cmmlu-marketing',
            'cmmlu-marxist_theory',
            'cmmlu-modern_chinese',
            'cmmlu-nutrition',
            'cmmlu-philosophy',
            'cmmlu-professional_accounting',
            'cmmlu-professional_law',
            'cmmlu-professional_medicine',
            'cmmlu-professional_psychology',
            'cmmlu-public_relations',
            'cmmlu-security_study',
            'cmmlu-sociology',
            'cmmlu-sports_science',
            'cmmlu-traditional_chinese_medicine',
            'cmmlu-virology',
            'cmmlu-world_history',
            'cmmlu-world_religions',
            ]),
    dict(name='ceval-stem',
        subsets=[
            'ceval-computer_network',
            'ceval-operating_system',
            'ceval-computer_architecture',
            'ceval-college_programming',
            'ceval-college_physics',
            'ceval-college_chemistry',
            'ceval-advanced_mathematics',
            'ceval-probability_and_statistics',
            'ceval-discrete_mathematics',
            'ceval-electrical_engineer',
            'ceval-metrology_engineer',
            'ceval-high_school_mathematics',
            'ceval-high_school_physics',
            'ceval-high_school_chemistry',
            'ceval-high_school_biology',
            'ceval-middle_school_mathematics',
            'ceval-middle_school_biology',
            'ceval-middle_school_physics',
            'ceval-middle_school_chemistry',
            'ceval-veterinary_medicine',
            ]),
    dict(name='ceval-social-science',
        subsets=[
            'ceval-college_economics',
            'ceval-business_administration',
            'ceval-marxism',
            'ceval-mao_zedong_thought',
            'ceval-education_science',
            'ceval-teacher_qualification',
            'ceval-high_school_politics',
            'ceval-high_school_geography',
            'ceval-middle_school_politics',
            'ceval-middle_school_geography',
            ]),
    dict(name='ceval-humanities',
        subsets=[
            'ceval-modern_chinese_history',
            'ceval-ideological_and_moral_cultivation',
            'ceval-logic',
            'ceval-law',
            'ceval-chinese_language_and_literature',
            'ceval-art_studies',
            'ceval-professional_tour_guide',
            'ceval-legal_professional',
            'ceval-high_school_chinese',
            'ceval-high_school_history',
            'ceval-middle_school_history',
            ]),
    dict(name='ceval-other',
        subsets=[
            'ceval-civil_servant',
            'ceval-sports_science',
            'ceval-plant_protection',
            'ceval-basic_medicine',
            'ceval-clinical_medicine',
            'ceval-urban_and_rural_planner',
            'ceval-accountant',
            'ceval-fire_engineer',
            'ceval-environmental_impact_assessment_engineer',
            'ceval-tax_accountant',
            'ceval-physician',
            ]),
    dict(name='ceval-hard',
        subsets=[
            'ceval-advanced_mathematics',
            'ceval-discrete_mathematics',
            'ceval-probability_and_statistics',
            'ceval-college_chemistry',
            'ceval-college_physics',
            'ceval-high_school_mathematics',
            'ceval-high_school_chemistry',
            'ceval-high_school_physics',
            ]),
    dict(name='ceval',
        subsets=[
            'ceval-computer_network',
            'ceval-operating_system',
            'ceval-computer_architecture',
            'ceval-college_programming',
            'ceval-college_physics',
            'ceval-college_chemistry',
            'ceval-advanced_mathematics',
            'ceval-probability_and_statistics',
            'ceval-discrete_mathematics',
            'ceval-electrical_engineer',
            'ceval-metrology_engineer',
            'ceval-high_school_mathematics',
            'ceval-high_school_physics',
            'ceval-high_school_chemistry',
            'ceval-high_school_biology',
            'ceval-middle_school_mathematics',
            'ceval-middle_school_biology',
            'ceval-middle_school_physics',
            'ceval-middle_school_chemistry',
            'ceval-veterinary_medicine',
            'ceval-college_economics',
            'ceval-business_administration',
            'ceval-marxism',
            'ceval-mao_zedong_thought',
            'ceval-education_science',
            'ceval-teacher_qualification',
            'ceval-high_school_politics',
            'ceval-high_school_geography',
            'ceval-middle_school_politics',
            'ceval-middle_school_geography',
            'ceval-modern_chinese_history',
            'ceval-ideological_and_moral_cultivation',
            'ceval-logic',
            'ceval-law',
            'ceval-chinese_language_and_literature',
            'ceval-art_studies',
            'ceval-professional_tour_guide',
            'ceval-legal_professional',
            'ceval-high_school_chinese',
            'ceval-high_school_history',
            'ceval-middle_school_history',
            'ceval-civil_servant',
            'ceval-sports_science',
            'ceval-plant_protection',
            'ceval-basic_medicine',
            'ceval-clinical_medicine',
            'ceval-urban_and_rural_planner',
            'ceval-accountant',
            'ceval-fire_engineer',
            'ceval-environmental_impact_assessment_engineer',
            'ceval-tax_accountant',
            'ceval-physician',
            ]),
    dict(name='ceval-test-stem',
        subsets=[
            'ceval-test-computer_network',
            'ceval-test-operating_system',
            'ceval-test-computer_architecture',
            'ceval-test-college_programming',
            'ceval-test-college_physics',
            'ceval-test-college_chemistry',
            'ceval-test-advanced_mathematics',
            'ceval-test-probability_and_statistics',
            'ceval-test-discrete_mathematics',
            'ceval-test-electrical_engineer',
            'ceval-test-metrology_engineer',
            'ceval-test-high_school_mathematics',
            'ceval-test-high_school_physics',
            'ceval-test-high_school_chemistry',
            'ceval-test-high_school_biology',
            'ceval-test-middle_school_mathematics',
            'ceval-test-middle_school_biology',
            'ceval-test-middle_school_physics',
            'ceval-test-middle_school_chemistry',
            'ceval-test-veterinary_medicine',
            ]),
    dict(name='ceval-test-social-science',
        subsets=[
            'ceval-test-college_economics',
            'ceval-test-business_administration',
            'ceval-test-marxism',
            'ceval-test-mao_zedong_thought',
            'ceval-test-education_science',
            'ceval-test-teacher_qualification',
            'ceval-test-high_school_politics',
            'ceval-test-high_school_geography',
            'ceval-test-middle_school_politics',
            'ceval-test-middle_school_geography',
            ]),
    dict(name='ceval-test-humanities',
        subsets=[
            'ceval-test-modern_chinese_history',
            'ceval-test-ideological_and_moral_cultivation',
            'ceval-test-logic',
            'ceval-test-law',
            'ceval-test-chinese_language_and_literature',
            'ceval-test-art_studies',
            'ceval-test-professional_tour_guide',
            'ceval-test-legal_professional',
            'ceval-test-high_school_chinese',
            'ceval-test-high_school_history',
            'ceval-test-middle_school_history',
            ]),
    dict(name='ceval-test-other',
        subsets=[
            'ceval-test-civil_servant',
            'ceval-test-sports_science',
            'ceval-test-plant_protection',
            'ceval-test-basic_medicine',
            'ceval-test-clinical_medicine',
            'ceval-test-urban_and_rural_planner',
            'ceval-test-accountant',
            'ceval-test-fire_engineer',
            'ceval-test-environmental_impact_assessment_engineer',
            'ceval-test-tax_accountant',
            'ceval-test-physician',
            ]),
    dict(name='ceval-test-hard',
        subsets=[
            'ceval-test-advanced_mathematics',
            'ceval-test-discrete_mathematics',
            'ceval-test-probability_and_statistics',
            'ceval-test-college_chemistry',
            'ceval-test-college_physics',
            'ceval-test-high_school_mathematics',
            'ceval-test-high_school_chemistry',
            'ceval-test-high_school_physics',
            ]),
    dict(name='ceval-test',
        subsets=[
            'ceval-test-computer_network',
            'ceval-test-operating_system',
            'ceval-test-computer_architecture',
            'ceval-test-college_programming',
            'ceval-test-college_physics',
            'ceval-test-college_chemistry',
            'ceval-test-advanced_mathematics',
            'ceval-test-probability_and_statistics',
            'ceval-test-discrete_mathematics',
            'ceval-test-electrical_engineer',
            'ceval-test-metrology_engineer',
            'ceval-test-high_school_mathematics',
            'ceval-test-high_school_physics',
            'ceval-test-high_school_chemistry',
            'ceval-test-high_school_biology',
            'ceval-test-middle_school_mathematics',
            'ceval-test-middle_school_biology',
            'ceval-test-middle_school_physics',
            'ceval-test-middle_school_chemistry',
            'ceval-test-veterinary_medicine',
            'ceval-test-college_economics',
            'ceval-test-business_administration',
            'ceval-test-marxism',
            'ceval-test-mao_zedong_thought',
            'ceval-test-education_science',
            'ceval-test-teacher_qualification',
            'ceval-test-high_school_politics',
            'ceval-test-high_school_geography',
            'ceval-test-middle_school_politics',
            'ceval-test-middle_school_geography',
            'ceval-test-modern_chinese_history',
            'ceval-test-ideological_and_moral_cultivation',
            'ceval-test-logic',
            'ceval-test-law',
            'ceval-test-chinese_language_and_literature',
            'ceval-test-art_studies',
            'ceval-test-professional_tour_guide',
            'ceval-test-legal_professional',
            'ceval-test-high_school_chinese',
            'ceval-test-high_school_history',
            'ceval-test-middle_school_history',
            'ceval-test-civil_servant',
            'ceval-test-sports_science',
            'ceval-test-plant_protection',
            'ceval-test-basic_medicine',
            'ceval-test-clinical_medicine',
            'ceval-test-urban_and_rural_planner',
            'ceval-test-accountant',
            'ceval-test-fire_engineer',
            'ceval-test-environmental_impact_assessment_engineer',
            'ceval-test-tax_accountant',
            'ceval-test-physician',
            ]),
    ]
triviaqa_datasets=[
    dict(abbr='triviaqa',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.datasets.TriviaQAEvaluator'),
            pred_role='BOT'),
        infer_cfg=dict(
            inferencer=dict(
                max_out_len=50,
                type='opencompass.openicl.icl_inferencer.GenInferencer'),
            prompt_template=dict(
                template=dict(
                    round=[
                        dict(prompt="Answer these questions, your answer should be as simple as possible, start your answer with the prompt 'The answer is '.\nQ: {question}?",
                            role='HUMAN'),
                        dict(prompt='A:',
                            role='BOT'),
                        ]),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                type='opencompass.openicl.icl_retriever.ZeroRetriever')),
        path='./data/triviaqa/',
        reader_cfg=dict(
            input_columns=[
                'question',
                ],
            output_column='answer',
            test_split='dev',
            train_split='test'),
        type='opencompass.datasets.TriviaQADataset'),
    dict(abbr='triviaqa_1shot',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.datasets.TriviaQAEvaluator'),
            pred_role='BOT'),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    round=[
                        dict(prompt="Answer the question, your answer should be as simple as possible, start your answer with the prompt 'The answer is '.\nQ: {question}?",
                            role='HUMAN'),
                        dict(prompt='A: The answer is {answer}.\n',
                            role='BOT'),
                        ]),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                max_out_len=50,
                type='opencompass.openicl.icl_inferencer.GenInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    begin='</E>',
                    round=[
                        dict(prompt="Answer the question, your answer should be as simple as possible, start your answer with the prompt 'The answer is '.\nQ: {question}?",
                            role='HUMAN'),
                        dict(prompt='A:',
                            role='BOT'),
                        ]),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        path='./data/triviaqa/',
        reader_cfg=dict(
            input_columns=[
                'question',
                ],
            output_column='answer',
            test_split='dev',
            train_split='test'),
        type='opencompass.datasets.TriviaQADataset'),
    dict(abbr='triviaqa_5shot',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.datasets.TriviaQAEvaluator'),
            pred_role='BOT'),
        infer_cfg=dict(
            ice_template=dict(
                template=dict(
                    round=[
                        dict(prompt="Answer the question, your answer should be as simple as possible, start your answer with the prompt 'The answer is '.\nQ: {question}?",
                            role='HUMAN'),
                        dict(prompt='A: The answer is {answer}.\n',
                            role='BOT'),
                        ]),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            inferencer=dict(
                max_out_len=50,
                type='opencompass.openicl.icl_inferencer.GenInferencer'),
            prompt_template=dict(
                ice_token='</E>',
                template=dict(
                    begin='</E>',
                    round=[
                        dict(prompt="Answer the question, your answer should be as simple as possible, start your answer with the prompt 'The answer is '.\nQ: {question}?",
                            role='HUMAN'),
                        dict(prompt='A:',
                            role='BOT'),
                        ]),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                fix_id_list=[
                    0,
                    1,
                    2,
                    3,
                    4,
                    ],
                type='opencompass.openicl.icl_retriever.FixKRetriever')),
        path='./data/triviaqa/',
        reader_cfg=dict(
            input_columns=[
                'question',
                ],
            output_column='answer',
            test_split='dev',
            train_split='test'),
        type='opencompass.datasets.TriviaQADataset'),
    ]
winogrande_datasets=[
    dict(abbr='winogrande',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator')),
        infer_cfg=dict(
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.PPLInferencer'),
            prompt_template=dict(
                template=dict(
                    {1: dict(
                        round=[
                            dict(prompt='Good sentence: {opt1}',
                                role='HUMAN'),
                            ]),
                    2: dict(
                        round=[
                            dict(prompt='Good sentence: {opt2}',
                                role='HUMAN'),
                            ])}),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                type='opencompass.openicl.icl_retriever.ZeroRetriever')),
        name='winogrande_xs',
        path='winogrande',
        reader_cfg=dict(
            input_columns=[
                'opt1',
                'opt2',
                ],
            output_column='answer',
            test_split='validation',
            train_split='validation'),
        type='opencompass.datasets.winograndeDataset'),
    ]
work_dir='./outputs/default/20231113_205556'