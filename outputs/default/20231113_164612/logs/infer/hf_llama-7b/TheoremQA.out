11/13 17:59:15 - OpenCompass - INFO - Task [hf_llama-7b/TheoremQA,hf_llama-7b/mbpp,hf_llama-7b/cmmlu-professional_law]
You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
11/13 17:59:16 - OpenCompass - WARNING - pad_token_id is not set for the tokenizer.
11/13 17:59:16 - OpenCompass - WARNING - Using eos_token_id </s> as pad_token_id.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.57s/it]
11/13 17:59:24 - OpenCompass - INFO - Start inferencing [hf_llama-7b/TheoremQA]
[2023-11-13 17:59:25,252] [opencompass.openicl.icl_inferencer.icl_gen_inferencer] [INFO] Starting inference process...
  0%|          | 0/50 [00:00<?, ?it/s]  2%|▏         | 1/50 [01:57<1:36:03, 117.63s/it]  4%|▍         | 2/50 [03:53<1:33:29, 116.87s/it]  6%|▌         | 3/50 [05:50<1:31:18, 116.56s/it]  8%|▊         | 4/50 [07:46<1:29:14, 116.40s/it] 10%|█         | 5/50 [09:42<1:27:18, 116.42s/it] 12%|█▏        | 6/50 [11:38<1:25:19, 116.35s/it] 14%|█▍        | 7/50 [13:32<1:22:46, 115.49s/it] 16%|█▌        | 8/50 [15:26<1:20:32, 115.06s/it] 18%|█▊        | 9/50 [17:20<1:18:23, 114.71s/it] 20%|██        | 10/50 [19:14<1:16:15, 114.40s/it] 22%|██▏       | 11/50 [21:08<1:14:15, 114.24s/it] 24%|██▍       | 12/50 [23:01<1:12:13, 114.05s/it] 26%|██▌       | 13/50 [24:55<1:10:16, 113.96s/it] 28%|██▊       | 14/50 [26:49<1:08:15, 113.76s/it] 30%|███       | 15/50 [28:42<1:06:18, 113.66s/it] 32%|███▏      | 16/50 [30:36<1:04:25, 113.69s/it] 34%|███▍      | 17/50 [32:29<1:02:29, 113.61s/it] 36%|███▌      | 18/50 [34:23<1:00:38, 113.70s/it] 38%|███▊      | 19/50 [36:16<58:38, 113.51s/it]   40%|████      | 20/50 [38:09<56:42, 113.41s/it] 42%|████▏     | 21/50 [40:03<54:51, 113.48s/it] 44%|████▍     | 22/50 [41:56<52:57, 113.47s/it] 46%|████▌     | 23/50 [43:50<51:02, 113.42s/it] 48%|████▊     | 24/50 [45:43<49:10, 113.46s/it] 50%|█████     | 25/50 [47:37<47:16, 113.44s/it] 52%|█████▏    | 26/50 [49:30<45:20, 113.36s/it] 54%|█████▍    | 27/50 [51:24<43:29, 113.46s/it] 56%|█████▌    | 28/50 [53:17<41:34, 113.40s/it] 58%|█████▊    | 29/50 [55:10<39:43, 113.50s/it] 60%|██████    | 30/50 [57:05<37:54, 113.70s/it] 62%|██████▏   | 31/50 [58:58<35:59, 113.64s/it] 64%|██████▍   | 32/50 [1:00:52<34:04, 113.56s/it] 66%|██████▌   | 33/50 [1:02:45<32:11, 113.64s/it] 68%|██████▊   | 34/50 [1:04:39<30:17, 113.61s/it] 70%|███████   | 35/50 [1:06:33<28:26, 113.75s/it] 72%|███████▏  | 36/50 [1:08:27<26:34, 113.87s/it] 74%|███████▍  | 37/50 [1:10:21<24:40, 113.87s/it] 76%|███████▌  | 38/50 [1:12:15<22:46, 113.88s/it] 78%|███████▊  | 39/50 [1:14:09<20:52, 113.89s/it] 80%|████████  | 40/50 [1:16:03<18:59, 113.99s/it] 82%|████████▏ | 41/50 [1:17:57<17:04, 113.87s/it] 84%|████████▍ | 42/50 [1:19:50<15:09, 113.75s/it] 86%|████████▌ | 43/50 [1:21:44<13:16, 113.78s/it] 88%|████████▊ | 44/50 [1:23:37<11:21, 113.60s/it] 90%|█████████ | 45/50 [1:25:31<09:28, 113.73s/it] 92%|█████████▏| 46/50 [1:27:25<07:34, 113.67s/it] 94%|█████████▍| 47/50 [1:29:19<05:41, 113.73s/it] 96%|█████████▌| 48/50 [1:31:12<03:47, 113.63s/it] 98%|█████████▊| 49/50 [1:33:06<01:53, 113.73s/it]100%|██████████| 50/50 [1:35:00<00:00, 113.70s/it]100%|██████████| 50/50 [1:35:00<00:00, 114.00s/it]
11/13 19:34:27 - OpenCompass - INFO - Start inferencing [hf_llama-7b/mbpp]
Token indices sequence length is longer than the specified maximum sequence length for this model (4427 > 2048). Running this sequence through the model will result in indexing errors
[2023-11-13 19:34:28,080] [opencompass.openicl.icl_inferencer.icl_gen_inferencer] [INFO] Starting inference process...
  0%|          | 0/32 [00:00<?, ?it/s]  3%|▎         | 1/32 [01:45<54:40, 105.84s/it]  6%|▋         | 2/32 [03:31<52:45, 105.53s/it]  9%|▉         | 3/32 [05:15<50:50, 105.19s/it] 12%|█▎        | 4/32 [07:00<49:01, 105.07s/it] 16%|█▌        | 5/32 [08:45<47:15, 105.01s/it] 19%|█▉        | 6/32 [10:30<45:30, 105.00s/it] 22%|██▏       | 7/32 [12:16<43:49, 105.18s/it] 25%|██▌       | 8/32 [14:01<42:02, 105.10s/it] 28%|██▊       | 9/32 [15:46<40:17, 105.12s/it] 31%|███▏      | 10/32 [17:31<38:30, 105.00s/it] 34%|███▍      | 11/32 [19:15<36:43, 104.92s/it] 38%|███▊      | 12/32 [21:00<34:57, 104.86s/it] 41%|████      | 13/32 [22:45<33:11, 104.80s/it] 44%|████▍     | 14/32 [24:29<31:26, 104.79s/it] 47%|████▋     | 15/32 [26:15<29:42, 104.86s/it] 50%|█████     | 16/32 [27:59<27:57, 104.87s/it] 53%|█████▎    | 17/32 [29:44<26:12, 104.82s/it] 56%|█████▋    | 18/32 [31:29<24:27, 104.79s/it] 59%|█████▉    | 19/32 [33:14<22:42, 104.82s/it] 62%|██████▎   | 20/32 [34:58<20:57, 104.81s/it] 66%|██████▌   | 21/32 [36:43<19:12, 104.77s/it] 69%|██████▉   | 22/32 [38:28<17:27, 104.74s/it] 72%|███████▏  | 23/32 [40:13<15:43, 104.78s/it] 75%|███████▌  | 24/32 [41:58<13:59, 104.97s/it] 78%|███████▊  | 25/32 [43:43<12:14, 104.90s/it] 81%|████████▏ | 26/32 [45:28<10:29, 104.86s/it] 84%|████████▍ | 27/32 [47:12<08:44, 104.84s/it] 88%|████████▊ | 28/32 [48:57<06:59, 104.87s/it] 91%|█████████ | 29/32 [50:43<05:15, 105.01s/it] 94%|█████████▍| 30/32 [52:28<03:29, 104.96s/it] 97%|█████████▋| 31/32 [54:13<01:45, 105.05s/it]100%|██████████| 32/32 [54:39<00:00, 81.39s/it] 100%|██████████| 32/32 [54:39<00:00, 102.48s/it]
11/13 20:29:07 - OpenCompass - INFO - Start inferencing [hf_llama-7b/cmmlu-professional_law]
  0%|          | 0/211 [00:00<?, ?it/s]100%|██████████| 211/211 [00:00<00:00, 4234440.88it/s]
[2023-11-13 20:29:08,010] [opencompass.openicl.icl_inferencer.icl_ppl_inferencer] [INFO] Calculating PPL for prompts labeled 'A'
  0%|          | 0/14 [00:00<?, ?it/s]  7%|▋         | 1/14 [00:00<00:11,  1.16it/s] 14%|█▍        | 2/14 [00:01<00:10,  1.17it/s] 21%|██▏       | 3/14 [00:02<00:09,  1.17it/s] 29%|██▊       | 4/14 [00:03<00:08,  1.18it/s] 36%|███▌      | 5/14 [00:04<00:07,  1.18it/s] 43%|████▎     | 6/14 [00:05<00:06,  1.19it/s] 50%|█████     | 7/14 [00:05<00:05,  1.18it/s] 57%|█████▋    | 8/14 [00:06<00:05,  1.19it/s] 64%|██████▍   | 9/14 [00:07<00:04,  1.18it/s] 71%|███████▏  | 10/14 [00:08<00:03,  1.18it/s] 79%|███████▊  | 11/14 [00:09<00:02,  1.15it/s] 86%|████████▌ | 12/14 [00:10<00:01,  1.14it/s] 93%|█████████▎| 13/14 [00:11<00:00,  1.15it/s]100%|██████████| 14/14 [00:11<00:00,  1.52it/s]100%|██████████| 14/14 [00:11<00:00,  1.24it/s]
[2023-11-13 20:29:19,591] [opencompass.openicl.icl_inferencer.icl_ppl_inferencer] [INFO] Calculating PPL for prompts labeled 'B'
  0%|          | 0/14 [00:00<?, ?it/s]  7%|▋         | 1/14 [00:00<00:11,  1.16it/s] 14%|█▍        | 2/14 [00:01<00:10,  1.17it/s] 21%|██▏       | 3/14 [00:02<00:09,  1.17it/s] 29%|██▊       | 4/14 [00:03<00:08,  1.18it/s] 36%|███▌      | 5/14 [00:04<00:07,  1.18it/s] 43%|████▎     | 6/14 [00:05<00:06,  1.19it/s] 50%|█████     | 7/14 [00:05<00:05,  1.18it/s] 57%|█████▋    | 8/14 [00:06<00:05,  1.18it/s] 64%|██████▍   | 9/14 [00:07<00:04,  1.18it/s] 71%|███████▏  | 10/14 [00:08<00:03,  1.18it/s] 79%|███████▊  | 11/14 [00:09<00:02,  1.15it/s] 86%|████████▌ | 12/14 [00:10<00:01,  1.14it/s] 93%|█████████▎| 13/14 [00:11<00:00,  1.15it/s]100%|██████████| 14/14 [00:11<00:00,  1.52it/s]100%|██████████| 14/14 [00:11<00:00,  1.24it/s]
[2023-11-13 20:29:31,178] [opencompass.openicl.icl_inferencer.icl_ppl_inferencer] [INFO] Calculating PPL for prompts labeled 'C'
  0%|          | 0/14 [00:00<?, ?it/s]  7%|▋         | 1/14 [00:00<00:11,  1.17it/s] 14%|█▍        | 2/14 [00:01<00:10,  1.17it/s] 21%|██▏       | 3/14 [00:02<00:09,  1.17it/s] 29%|██▊       | 4/14 [00:03<00:08,  1.19it/s] 36%|███▌      | 5/14 [00:04<00:07,  1.18it/s] 43%|████▎     | 6/14 [00:05<00:06,  1.19it/s] 50%|█████     | 7/14 [00:05<00:05,  1.18it/s] 57%|█████▋    | 8/14 [00:06<00:05,  1.19it/s] 64%|██████▍   | 9/14 [00:07<00:04,  1.18it/s] 71%|███████▏  | 10/14 [00:08<00:03,  1.18it/s] 79%|███████▊  | 11/14 [00:09<00:02,  1.15it/s] 86%|████████▌ | 12/14 [00:10<00:01,  1.14it/s] 93%|█████████▎| 13/14 [00:11<00:00,  1.15it/s]100%|██████████| 14/14 [00:11<00:00,  1.53it/s]100%|██████████| 14/14 [00:11<00:00,  1.24it/s]
[2023-11-13 20:29:42,754] [opencompass.openicl.icl_inferencer.icl_ppl_inferencer] [INFO] Calculating PPL for prompts labeled 'D'
  0%|          | 0/14 [00:00<?, ?it/s]  7%|▋         | 1/14 [00:00<00:11,  1.17it/s] 14%|█▍        | 2/14 [00:01<00:10,  1.17it/s] 21%|██▏       | 3/14 [00:02<00:09,  1.17it/s] 29%|██▊       | 4/14 [00:03<00:08,  1.19it/s] 36%|███▌      | 5/14 [00:04<00:07,  1.18it/s] 43%|████▎     | 6/14 [00:05<00:06,  1.19it/s] 50%|█████     | 7/14 [00:05<00:05,  1.18it/s] 57%|█████▋    | 8/14 [00:06<00:05,  1.19it/s] 64%|██████▍   | 9/14 [00:07<00:04,  1.18it/s] 71%|███████▏  | 10/14 [00:08<00:03,  1.18it/s] 79%|███████▊  | 11/14 [00:09<00:02,  1.15it/s] 86%|████████▌ | 12/14 [00:10<00:01,  1.15it/s] 93%|█████████▎| 13/14 [00:11<00:00,  1.15it/s]100%|██████████| 14/14 [00:11<00:00,  1.53it/s]100%|██████████| 14/14 [00:11<00:00,  1.24it/s]
11/13 20:29:54 - OpenCompass - INFO - time elapsed: 9038.20s
