dataset,version,metric,mode,hf_llama-7b
------- MMLU details -------,-,-,-,-
mmlu-humanities,-,-,-,-
mmlu-stem,-,naive_average,ppl,31.12
mmlu-social-science,-,-,-,-
mmlu-other,-,-,-,-
mmlu,-,-,-,-
---- Standard Benchmarks ---,-,-,-,-
BoolQ,314797,accuracy,ppl,75.50
piqa,-,-,-,-
siqa,-,-,-,-
hellaswag,a6e128,accuracy,ppl,74.29
winogrande,-,-,-,-
ARC-e,-,-,-,-
ARC-c,2ef631,accuracy,ppl,32.20
openbookqa_fact,6aac9e,accuracy,ppl,29.80
commonsense_qa,-,-,-,-
mmlu,-,-,-,-
------ Code Generation -----,-,-,-,-
openai_humaneval,-,-,-,-
mbpp,1e1056,score,gen,17.20
------ World Knowledge -----,-,-,-,-
triviaqa,2121ce,score,gen,44.26
--- Reading Comprehension --,-,-,-,-
squad2.0,1710bc,score,gen,35.00
---------- Exams -----------,-,-,-,-
math,265cce,accuracy,gen,2.88
gsm8k,1d7fe4,accuracy,gen,10.61
TheoremQA,ef26ca,accuracy,gen,1.25
--------- Chinese ----------,-,-,-,-
ceval,-,naive_average,ppl,27.38
ceval-stem,-,naive_average,ppl,26.90
ceval-social-science,-,naive_average,ppl,29.68
ceval-humanities,-,naive_average,ppl,24.18
ceval-other,-,naive_average,ppl,29.36
ceval-hard,-,naive_average,ppl,27.68
ceval-test-stem,-,-,-,-
ceval-test-social-science,-,-,-,-
ceval-test-humanities,-,-,-,-
ceval-test-other,-,-,-,-
ceval-test-hard,-,-,-,-
ceval-test,-,-,-,-
cmmlu,-,naive_average,ppl,26.77
cmmlu-humanities,-,naive_average,ppl,26.74
cmmlu-stem,-,naive_average,ppl,25.34
cmmlu-social-science,-,naive_average,ppl,27.31
cmmlu-other,-,naive_average,ppl,27.62
cmmlu-china-specific,-,naive_average,ppl,25.62
